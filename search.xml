<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>tcp_ip八股文</title>
      <link href="/2021/08/03/tcp-ip%E5%85%AB%E8%82%A1%E6%96%87/"/>
      <url>/2021/08/03/tcp-ip%E5%85%AB%E8%82%A1%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h1 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h1><p>udp协议属于传输层协议。</p><h2 id="udp报文协议"><a href="#udp报文协议" class="headerlink" title="udp报文协议"></a>udp报文协议</h2><table><thead><tr><th align="center">16位源端口号</th><th align="center">16位目的端口号</th></tr></thead><tbody><tr><td align="center">16位UDP长度</td><td align="center">16为UDP校验和</td></tr><tr><td align="center">数据内容</td><td align="center">数据内容</td></tr></tbody></table><p>0                                                                        15 16                                                                                            31</p><p>源端口：0<del>65535，1</del>1024为保留端口，为标准的服务端口</p><p>UDP长度：header + data 总长度</p><p>UDP校验和：伪头部、头部、data 三部分的校验和</p><p>数据内容：上层应用的数据，可以没有数据</p><ul><li>若校验和失败，就会丢弃数据</li></ul><h2 id="UDP协议的特点"><a href="#UDP协议的特点" class="headerlink" title="UDP协议的特点"></a>UDP协议的特点</h2><ul><li><p>无链接</p><p>  只需知道对端的IP和PORT就可以发送数据，不需要建立链接</p></li><li><p>不可靠</p><p>  没有确认机制，没有重传机制。若因为网络原因没有发送到对端，UDP协议层也不会返回任何错误给应用层。</p></li><li><p>面向数据报</p><p>  应用层交给UDP多长的报文，UDP就会直接传送过去，不会进行拆分。接收时也是一次性接受全部传送的数据报。</p></li><li><p>UDP存在接收缓冲区，单步存在发送缓冲区</p><p>  UDP在发送数据时没有缓冲区，会直接将数据传递给内核，内核会直接调用网卡进行传输。因为UDP不需要保证可靠机制，所以报文丢失之后不需要再重新发送。而UDP虽然有接受缓冲区，但是不会保证收到的数据顺序，缓冲区满了之后就会将新接收的报文丢弃。</p></li><li><p>双全工通信</p><p>  UDP可同时接收和发送数据报文。</p></li></ul><p>UDP协议首部有一个16位的长度，说明UDP最长可以发送64k数据(包含首部)，超过之后就需要我们手工在应用层分包。</p><h2 id="常见的UDP协议"><a href="#常见的UDP协议" class="headerlink" title="常见的UDP协议"></a>常见的UDP协议</h2><ul><li>NFS：网络文件传输协议</li><li>TFTP：简单文件传输协议</li><li>DHCP：动态主机配置协议</li><li>DNS：域名解析协议</li><li>自定义的UDP协议等</li></ul><h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><p>TCP全称为<strong>传输控制</strong>协议，必需对数据的传输进行控制。</p><h2 id="tcp协议报文格式"><a href="#tcp协议报文格式" class="headerlink" title="tcp协议报文格式"></a>tcp协议报文格式</h2><p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-nVPhK4MP-1622623775394)(C:\Users\10288683\AppData\Roaming\Typora\typora-user-images\tcp报文协议.png)]</p><ul><li><p>源/目的端口：标识数据从哪儿来要去哪儿</p></li><li><p>32位序号：序号保证了可靠传输。TCP将传输的每一个字节都编号了，序号是本报文段数据的第一个字节编号。例如：一个报文段序号是300，其数据部分共有100字节，则下一个报文段序号为401。</p></li><li><p>32位徐仁序列号：每一个ACK对应这个确认号，它指明下一个期待收到的字节序号。其表明之前收到的所有数据都已经正确无误。确认号只有当ACK标志为1的时候才有效。<strong>建立连接时，SYN报文的ACK标志为0</strong>。</p></li><li><p>4位首部长度(数据偏移)：表示该TCP头部有多少个32位bit，所以TCP头部大长度是<strong>15*4=60</strong>。TCP默认报文大小为20字节。</p></li><li><p>6个标志位：</p><ul><li>URG:它为了标志紧急指针是否有效。</li><li>ACK：标识确认号是否有效。</li><li>PSH:提示接收端应用程序立即将接收缓冲区的数据拿走。</li><li>RST：它是为了处理异常连接的， 告诉连接不一致的一方，我们的连接还没有建立好， 要求对方重新建立连接。我们把携带RST标识的称为复位报文段。</li><li>SYN：请求建立连接；把携带SYN标识的称为同步报文段。</li><li>FIN：通知对端本段要关闭链接了；把携带FIN标识的称为结束报文段。</li></ul></li><li><p>16位紧急指针：当有些报文想优先被处理时(原来是按序处理)，设置紧急指针指向该报文，同时将紧急指针有效位置1。</p></li><li><p>16位窗口大小：若发送方发送速度大于接收方发送速度(比如发送方发送大量数据)，这时可能会导致大量数据丢失，接收方可以发送消息给发送方让其发送慢一点，这就是<strong>流量控制</strong>。接收方将自己接受缓冲器剩余空间的大小告诉发送方叫做<strong>16位窗口大小</strong>。窗口大小最大是2^16^，也就是64k。</p></li><li><p>16位校验和：发送端填充，<code>CRC</code>校验。</p></li></ul><h2 id="TCP确认应答机制"><a href="#TCP确认应答机制" class="headerlink" title="TCP确认应答机制"></a>TCP确认应答机制</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant 主机A</span><br><span class="line">participant 主机B</span><br><span class="line">主机A-&gt;&gt;主机B:数据：1~1000</span><br><span class="line">主机B-&gt;&gt;主机A:确认应答，下一个是1001</span><br><span class="line">主机A-&gt;&gt;主机B:数据：1001~2000</span><br><span class="line">主机B-&gt;&gt;主机A:确认应答，下一个是2001</span><br></pre></td></tr></table></figure><p>发送端放一条数据到接收端，接收端在收到一条报文后，向发送端发送一条<code>ACK</code>确认报文，告诉发送端已经成功的接收到了消息，并且希望收到的下一个序列号是多少。这个确认号就是下一个报文的序列号。</p><h2 id="超时重传机制"><a href="#超时重传机制" class="headerlink" title="超时重传机制"></a>超时重传机制</h2><p>注：虚线标识未可达，实线表示到达。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant 主机A</span><br><span class="line">participant 主机B</span><br><span class="line"> 主机A--&gt;&gt;主机B:数据：1~1000</span><br><span class="line"> Note right of 主机A:数据1到1000未到达主机B</span><br><span class="line"> Note left of 主机A:一段特定的时间间隔过后</span><br><span class="line">  主机A-&gt;&gt;主机B:数据：1~1000</span><br><span class="line">  主机B-&gt;&gt;主机A:确认应答，下一个是1001</span><br></pre></td></tr></table></figure><p>在传输过程中的超时重传机制。A给B发送数据，若A在一定时间没有收到B的确认应答消息，会进行重发。其中可能存在B没有收到A的消息，这时B不会应答；也可能是B的应答A没有收到，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant A</span><br><span class="line">participant B</span><br><span class="line">A-&gt;&gt;B:数据：1~1000</span><br><span class="line">B--&gt;&gt;A:确认应答，下一个是1001</span><br><span class="line">Note right of A:未收到B发送的确认应答消息</span><br><span class="line">Note left of A:一段时间间隔之后</span><br><span class="line">A-&gt;&gt;B:数据：1~1000</span><br><span class="line">B-&gt;&gt;A:确认应答，下一个是1001</span><br></pre></td></tr></table></figure><p>此时主机B就会收到很多重复的包，可以利用前面的16位序列号将重复的包识别出来并丢弃，这样就做到了数据去重的效果。</p><p>超时时间的确认：</p><p>​    若超时时间间隔设置的太长，会影响整体重传的效率；若设置的时间间隔太短，就可能会频繁的发送重复的包。TCP为了保证不同的网络传输效率的高效，会动态的计算这个时间间隔。</p><p>​    在linux中，以500ms为一个时间单位进行控制。若超过500ms没有收到应答，则重发一次；若重发一次之后仍未等待到确认应答，则等待2*500ms进行重发，下一次重发为4*500ms。依次类推，成指数级增长。当累计到一定次数，则认为网络或者对端主机出现异常，关闭链接。</p><h1 id="三次握手与四次挥手"><a href="#三次握手与四次挥手" class="headerlink" title="三次握手与四次挥手"></a>三次握手与四次挥手</h1><h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p>三次握手也就是建立连接的过程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant Client</span><br><span class="line">participant Server</span><br><span class="line">Note over Client,Server:CLOSED</span><br><span class="line">Note over Server:LISTEN</span><br><span class="line">Client -&gt;&gt; Server:连接请求：SYN=1,seq=x</span><br><span class="line">Note over Client:SYN-SENT</span><br><span class="line">Server -&gt;&gt; Client:SYN=1,ACK=1,seq=y,ack=x+1</span><br><span class="line">Note over Server:SYN-RCVD</span><br><span class="line">Client -&gt;&gt; Server:ACK=1,seq=x+1,ack=y+1</span><br><span class="line">Note over Client,Server:ESTABLISHED</span><br><span class="line">Note left of Server:数据传输开始</span><br></pre></td></tr></table></figure><ol><li>服务器由CLOSED状态转换为LISTEN(监听)状态。</li><li>客户端发送连接请求报文到服务端。此时报文中的同步标志位SYN置为1，选择一个初始序列号seq=x，并将客户端置为SYN-SENT(同步已发送态)状态。注意，TCP规定SYN不能携带数据，但是会消耗一个序列号。</li><li>TCP服务端收到报文，如果同意连接则发送应答确认报文。其中，确认报文的SYN=1，ACK=1，确认序列号为x+1，服务端也会初始化生成一个序列号y，此时服务端进入SYN-RCVD(同步收到态)状态。这个报文同样不能携带数据，但是也会消耗一个序列号。</li><li>TCP客户端收到确认报文后，还需要向服务器应答一个确认报文(为了链接的可靠性)。其中，ACK=1，确认序列号ack=y+1，自己的序列号req=x+1。</li><li>连接建立，CS之间可以相互通信收发数据。</li></ol><h3 id="第三次握手的意义："><a href="#第三次握手的意义：" class="headerlink" title="第三次握手的意义："></a>第三次握手的意义：</h3><p>​    主要是为了防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送的第一个请求连接并且没有丢失，只是因为在网络中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时之前滞留的那一次请求连接，因为网络通畅了, 到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的费。 </p><p>​    如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。</p><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant Client</span><br><span class="line">participant Server</span><br><span class="line">Note over Client,Server:ESTABLISHED</span><br><span class="line">Note left of Client:主动关闭链接</span><br><span class="line">Client -&gt;&gt; Server:连接请求：FIN=1,seq=u</span><br><span class="line">Note over Client:FIN-WAIT1</span><br><span class="line">Server -&gt;&gt; Client:ACK=1,seq=v,ack=u+1</span><br><span class="line">Note over Server:CLOSE-WAIT</span><br><span class="line">Note over Client:FIN-WAIT2</span><br><span class="line">Server -&gt;&gt; Client:数据传输</span><br><span class="line">Server -&gt;&gt; Client:FIN=1,ACK=1,seq=w,ack=u+1</span><br><span class="line">Note over Server:LAST-ACK</span><br><span class="line">Client -&gt;&gt; Server:ACK=1,seq=u+1,ack=w+1</span><br><span class="line">Note over Client:TIME-WAIT (2MSL)</span><br><span class="line">Note over Client,Server:CLOSED</span><br></pre></td></tr></table></figure><p>在建立连接后，两边都可以断开连接。</p><p>此时客户端和服务器都是处于ESTABLISHED状态，然后客户端主动断开连接，服务器被动断开连接。</p><ol><li>客服端发送释放连接报文FIN，这时客户端不再发送数据。此时FIN=1,序列号seq=u(等于前面已发送的数据的最后一个字节的序号加1)，客户端进入FIN-WAIT-1状态。TCP规定及时FIN报文不携带数据也要消耗一个序列号。</li><li>服务端收到FIN报文，发出确认报文ACK。其中ACK=1,确认序列号ack=u+1，并且带上自己的序列号v。此时服务端进入CLOSE-WAIT(关闭等待)状态。 此时， TCP服务器会通知上层的应用，客服端向服务器方向释放了连接，处于半关闭状态，即客户端没有数据需要发送了但服务端可以发送数据到客户端让客户端处理。</li><li>客服端收到服务端发送的ACK报文后，客户端进入FIN-WAIT-2状态。等待服务端发送FIN释放报文。</li><li>服务端将所有数据发送完之后，向客户端发送FIN释放报文。其中，FIN=1，ACK=1，此时自己的序列号seq=w，确认序列号ack=u+1。此时服务端进入了LAST-ACK(最终确认)状态，等待客户端的确认报文。</li><li>客户端收到服务端的FIN释放报文，必需发出确认ACK报文。其中ACK=1，确认序列号ack=w+1，自己的序列号req=u+1。此时客户端进入了TIME-WAIT(时间等待)状态，必需经过2*MSL(最长报文寿命时间段)之后才能进入CLOSED状态。</li></ol><h3 id="第四次握手为什么要等待2MSL时长"><a href="#第四次握手为什么要等待2MSL时长" class="headerlink" title="第四次握手为什么要等待2MSL时长"></a>第四次握手为什么要等待2MSL时长</h3><ul><li><p>ACK报文的可靠性</p><p>  保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。</p></li><li><p>去除无效报文</p><p>  防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。</p></li></ul><h3 id="为什么握手要三次，挥手要四次"><a href="#为什么握手要三次，挥手要四次" class="headerlink" title="为什么握手要三次，挥手要四次"></a>为什么握手要三次，挥手要四次</h3><p>​    建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。 </p><p>​    而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。</p><h3 id="建链之后，客户端故障了怎么处理"><a href="#建链之后，客户端故障了怎么处理" class="headerlink" title="建链之后，客户端故障了怎么处理"></a>建链之后，客户端故障了怎么处理</h3><p>​    TCP设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p><p>此种机制类似心跳检测机制。</p><h3 id="TIME-WAIT状态解读"><a href="#TIME-WAIT状态解读" class="headerlink" title="TIME-WAIT状态解读"></a>TIME-WAIT状态解读</h3><p>​        当我们实现一个TCP服务器时，我们把这个服务器运行起来然后再将服务器关闭掉，再次重新启动服务器会发现一个问题：就是不能马上再次绑定这个端口号和ip，需要等一会才可以重新绑定，其实等的这一会就是TIME_WAIT状态。</p><ul><li>TCP协议规定主动关闭连接的一方要处于TIME_ WAIT状态，等待两个MSL的时间后才能回到CLOSED状态。</li><li>当我们使用Ctrl-C终止了server，server是主动关闭连接的一方在TIME_WAIT期间仍然不能再次监听同样的server端口。</li><li>MSL在RFC1122中规定为两分钟(120s)，但是各操作系统的实现不同，在Centos7上默认配置的值是60s可以通过cat /proc/sys/net/ipv4/tcp_fin_timeout查看MSL的值。</li></ul><p>解决TIME_WAIT状态引起的bind失败的方法：</p><p>​        在server的TCP连接没有完全断开之前不允许重新绑定，也就是TIME_WAIT时间没有过，但是这样不允许立即绑定在某些情况下是不某些特定场景的：</p><ul><li>服务器需要处理非常大量的客户端的连接 (每个连接的生存时间可能很短，但是每秒都有很大数量的客户 端来请求)</li><li>这个时候如果由服务器端主动关闭连接(比如某些客户端不活跃，就需要被服务器端主动清理掉)，这样服务器端就会产生大量TIME_WAIT状态。</li><li>如果客户端的请求量很大，就可能导致TIME_WAIT的连接数很多，每个连接都会占用一个通信五元组(源ip, 源端口, 目的ip, 目的端口, 协议)。其中服务器的ip和端口和协议是固定的，如果新来的客户端连接的ip和端口号和TIME_WAIT占用的连接重复就造成等待。</li></ul><p>解决方法：使用setsockopt()设置socket描述符的选项SO_REUSEADDR为1，表示<strong>允许创建端口号相同但IP地址不同的多个socket描述符</strong>。</p><h1 id="滑动窗口机制"><a href="#滑动窗口机制" class="headerlink" title="滑动窗口机制"></a>滑动窗口机制</h1><p>​        <strong>确认应答策略</strong>对每一个发送的数据段都要给一个ACK确认应答，接收方收到ACK后再发送下一个数据段，但是这样做有一个比较大的缺点，就是<strong>性能较差</strong>，尤其是数据往返的时间较长的时候。</p><p>​        考虑一次发送多条数据，它是将多个段的等待时间重叠在一起。</p><p>​        窗口大小指的是无需等待确认应答而可以继续发送数据的最大值。若需要发送12个报文段。发送前四个段的时候，不需要等待任何ACK直接发送即可。当收到第一个ACK后滑动窗口向后移动，继续发送第五个段的数据，然后依次类推。<strong>操作系统内核为了维护</strong>这个滑动窗口，需要开辟<strong>发送缓冲区</strong>来记录当前还有哪些数据没有应答。只有确认应答过的数据，才能从缓冲区删掉，窗口越大，则网络的吞吐率就越高。滑动窗口<strong>左边代表已经发送过并且确认</strong>，可以从发送缓冲区中删除了，滑动窗口<strong>里边代表发送出去但是没有确认</strong>，滑动窗口<strong>右边代表还没有发送的</strong>数据。</p><h2 id="快重传"><a href="#快重传" class="headerlink" title="快重传"></a>快重传</h2><p>若出现丢包现象该怎么处理呢？</p><ol><li><p>数据到达接收方但丢失了应答报文？</p><p> ​    可以根据后面的应答ACK确认。假设发送了1~1000的数据，接收方接收到了但是返回的应答报文丢失。发送方继续发送1001——2000收到确认ACK 2001，则认为1-1000发送成功并成功接收了。</p></li><li><p>数据包之间丢失报文？</p><p> 当某一段报文1001-2000丢失后，发送端会一直收到1001的这样的ACK确认(就像在提醒发送端我想要的报文是1001开头)，若发送端连续三次收到这样的确认ACK，就会将1001-2000报文重发。这个时候接收端收到1001报文之后就会收到当前的报文段6001(假设前面发送到6000了，被放到了内核缓冲区中)。<strong>这种机制就叫做快重传</strong>。</p><p> ​    快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。由于不需要等待设置的重传计时器到期，能尽早重传未被确认的报文段，能提高整个网络的吞吐量。</p></li></ol><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>​        因为接收端的处理数据能力有限，因各种原因接收端的缓冲区被填满，如果这个时候发送端继续发送就会发生丢包现象，然后引起丢包重传等一系列连锁反应。因此要根据接收端处理数据的能力来控制发送端的发送速度。这就叫<strong>流量控制</strong>。</p><ol><li>接收端将自己可以接受的缓冲区大小放在TCP首部的窗口大小字段，通过ACK确认应答报文通知发送端。</li><li>窗口大小越大，说明吞吐量越大，当缓冲区快满了的时候，就会将窗口值设置为一个更小的值通知给发送端。</li><li>当窗口大小为0之后，发送端在接收到ACK确认报文之后就不会发送数据了。但是会定期发送一个<em>窗口探测数据端</em>(防止缓冲区满了之后无法继续通信)，使接收端把窗口大小发送给发送端。</li></ol><p>象，然后引起丢包重传等一系列连锁反应。因此要根据接收端处理数据的能力来控制发送端的发送速度。这就叫<strong>流量控制</strong>。</p><ol><li>接收端将自己可以接受的缓冲区大小放在TCP首部的窗口大小字段，通过ACK确认应答报文通知发送端。</li><li>窗口大小越大，说明吞吐量越大，当缓冲区快满了的时候，就会将窗口值设置为一个更小的值通知给发送端。</li><li>当窗口大小为0之后，发送端在接收到ACK确认报文之后就不会发送数据了。但是会定期发送一个<em>窗口探测数据端</em>(防止缓冲区满了之后无法继续通信)，使接收端把窗口大小发送给发送端。</li></ol><p>​        在TCP首部的窗口大小字段，大小为16位，数据大小为65535，但由于TCP首部还有40字节的选项中包含了一个窗口扩大因子M，所以实际实际大小是窗口字段左移M位。</p><h1 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h1><p>​        拥塞控制是TCP通信的每一方需要执行的一系列行为。这些行为是由一些特定的算法规定，用于防止网络因为大规模的通信而瘫痪。其基本方法是可以认为网络即将进入拥塞状态或已经拥塞而出现的丢包情况出现时，减缓TCP传输数据。其难点在于怎样精准的判断何时需要减缓且如何减缓TCP传输、何时恢复原有的速度。</p><h2 id="TCP拥塞检测"><a href="#TCP拥塞检测" class="headerlink" title="TCP拥塞检测"></a>TCP拥塞检测</h2><p>​        典型的TCP拥塞检测通常看是否有丢包出现，丢包在TCP中被用作判断拥塞发生与否指标。当然也有其他的一些方法，如时延测量、显式拥塞通知等等。</p><h2 id="慢启动算法"><a href="#慢启动算法" class="headerlink" title="慢启动算法"></a>慢启动算法</h2><p>​        若网络上有很多的计算机，可能当前的网络状态就已经比较拥堵，在不清楚当前网络状态下，贸然发送大量的数据是很有可能引起雪上加霜的，造成网络更加堵塞，所以需要缓慢探测可用传输资源，防止短时间内大量数据注入导致拥塞甚至瘫痪。慢启动算法就是为了这一目的设计而出的。<strong>在数据传输之初或重传计时器检测到丢包后执行慢启动</strong>，直到有丢包时执行拥塞避免算法。</p><p>​    注：慢启动算法和拥塞避免算法在同一时刻只会运行其中一个，但两者可相互切换。</p><p>​        <code>cwnd</code>为拥塞窗口大小，在发送开始的时候定义拥塞窗口大小为1，每次收到一个ACK应答拥塞窗口加1。每次发送数据包的时候，将<em>拥塞窗口</em>和<em>接收端主机反馈的窗口大小</em>做比较，取较小的值作为实际发送的窗口。<code>cwnd</code>是随时间以指数增长的。</p><p>​        <code>&quot;慢启动&quot;</code>只是指初使时慢，但是增长速度非常快。为了不增长的那么快，因此不能使<code>拥塞窗口</code>单纯的加倍，此处引入一个叫做<code>慢启动的阈值</code>当拥塞窗口超过这个阈值的时候，不再按照指数方式增长， 而是按照<code>线性方式</code>增长。这个阈值是慢启动阶段至拥塞避免阶段的转折点。</p><ul><li>当<code>TCP</code>开始启动的时候，慢启动<code>阈值</code>等于窗口最大值</li><li>在每次<code>超时重发</code>的时候，慢启动<code>阈值</code>会变成原来的一半同时拥塞窗口置回<code>1</code></li></ul><h2 id="拥塞避免算法"><a href="#拥塞避免算法" class="headerlink" title="拥塞避免算法"></a>拥塞避免算法</h2><p>​        在慢启动阶段，cwnd会快速增长，帮助确定一个慢启动阈值。一旦到达这阈值，意味着可能有更多的资源可被传输。若全部占用这些资源，将会使共享路由器队列的其他链接出现严重的丢包和重传情况，从而导致整个网络的不稳定。<em>为了获取更多资源而不影响其他的连接传输，引入了拥塞避免算法</em>。一旦进入慢启动阈值，TCP就会进入拥塞避免阶段，cwnd每次增长值近似于成功传输的数据段大小。这种随时间接近线性增长。</p><h3 id="拥塞控制与流量控制"><a href="#拥塞控制与流量控制" class="headerlink" title="拥塞控制与流量控制"></a>拥塞控制与流量控制</h3><p>​        拥塞控制是防止过多的流量进入网络中，使网络中的路由器或链路不至于过载，是一个全局性的过程。流量是点对点的通信量的控制，是一个端到端的控制问题，主要权衡发送端发送数据的速度，以便接收端能够接收。</p><p>​    无论是在<code>慢启动阶段</code>还是在<code>拥塞避免阶段</code>，只要发送方判断网络出现<code>拥塞</code>（其根据就是没有收到确认，虽然没有收到<code>确认</code>可能是其他原因的分组丢失，但是因为无法判定，所以都当做<code>拥塞</code>来处理），这时就把<code>慢启动门限</code>设置为<code>出现拥塞</code>时的门限的一半。然后把<code>拥塞窗口</code>设置为1，执行<code>慢启动</code>算法。</p><pre><code>* 加法增大：执行`拥塞避免`算法后，拥塞窗口`线性缓慢`增大，防止网络过早出现拥塞* 乘法减小：无论是慢启动阶段还是拥塞避免，只要出现了网络拥塞（超时），那就把慢启动门限值`ssthresh`减半</code></pre><h2 id="延迟应答"><a href="#延迟应答" class="headerlink" title="延迟应答"></a>延迟应答</h2><p>​        如果接收数据的主机立刻返回ACK应答，这时候返回的窗口可能比较小。假设接收端缓冲区为1M 一次收到了500K的数据。如果立刻应答，返回的窗口就是500K。 但实际上可能处理端处理的速度很快，10ms之内就把500K数据从缓冲区消费掉了，在这种情况下，接收端处理还远没有达到自己的极限，即使窗口再放大一些也能处理过来。如果接收端稍微等一会再应答，比如等待200ms再应答，那么这个时候返回的窗口大小就是1M。</p><p>​        窗口越大，网络吞吐量就越大，传输效率就越高。我们的目标是在保证网络不拥塞的情况下尽量提高传输效率。</p><ul><li><p>数量限制: 每隔<code>N个包</code>就应答一次</p></li><li><p>时间限制: 超过大<code>延迟时间</code>就应答一次</p><p>  捎带应答：</p><p>  ​    在延迟应答的基础上，存在很多情况下，客户端服务器在应用层也是”一发一收” 的。 意味着客户端给服务器说了”How are you”， 服务器也会给客户端回一个”Fine, thank you”。那么这个时候ACK就可以搭顺风车，和服务器回应的 “Fine, thank you” 一起回给客户端。</p></li></ul><h2 id="面向字节流"><a href="#面向字节流" class="headerlink" title="面向字节流"></a>面向字节流</h2><p>​    当我们创建一个TCP的socket，同时在内核中创建一个发送缓冲区和一个接收缓冲区。</p><ul><li><p>调用write时，内核将数据会先写入发送缓冲区中，如果发送的字节数太长，会被拆分成多个TCP的数据包发出，如果发送的字节数太短，就会先在缓冲区里等待， 等到缓冲区长度达到设置长度，然后等到其他合适的时机发送出去。</p></li><li><p>调用read接收数据的时候， 数据也是从网卡驱动程序到达内核的接收缓冲区。然后应用程序可以调用read从接收缓冲区拿数据。TCP的一个连接，既有发送缓冲区, 也有接收缓冲区，那么对于这一个连接，既可以读数据，也可以写数据。所以是全双工的。</p></li></ul><p>​        由于缓冲区的存在，TCP程序的读和写不需要一一匹配。例如: 写100个字节数据时, 可以调用一次write写100个字节, 也可以调用100次write, 每次写一个字节; 读100个字节数据时, 也完全不需要考虑写的时候是怎么写的, 既可以一次read 100个字节, 也可以一次 read一个字节, 重复100次。</p><h2 id="粘包问题"><a href="#粘包问题" class="headerlink" title="粘包问题"></a>粘包问题</h2><p>​        粘包问题中的 “包”是指的应用层的数据包。在TCP的协议头中，没有如同UDP一样的 “报文长度”这样的字段，但是有一个序号这样的字段。站在传输层的角度， TCP是一个一个报文过来的，按照序号排好序放在缓冲区中，但是站在应用层的角度，它看到的只是一串连续的字节数据。应用程序看到了这么一连串的字节数据， 就不知道<strong>从哪个部分开始到哪个部分结束是一个完整的应用层数据包</strong>，这就是粘包问题。</p><p>​        如何解决：</p><ul><li>对于定长的包，保证每次都按固定大小读取即可。例如一个Request结构, 是固定大小的, 那么就从缓冲区从头开始按sizeof(Request)依次读取即可。</li><li>对于变长的包，可以在包头的位置，约定一个包总长度的字段，从而就知道了包的结束位置。</li><li>对于变长的包，还可以在包和包之间使用明确的分隔符(应用层协议是程序员自己来定义的, 只要保证分隔符不和正文冲突即可)。</li></ul><p>层的角度， TCP是一个一个报文过来的，按照序号排好序放在缓冲区中，但是站在应用层的角度，它看到的只是一串连续的字节数据。应用程序看到了这么一连串的字节数据， 就不知道<strong>从哪个部分开始到哪个部分结束是一个完整的应用层数据包</strong>，这就是粘包问题。</p><p>​        如何解决：</p><ul><li>对于定长的包，保证每次都按固定大小读取即可。例如一个Request结构, 是固定大小的, 那么就从缓冲区从头开始按sizeof(Request)依次读取即可。</li><li>对于变长的包，可以在包头的位置，约定一个包总长度的字段，从而就知道了包的结束位置。</li><li>对于变长的包，还可以在包和包之间使用明确的分隔符(应用层协议是程序员自己来定义的, 只要保证分隔符不和正文冲突即可)。</li></ul><p>对于UDP协议，如果还没有上层交付数据， UDP的报文长度仍然在。 同时UDP是一个一个把数据交付给应用层，这样就有存在明确的数据边界，站在应用层的角度， 使用UDP的时候要么收到完整的UDP报文要么不收，不会出现”半个”的情况。</p><h1 id="HTTP与HTTPS区别"><a href="#HTTP与HTTPS区别" class="headerlink" title="HTTP与HTTPS区别"></a>HTTP与HTTPS区别</h1><ol><li> https需要到ca申请证书，申请证书需要money；</li><li> http是超文本传输协议，信息是明文传输，https则是使用SSL/STL加密传输协议，安全性较高；</li><li> http使用80端口，https使用443端口；</li><li> http是无状态连接，https是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。</li></ol><h2 id="HTTPS工作原理"><a href="#HTTPS工作原理" class="headerlink" title="HTTPS工作原理"></a>HTTPS工作原理</h2><img src="/2021/08/03/tcp-ip%E5%85%AB%E8%82%A1%E6%96%87/https%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png" class="" title="image-20210603211824919"><ol><li> 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。</li><li> Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。</li><li> 客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。</li><li> 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。</li><li> Web服务器利用自己的私钥解密出会话密钥。</li><li> Web服务器利用会话密钥加密与客户端之间的通信。</li></ol><p>https缺点：</p><ul><li><p>  HTTPS协议握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电；</p></li><li><p>  HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；</p></li><li><p>  SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。</p></li><li><p>  SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。</p></li><li><p>  HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击(dos)、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。</p></li></ul><h1 id="session与cookie"><a href="#session与cookie" class="headerlink" title="session与cookie"></a>session与cookie</h1><p>cookie的内容主要包括：名字，值，过期时间，路径和域。路径与域一起构成cookie的作用范围。若不设置过期时间，则表示这个cookie的生命期为浏览器会话期间，关闭浏览器窗口，cookie就消失。这种生命期为浏览器会话期的cookie被称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。若设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存里的cookie，不同的浏览器有不同的处理方式</p><p>session机制。session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了一个session标识（称为session id），如果已包含则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（检索不到，会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发送给服务器。</p><p>区别：</p><ol><li> cookie数据放在客户的浏览器上，session数据放在服务器上；</li><li> cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，考虑到安全应当使用session；</li><li> session会在一定时间内保存在服务器上。当访问增多，会比较占用服务器的性能，考虑到服务器性能应当使用cookie；</li><li> 单个cookie保存的数据不能超过4k，很多浏览器都限制一个站点最多保存20个cookie；</li></ol><p><strong>建议：将登录等重要信息存放在session中，其他的一些信息若需要保留，就存放在cookie中</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP/IP </tag>
            
            <tag> 面试 </tag>
            
            <tag> UDP </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>go_GC原理</title>
      <link href="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/"/>
      <url>/2021/07/25/go-GC%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Mark-amp-Sweep"><a href="#Mark-amp-Sweep" class="headerlink" title="Mark &amp; Sweep"></a>Mark &amp; Sweep</h1><h3 id="Carbage-Collection"><a href="#Carbage-Collection" class="headerlink" title="Carbage Collection"></a>Carbage Collection</h3><p>现代高级编程语言管理内存的方式分为两种：<em>自动</em>和<em>手动</em>，像 C、C++ 等编程语言使用手动管理内存的方式，工程师编写代码过程中需要<em>主动申请</em>或者<em>释放内存</em>；而 PHP、Java 和 Go 等语言使用自动的内存管理系统，有<em>内存分配器</em>和<em>垃圾收集器</em>来代为分配和回收内存，其中垃圾收集器就是我们常说的 GC。主流的垃圾回收算法：</p><ul><li>  <strong>引用计数</strong></li><li>  <strong>追踪式垃圾回收</strong></li></ul><p><strong>Go 现在用的三色标记法就属于追踪式垃圾回收算法的一种。</strong></p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/carbage-collection.png" class="" title="image-20210725130838565"><h3 id="Mark-amp-Sweep-1"><a href="#Mark-amp-Sweep-1" class="headerlink" title="Mark &amp; Sweep"></a>Mark &amp; Sweep</h3><p><em>STW</em></p><p><code>stop the world</code>, GC 的一些阶段需要停止所有的 <code>mutator </code>以确定当前的引用关系。这便是很多人对 GC 担心的来源，这也是 GC 算法优化的重点。</p><p><em>Root</em></p><p>根对象是 <code>mutator </code><strong>不需要通过其他对象就可以直接访问</strong>到的对象。比如<strong>全局对象</strong>，<strong>栈对象</strong>中的数据等。通过<code>Root </code>对象，可以<strong>追踪到其他存活的对象</strong>。</p><p><code>Mark Sweep</code> 两个阶段：**标记(Mark)**和 **清除(Sweep)**两个阶段，所以也叫 <code>Mark-Sweep</code> 垃圾回收算法。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/GC-root.png" class="" title="image-20210725131746009"><p>下面这个算法就是严格按照<em>追踪式算法</em>的思路来实现的：</p><ul><li>  <code>Stop the World</code></li><li>  <code>Mark</code>：通过 Root 和 Root 直接间接访问到的对象， 来寻找所有可达的对象，并进行标记。</li><li>  <code>Sweep</code>：对<em>堆对象迭代</em>，已标记的对象置位标记。所有<em>未标记的对象加入freelist</em>， 可用于再分配。</li><li>  <code>Start the Wrold</code></li></ul><p>这个算法最大的问题是 <strong>GC 执行期间需要把整个程序完全暂停</strong>，朴素的 Mark Sweep 是<code>整体 STW</code>，并且<em>分配速度慢</em>，<em>内存碎片率高</em>。</p><p><strong>标记过程</strong>需的要 <code>STW</code>，因为对象引用关系如果在标记阶段做了修改，会影响标记结果的正确性。</p><p>并发 GC 分为两层含义：</p><ul><li>  每个 <code>mark </code>或 <code>sweep ``本身是多个线程</code>(协程)执行的(<code>concurrent</code>)</li><li>  <code>mutator </code>和 <code>collector </code><em>同时运行</em>(<code>background</code>)</li></ul><p><em>concurrent 这一层是比较好实现的, GC 时整体进行STW，那么对象引用关系不会再改变，对 mark 或者sweep 任务进行分块，就能多个线程(协程) conncurrent 执行任务 mark 或 sweep</em>。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/mark-STW.png" class="" title="image-20210725141141348"><p>而对于 <code>backgroud </code>这一层, 也就是说 <code>mutator </code>和 <code>mark</code>，<code>sweep </code>同时运行，则相对复杂。</p><ul><li>  1.3以前的版本使用<strong>标记-清扫</strong>的方式，<em>整个过程都需要 STW</em>。</li><li>  1.3版本<strong>分离了标记和清扫</strong>的操作，<em>标记过程STW</em>，<em>清扫过程并发</em>执行。</li></ul><p><code>backgroup sweep</code> 是比较容易实现的，因为 mark 后，哪些对象是存活，哪些是要被 sweep 是已知的，sweep 的是不再引用的对象。sweep 结束前，这些对象不会再被分配到，所以 sweep 和 mutator 运行共存。无论全局还是栈不可能能访问的到这些对象，可以安全清理。</p><p>1.5版本在标记过程中使用<em>三色标记</em>法。标记和清扫都并发执行的，但<em>标记阶段的前后</em>需要 <code>STW</code> 一定时间来做 <em>GC 的准备工作</em>和<strong>栈的re-scan</strong>。</p><h1 id="Tri-color-Mark-amp-Sweep"><a href="#Tri-color-Mark-amp-Sweep" class="headerlink" title="Tri-color Mark &amp; Sweep"></a>Tri-color Mark &amp; Sweep</h1><h3 id="Tri-color-Mark-amp-Sweep-1"><a href="#Tri-color-Mark-amp-Sweep-1" class="headerlink" title="Tri-color Mark &amp; Sweep"></a>Tri-color Mark &amp; Sweep</h3><p>三色标记是对标记清除法的改进，标记清除法在整个执行时要求长时间 STW，Go 从1.5版本开始改为三色标记法，<strong>初始将所有内存标记为白色</strong>，然后将 <strong>roots 加入待扫描队列</strong>(<em>进入队列即被视为变成灰</em>色)，然后使用<em>并发 goroutine 扫描队列中的指针</em>，如果指针还引用了其他指针，那么<em>被引用的也进入队列</em>，<em>被扫描的对象视为黑色</em>。</p><ul><li>  <strong>白色</strong>对象：潜在的<code>垃圾</code>，其内存可能会被垃圾收集器回收。</li><li>  <strong>黑色</strong>对象：<code>活跃</code>的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象，<em>垃圾回收器不会扫描这些对象的子对象</em>。</li><li>  <strong>灰色</strong>对象 ：<code>活跃</code>的对象，因为存在指向白色对象的外部指针，<em>垃圾收集器会扫描这些对象的子对象</em>。</li></ul><h3 id="Tri-color-Marking"><a href="#Tri-color-Marking" class="headerlink" title="Tri-color Marking"></a>Tri-color Marking</h3><p>垃圾收集器从 <code>root </code><em>开始</em>然后跟随指针<em>递归整个内存空间</em>。分配于 <code>noscan </code>的 span 的对象, 不会进行扫描。然而，此过程不是由同一个 goroutine 完成的，每个指针都排队在工作池中。然后，先看到的被标记为工作协程的后台协程从该池中出队，扫描对象，然后将在其中找到的指针排入队列。</p><h3 id="Tri-color-Coloring"><a href="#Tri-color-Coloring" class="headerlink" title="Tri-color Coloring"></a>Tri-color Coloring</h3><p><strong>染色</strong>流程：</p><ul><li>  <em>一开始所有对象被认为是白色</em></li><li>  <em>根</em>节点(<code>stacks</code>，<code>heap</code>，<code>global variables</code>)<em>被染色为灰色</em></li></ul><p>一旦主流程走完，gc 会：</p><ul><li>  <em>选一个灰色对象，标记为黑色</em></li><li>  <em>遍历这个对象的所有指针，标记所有其引用的对象为灰色</em></li></ul><p>最终直到所有对象需要被染色。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/coloring-white.png" class="" title="image-20210725143944601"><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/coloring-grey.png" class="" title="image-20210725144023009"><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/coloring-black.png" class="" title="image-20210725144051380"><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/coloring-done.png" class="" title="image-20210725144137278"><p>标记结束后，<em>黑色对象是内存中正在使用的对象</em>，而<em>白色对象是要收集的对象</em>。由于s2的实例是在匿名函数中创建的，并且无法从堆栈访问，因此它保持为白色，可以清除。</p><p>颜色在内部实现原理：</p><p><em>每个 span 中有一个名为 <code>gcmarkBits </code>的位图属性，该属性跟踪扫描，并将相应的位设置为1</em>。</p><h1 id="Write-Barrier"><a href="#Write-Barrier" class="headerlink" title="Write Barrier"></a>Write Barrier</h1><h3 id="Wirte-Barrier"><a href="#Wirte-Barrier" class="headerlink" title="Wirte Barrier"></a>Wirte Barrier</h3><p>1.5版本在标记过程中使用三色标记法。<em>回收过程主要有四个阶段</em>，其中，<strong>标记</strong>和<strong>清扫</strong>都<em>并发执行</em>的，但标记阶段的前后需要 STW 一定时间来做<strong>GC 的准备工作</strong>和<strong>栈的 re-scan</strong>。</p><p>使用并发的垃圾回收，也就是多个 <code>Mutator </code>与 <code>Mark </code>并发执行，想要在并发或者增量的标记算法中保证正确性，我们需要达成以下<em>两种三色不变性</em>(<code>Tri-color invariant</code>)中的任意一种：</p><ul><li>  <strong>强三色</strong>不变性：<em>黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象</em>。</li><li>  <strong>弱三色</strong>不变性 ：<em>黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径</em>。</li></ul><p>也就是黑色到白色要么不可达，要么间接可达。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/change-pointer.png" class="" title="image-20210725145306181"><p>标记过程需要 STW，因为<em>对象引用关系如果在标记阶段做了修改，会影响标记结果的正确性</em>。<em>灰色对象 B 中包含指向白色对象 C 的指针 e，对象 C 尚未被扫描，此时，如有其他程序，将 e 指针从 B 对象中删除，并将指向对象 C 的新指针 f插入到黑色对象 A 中，由于对象 A 早已完成扫描，对象 C 就会一直保持白色状态直到被回收</em>。</p><p>可以看出，一个白色对象被黑色对象引用，是注定无法通过这个黑色对象来保证自身存活的，与此同时，如果所有能到达它的灰色对象与它之间的可达关系全部遭到破坏，那么这个白色对象必然会被视为垃圾清除掉。 故当上述两个条件同时满足时，就会出现对象丢失的问题。如果这个白色对象下游还引用了其他对象，并且这条路径是指向下游对象的唯一路径，那么他们也是必死无疑的。</p><p>为了防止这种现象的发生，最简单的方式就是 STW，直接禁止掉其他用户程序对对象引用关系的干扰，但是 STW 的过程有明显的资源浪费，对所有的用户程序都有很大影响，如何能在保证对象不丢失的情况下合理的尽可能的提高 GC 效率，减少 STW 时间呢？</p><h3 id="Dijkstra-写屏障"><a href="#Dijkstra-写屏障" class="headerlink" title="Dijkstra 写屏障"></a>Dijkstra 写屏障</h3><p><strong>插入屏障拦截</strong> <em>将白色指针插入黑色对象的操作，标记其对应对象为灰色状态</em>，这样就不存在黑色对象引用白色对象的情况了，满足强三色不变式，在插入指针 f 时将 C 对象标记为灰色。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/write-barrier.png" class="" title="image-20210725145657296"><p>如果对栈上的写做拦截，那么流程代码会非常复杂，并且性能下降会非常大，得不偿失。根据局部性的原理来说，其实我们程序跑起来，大部分的其实都是操作在栈上，函数参数啊、函数调用导致的压栈出栈、局部变量啊，协程栈，这些如果也弄起写屏障，那么可想而知了，根本就不现实，复杂度和性能就是越不过去的坎。</p><p>1、内存屏障只是对应一段特殊的代码；2、内存屏障这段代码在编译期间生成；3、内存屏障本质上在运行期间拦截内存写操作，相当于一个 <code>hook </code>调用</p><p>Go 团队在实现上选择了<em>在标记阶段完成时暂停程序</em>、<em>将所有栈对象标记为灰色并重新扫描</em>，在活跃 <code>goroutine </code>非常多的程序中，重新扫描的过程需要占用 10 ~ 100ms 的时间。</p><p>所以 Go 选择<strong>仅对堆上的指针插入增加写屏障</strong>，这样就会出现在扫描结束后，<em>栈上仍存在引用白色对象的情况，这时的栈是灰色的，不满足三色不变式，所以需要对栈进行重新扫描使其变黑，完成剩余对象的标记，这个过程需要 STW</em>。</p><p><strong>初始化 GC <strong>任务，包括</strong>开启写屏障</strong>(write barrier)和<strong>开启辅助 GC</strong>(mutator assist)，<strong>统计 root 对象</strong>的任务数量等，<em>这个过程需要 STW</em>。</p><p><strong>扫描</strong>所有 root 对象，包括<em>全局指针</em>和 g<em>oroutine(G) 栈上的指针</em>(<strong>扫描对应 G 栈时需停止该 G</strong>)，将其加入标记队列(灰色队列)，并<em>循环处理灰色队列</em>的对象，<em>直到灰色队列为空</em>，该过程后台并行执行。</p><p>完成<strong>标记</strong>工作，<strong>重新扫描(re-scan)全局指针和栈</strong>。因为 <code>Mark </code>和 <code>mutator </code>是并行的，所以在 Mark 过程中可能会有新的对象分配和指针赋值，这个时候就需要通过写屏障(write barrier)记录下来，<em>re-scan 再检查一下，这个过程也是会 STW 的</em>。按照标记结果回收所有的白色对象，该过程后台并行执行。</p><p>对未清扫的span进行清扫, 只有<em>上一轮的GC的清扫工作完成才可以开始新一轮的GC</em>。</p><p>如果发现扫描后<em>回收的速度跟不上分配的速度它依然会把⽤户逻辑暂停</em>，⽤户逻辑暂停了以后也就意味着不会有新的对象出现，同时<em>会把⽤户线程抢过来加⼊到垃圾回收⾥⾯加快垃圾回收的速度</em>。这样⼀来原来的并发还是变成了STW，还是得把⽤户线程暂停掉，要不然扫描和回收没完没了了停不下来，因为新分配对象⽐回收快，所以这种东⻄叫做辅助回收.</p><h3 id="Yuasa-删屏障"><a href="#Yuasa-删屏障" class="headerlink" title="Yuasa 删屏障"></a>Yuasa 删屏障</h3><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/delete-barrier.png" class="" title="image-20210725150635934"><p><em>删除屏障</em>也是<strong>拦截写操作</strong>的，但是是通过<strong>保护灰色对象到白色对象的路径不会断</strong>来实现的。如上图例中，<strong>在删除指针 e 时将对象 C 标记为灰色</strong>，这样 C 下游的所有白色对象，即使会被黑色对象引用，最终也还是会被扫描标记的，满足了弱三色不变式。这种方式的回收<em>精度低</em>，<em>一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮 GC 中被清理掉</em>。</p><h3 id="混合屏障"><a href="#混合屏障" class="headerlink" title="混合屏障"></a>混合屏障</h3><p>插入屏障和删除屏障各有优缺点，Dijkstra 的<em>插入写屏障</em>在<strong>标记开始时无需 STW</strong>，可直接开始，并发进行，但<strong>结束时需要 STW 来重新扫描栈</strong>，标记栈上引用的白色对象的存活；Yuasa 的<em>删除写屏障</em>则需要在 <strong>GC 开始时 STW 扫描堆栈来记录初始快照</strong>，这个过程会保护开始时刻的所有存活对象，但<em>结束时无需 STW</em>。</p><p>Golang 中的<em>混合写屏障</em>满足的是<em>变形的弱三色不变式</em>，同样允许<strong>黑色对象引用白色对象，白色对象处于灰色保护状态，但是只由堆上的灰色对象保护</strong>。</p><p>由于结合了 Yuasa 的删除写屏障和 Dijkstra 的插入写屏障的优点，只<em>需要在开始时并发扫描各个goroutine 的栈，使其变黑并一直保持</em>，这个过程<em>不需要 STW</em>，而<em>标记结束后</em>，因为<em>栈在扫描后始终是黑色的，也无需再进行 re-scan 操作了</em>，减少了 STW 的时间。</p><p>为了移除栈的重扫描过程，除了<strong>引入混合写屏障</strong>之外，在垃圾收集的<em>标记</em>阶段，我们还需要<strong>将创建的所有堆上新对象都标记成黑色</strong>，防止新分配的栈内存和堆内存中的对象被错误地回收，因为<em>栈内存在标记阶段最终都会变为黑色</em>，所以不再需要重新扫描栈空间。</p><h3 id="Sweep"><a href="#Sweep" class="headerlink" title="Sweep"></a>Sweep</h3><p>Sweep 让 Go 知道哪些内存可以重新分配使用，然而，<em>Sweep 过程并不会处理释放的对象内存置为0</em>(zeroing the memory)。而是在分配重新使用的时候，重新 reset bit。</p><p>每个 span 内有一个 <code>bitmap allocBits</code>，他表示<em>上一次 GC 之后每一个 object 的分配情况</em>，<strong>1：表示已分配，0：表示未使用或释放</strong>。</p><p>内部还使用了 uint64 allocCache(deBruijn)，加速寻找 <code>freeobject</code>。</p><p>GC 将会启动去<em>释放不再被使用的内存</em>。在标记期间，GC 会用一个位图 <code>gcmarkBits </code>来跟踪在使用中的内存。</p><p><em>正在被使用的内存被标记为黑色，然而当前执行并不能够到达的那些内存会保持为白色</em>。</p><p>现在，我们可以使用 <code>gcmarkBits </code>精确查看可用于分配的内存。Go 使用 gcmarkBits 赋值了 allocBits，这个操作就是内存清理。</p><p>然而必须每个 <code>span </code>都来一次类似的处理，需要耗费大量时间。Go 的目标是在<strong>清理内存时不阻碍执行</strong>，并为此提供了两种策略。</p><p>Go 提供<strong>两种</strong>方式来清理内存：</p><ul><li>  在<strong>后台</strong>启动一个<strong>worker 等待清理内存</strong>，<em>一个一个 mspan 处理</em></li></ul><p>当开始运行程序时，Go 将设置一个后台运行的 Worker(唯一的任务就是去清理内存)，它将<em>进入睡眠状态并等待内存段扫描</em>。</p><ul><li>  当<strong>申请分配内存时候 lazy 触发</strong></li></ul><p>当应用程序 <code>goroutine </code>尝试在<strong>堆内存中分配新内存</strong>时，会触发该操作。清理导致的延迟和吞吐量降低被分散到每次内存分配时。</p><p>清理内存段的第二种方式是<strong>即时执行</strong>。但是，由于这些内存段已经被分发到每一个处理器 P 的本地缓存 mcache 中，因此很难追踪首先清理哪些内存。这就是为什么 <strong>Go 首先将所有内存段移动到 mcentral 的原因</strong>。然后，它将会让本地缓存 mcache 再次请求它们，去即时清理。</p><p><strong>即时扫描</strong>确保<em>所有内存段都会得到清理</em>（节省资源），同时<strong>不会阻塞程序</strong>执行。</p><p>由于后台只有一个 <code>worker </code>在清理内存块，清理过程可能会花费一些时间。但是，我们可能想知道如果另一个 GC 周期在一次清理过程中启动会发生什么。在这种情况下，这个运行 GC 的 Goroutine 就会在开始标记阶段前去协助完成剩余的清理工作。</p><h1 id="Stop-The-World"><a href="#Stop-The-World" class="headerlink" title="Stop The World"></a>Stop The World</h1><h3 id="STW"><a href="#STW" class="headerlink" title="STW"></a>STW</h3><p>在垃圾回收机制 (GC) 中，”Stop the World” (STW) 是一个重要阶段。顾名思义， 在 “Stop the World” 阶段， 当前运行的所有程序将被暂停， <strong>扫描内存的 root 节点</strong>和**添加写屏障 (write barrier) **。</p><p>这个阶段的第一步， 是<em>抢占所有正在运行的 goroutine</em>，被抢占之后， 这些 goroutine 会被<em>悬停在一个相对安全的状态</em>。</p><p>处理器 P (无论是正在运行代码的处理器还是已在 idle 列表中的处理器)， 都会被被标记成<strong>停止状态</strong> (stopped)， 不再运行任何代码。 调度器把每<em>个处理器的 M  从各自对应的处理器 P 分离出来</em>， 放到 <em>idle 列表</em>中去。</p><p>对于 <code>Goroutine </code>本身， 他们会被放到一个<em>全局队列中等待</em>。</p><h3 id="Pacing"><a href="#Pacing" class="headerlink" title="Pacing"></a>Pacing</h3><p><strong>运行时中有 GC Percentage 的配置选项，默认情况下为100。</strong></p><p>此值表示在下一次垃圾收集必须启动之前可以分配多少新内存的比率。将 GC 百分比设置为100意味着，*基于在垃圾收集完成后标记为活动的堆内存量，下次垃圾收集前，堆内存使用可以增加100%*。</p><p><strong>如果超过2分钟没有触发，会强制触发 GC。</strong></p>]]></content>
      
      
      <categories>
          
          <category> Goroutine </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
            <tag> GC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Goroutine原理</title>
      <link href="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/"/>
      <url>/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Goroutine"><a href="#Goroutine" class="headerlink" title="Goroutine"></a>Goroutine</h1><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>“Goroutine 是一个与其他 goroutines 并行运行在同一地址空间的 Go 函数或方法。一个运行的程序由一个或更多个 goroutine 组成。它与线程、协程、进程等不同。它是一个 goroutine” —— Rob Pike</p><p><strong>Goroutines 在同一个用户地址空间里并行独立执行 functions，channels 则用于 goroutines 间的通信和同步访问控制。</strong></p><h3 id="goroutine-与thread有何区别"><a href="#goroutine-与thread有何区别" class="headerlink" title="goroutine 与thread有何区别"></a>goroutine 与thread有何区别</h3><ul><li><p><strong>内存占用</strong>，创建一个 goroutine 的栈内存消耗为 2 KB(Linux AMD64 Go v1.4后)，运行过程中，如果栈空间不够用，<strong>会自动进行扩缩容</strong>。<br>  <em>创建一个 thread 为了尽量避免极端情况下操作系统线程栈的溢出，默认会为其分配一个较大的栈内存( 1 - 8 MB 栈内存，线程标准 POSIX Thread)，而且还需要一个被称为 “guard page” 的区域用于和其他 thread 的栈空间进行隔离。而栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。</em></p></li><li><p><strong>创建/销毁</strong>，线程创建和销毀都会有巨大的消耗，是<strong>内核级的交互</strong>(trap)。<br>  <em>POSIX 线程(定义了创建和操纵线程的一套 API)通常是在已有的进程模型中增加的逻辑扩展，所以线程控制和进程控制很相似。而进入内核调度所消耗的性能代价比较高，开销较大。goroutine 是用户态线程，是由 go runtime 管理，创建和销毁的消耗非常小。</em></p></li><li><p><strong>调度切换</strong></p><pre><code>  抛开陷入内核，线程切换会消耗 1000-1500 纳秒(**上下文保存成本高，较多寄存器，公平性，复杂时间计算统计**)，一个纳秒平均可以执行 12-18 条指令。  所以由于线程切换，执行指令的条数会减少 12000-18000。goroutine 的切换约为 200 ns(用户态、3个寄存器，现在甚至达到了100~120ns)，相当于 2400-3600 条指令。因此，goroutines 切换**成本比 threads 要小得多**。</code></pre></li><li><p><strong>复杂性</strong></p><pre><code>  线程的**创建和退出**复杂，多个 thread 间**通讯**复杂(share memory)。  不能大量创建线程(参考早期的 httpd)，成本高，使用网络多路复用，存在大量`callback`(参考twemproxy、nginx 的代码)。对于应用服务线程门槛高，例如需要做第三方库隔离，需要考虑引入线程池等。</code></pre></li></ul><h3 id="M-N模型"><a href="#M-N模型" class="headerlink" title="M:N模型"></a>M:N模型</h3><p>Go 创建 M 个线程(CPU 执行调度的单元，内核的 task_struct)，之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行，即 M:N 模型。它们能够同时运行，与线程类似，但相比之下非常轻量。因此，<strong>程序运行时，Goroutines 的个数应该是远大于线程的个数的</strong>（phread 是内核线程？）。</p><p><strong>同一个时刻，一个线程只能跑一个 goroutine</strong>。<em>当 goroutine 发生阻塞 (chan 阻塞、mutex、syscall 等等) 时，Go 会把当前的 goroutine 调度走，让其他 goroutine 来继续执行，而不是让线程阻塞休眠，尽可能多的分发任务出去，让 CPU 忙</em>。</p><h1 id="GMP调度模型"><a href="#GMP调度模型" class="headerlink" title="GMP调度模型"></a>GMP调度模型</h1><h2 id="GMP概念"><a href="#GMP概念" class="headerlink" title="GMP概念"></a>GMP概念</h2><ul><li>  G </li></ul><p>goroutine 的缩写，每次 go func() 都代表一个 G，无限制。<br>使用 <code>struct runtime.g</code>，包含了当前 goroutine 的<strong>状态、堆栈、上下文</strong>。</p><ul><li>  M</li></ul><p>工作线程(<code>OS thread</code>)也被称为 Machine，使用 <code>struct runtime.m</code>，所有 M 是有<strong>线程栈</strong>的。<br>    如果不对该线程栈提供内存的话，系统会给该线程栈提供内存(不同操作系统提供的线程栈大小不同)。当指定了线程栈，则 <code>M.stack→G.stack</code>，M 的 PC 寄存器(下一个指令执行寄存器)指向 G 提供的函数，然后去执行。</p><ul><li>  P</li></ul><p><em>“Processor”是一个抽象的概念，并不是真正的物理 CPU。</em></p><p>Dmitry Vyukov 的方案是引入一个结构 P，它代表了 <em>M 所需的上下文环境</em>，也是处理<strong>用户级代码逻辑的处理器</strong>。它负责<strong>衔接 M 和 G 的调度上下文，将等待执行的 G 与 M 对接</strong>。当 P 有任务时需要<strong>创建</strong>或者<strong>唤醒</strong>一个 M 来执行它队列里的任务。所以 P/M 需要进行绑定，构成一个执行单元。P 决定了并行任务的数量，可通过 <code>runtime.GOMAXPROCS</code> 来设定。在 Go1.5 之后GOMAXPROCS 被默认设置可用的核数，而之前则默认为1。</p><p>Tips: <a href="https://github.com/uber-go/automaxprocs">https://github.com/uber-go/automaxprocs</a></p><p>Automatically set GOMAXPROCS to match Linux container CPU quota.</p><p><strong>mcache/stackalloc 从 M 移到了 P，而 G 队列也被分成两类，保留全局 G 队列，同时每个 P 中都会有一个本地的 G 队列。</strong></p><h3 id="GM调度器"><a href="#GM调度器" class="headerlink" title="GM调度器"></a>GM调度器</h3><p>Go 1.2前的调度器实现，限制了 Go 并发程序的伸缩性，尤其是对那些有高吞吐或并行计算需求的服务程序。</p><p>每个 goroutine 对应于 runtime 中的一个抽象结构：G，而 thread 作为“物理 CPU”的存在而被抽象为一个结构：M(machine)。当 goroutine 调用了一个阻塞的系统调用，运行这个 goroutine 的线程就会被阻塞，这时至少应该再创建/唤醒一个线程来运行别的没有阻塞的 goroutine。线程这里可以创建不止一个，可以按需不断地创建，而活跃的线程（处于非阻塞状态的线程）的最大个数存储在变量 GOMAXPROCS中。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/GM-Schedule.png" class="" title="image-20210718144120182"><h3 id="GM调度模型的问题"><a href="#GM调度模型的问题" class="headerlink" title="GM调度模型的问题"></a>GM调度模型的问题</h3><ul><li><p><strong>单一全局互斥锁</strong>(<code>Sched.Lock</code>)和<strong>集中状态存储</strong></p><pre><code>  导致所有 goroutine 相关操作，比如：创建、结束、重新调度等都要上锁。</code></pre></li><li><p><strong>Goroutine 传递</strong>问题</p><pre><code>   `M` 经常**在 M 之间**传递”可运行”的 goroutine，这导致**调度延迟增大**以及**额外的性能损耗**（*刚创建的 G 放到了全局队列，而不是本地 M 执行，不必要的开销和延迟*）。</code></pre></li><li><p><strong>Per-M 持有内存缓存</strong> (<code>M.mcache</code>)</p><pre><code>  每个 M 持有 `mcache `和 `stackalloc`，然而**只有在 M 运行 Go 代码时才需要使用内存**(每个 mcache 可以高达2mb)，**当 M 在处于 syscall 时并不需要这个内存**。运行 Go 代码和阻塞在 syscall 的 M 的比例高达`1:100`，造成了很大的浪费。同时**内存亲缘性也较差**，G 当前在 M 运行后对 M 的内存进行了预热，因为现在* G 调度到同一个 M 的概率不高，数据局部性不好*。</code></pre></li><li><p><strong>严重的线程阻塞/解锁</strong></p><pre><code>  在**系统调用**的情况下，工作线程**经常被阻塞和取消阻塞**，这增加了很多开销。比如 M 找不到G，此时 M 就会进入频繁阻塞/唤醒来进行检查的逻辑，以便及时发现新的 G 来执行。</code></pre><p>  <code>by Dmitry Vyukov “Scalable Go Scheduler Design Doc”</code></p></li></ul><h2 id="GMP调度器"><a href="#GMP调度器" class="headerlink" title="GMP调度器"></a>GMP调度器</h2><p>引入了<code> local queue</code>，因为 P 的存在，runtime 并不需要做一个集中式的 goroutine 调度，每一个 M 都会在 <code>P&#39;s local queue</code>、<code>global queue</code> 或者<code>其他 P 队列中找 G </code>执行，<em>减少全局锁对性能的影响</em>。</p><p>这也是 <code>GMP Work-stealing</code> 调度算法的核心。注意 P 的本地 G 队列还是可能面临一个并发访问的场景，为了避免加锁，这里 P 的本地队列是一个 <code>LockFree</code>的队列，窃取 G 时<strong>使用 CAS 原子操作</strong>来完成。关于LockFree 和 CAS 的知识参见 Lock-Free。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/GMP-schedule%E6%A8%A1%E5%9E%8B.png" class="" title="image-20210718145843014"><h1 id="Work-stealing调度算法"><a href="#Work-stealing调度算法" class="headerlink" title="Work-stealing调度算法"></a>Work-stealing调度算法</h1><h3 id="Work-stealing"><a href="#Work-stealing" class="headerlink" title="Work-stealing"></a>Work-stealing</h3><p><strong>当一个 P 执行完本地所有的 G 之后，并且全局队列为空的时候，会尝试挑选一个受害者 P，从它的 G 队列中窃取一半的 G。否则会从全局队列中获取(当前个数/GOMAXPROCS)个 G。</strong></p><p><strong>为了保证公平性，从随机位置上的 P 开始，而且遍历的顺序也随机化了(选择一个小于 GOMAXPROCS，且和它互为质数的步长)，保证遍历的顺序也随机化了。</strong></p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/work-stealing-p0.png" class="" title="image-20210718150126958"><p>光窃取失败时获取是不够的，可能会导致<strong>全局队列饥饿</strong>。P 的调度算法中还会<strong>每个 N (1/61 time)轮调度之后就去全局队列拿一个 G</strong>。</p><p>谁放入的全局队列呢？</p><p><em>新建 G 时 P 的本地 G 队列放不下已满并达到256个的时候会放半数 G 到全局队列去，阻塞的系统调用返回时找不到空闲 P 也会放到全局队列。</em></p><h3 id="Syscall"><a href="#Syscall" class="headerlink" title="Syscall"></a>Syscall</h3><p>调用 syscall 后<strong>M会解绑 P</strong>，然后**<code>M </code>和 <code>G</code> 进入<code>阻塞</code>*<em>，而 P 此时的状态就是 <code>syscall</code>，</em>表明这个 P 的 G 正在 syscall 中<em>，这时的 P 是</em>不能被调度给别的 M* 的。<em>如果在短时间内阻塞的 M 就唤醒了，那么 M 会优先来重新获取这个 P，能获取到就继续绑回去，这样有利于数据的局部性</em>。</p><p>系统监视器 (<code>system monitor</code>)，称为 <code>sysmon</code>，会<strong>定时扫描</strong>。在执行 syscall 时, 如果某个 P 的 G 执行超过一个<code> sysmon tick(10ms)</code>，就会把他设为 <code>idle</code>，<em>重新调度给需要的 M，强制解绑</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/syscall-handoffs-p-sysmon.png" class="" title="image-20210718152037397"><p>P1 和 M 脱离后目前在 idle list 中等待被绑定（处于 syscall 状态）。而 syscall 结束后 M 按照如下规则执行直到满足其中一个条件：</p><ol><li> 尝试<em>获取同一个 P</em>(P1)，恢复执行 G</li><li> 尝试<em>获取 idle list 中的其他空闲 P</em>，恢复执行 G</li><li> <em>找不到空闲 P，把 G 放回 global queue，M 放回到 idle list</em></li></ol><h3 id="Spining-thread"><a href="#Spining-thread" class="headerlink" title="Spining thread"></a>Spining thread</h3><p><em>线程自旋是相对于线程阻塞而言的</em>，表象就是循环执行一个指定逻辑(调度逻辑，目的是不停地寻找 G)。这样做的问题显而易见，如果 G 迟迟不来，<em>CPU 会白白浪费在这无意义的计算上</em>。但好处也很明显，<em>降低了 M 的上下文切换成本，提高了性能</em>。在两个地方引入自旋：</p><ul><li>  类型1：M 不带 P 的<strong>找 P</strong> 挂载（一有 P 释放就结合）</li><li>  类型2：M 带 P 的<strong>找 G</strong> 运行（一有 runable 的 G 就执行）</li></ul><p>为了避免过多浪费 CPU 资源，自旋的 M 数量最多只允许 <code>GOMAXPROCS (Busy P)</code>。同时当有类型1的自旋 M 存在时，类型2的自旋 M 就不阻塞，阻塞会释放 P，一释放 P 就马上被类型1的自旋 M 抢走了，没必要。</p><p>在<strong>新 G 被创建</strong>、<strong>M 进入系统调用</strong>、<strong>M 从空闲被激活</strong>这三种状态变化前，调度器会确保<strong>至少有一个自旋 M 存在</strong>（唤醒或者创建一个 M），<strong>除非没有空闲的 P</strong>。</p><ul><li><p>  <code>当新 G 创建，如果有可用 P，就意味着新 G 可以被立即执行，即便不在同一个 P 也无妨，所以我们保留一个自旋的 M（这时应该不存在类型1的自旋只有类型2的自旋）就可以保证新 G 很快被运行。</code></p></li><li><p>  <code>当 M 进入系统调用，意味着 M 不知道何时可以醒来，那么 M 对应的 P 中剩下的 G 就得有新的 M 来执行，所以我们保留一个自旋的 M 来执行剩下的 G（这时应该不存在类型2的自旋只有类型1的自旋）。</code></p></li><li><p>  <code>如果 M 从空闲变成活跃，意味着可能一个处于自旋状态的 M 进入工作状态了，这时要检查并确保还有一个自旋 M 存在，以防还有 G 或者还有 P 空着的。</code></p></li></ul><h3 id="GMP问题总结"><a href="#GMP问题总结" class="headerlink" title="GMP问题总结"></a>GMP问题总结</h3><ul><li><p><strong>单一全局互斥锁(Sched.Lock)和集中状态存储</strong></p><pre><code>  G 被分成全局队列和 P 的本地队列，*全局队列依旧是全局锁，但是使用场景明显很少，P 本地队列使用无锁队列，使用原子操作来面对可能的并发场景*。</code></pre></li><li><p><strong>Goroutine 传递问题</strong></p><pre><code>   *G 创建时就在 P 的本地队列*，可以避免在 G 之间传递（窃取除外），G 对 P 的数据局部性好; 当 G 开始执行了，系统调用返回后 M 会尝试获取可用 P，获取到了的话可以避免在 M 之间传递。**而且优先获取调用阻塞前的 P，所以 G 对 M 数据局部性好，G 对 P 的数据局部性也好。**</code></pre></li><li><p><strong>Per-M 持有内存缓存 (M.mcache)</strong></p><pre><code> *内存 mcache 只存在 P 结构中*，P 最多只有 GOMAXPROCS 个，远小于 M 的个数，所以内存没有过多的消耗。  </code></pre></li><li><p>严重的线程<strong>阻塞/解锁</strong></p><pre><code>  通过*引入自旋*，保证**任何时候都有处于等待状态的自旋 M**，避免**在等待可用的 P 和 G 时频繁的阻塞和唤醒**。</code></pre></li></ul><p><code>by Dmitry Vyukov “Scalable Go Scheduler Design Doc”</code></p><h3 id="sysmon"><a href="#sysmon" class="headerlink" title="sysmon"></a>sysmon</h3><p>sysmon 也叫<em>监控线程</em>，它<em>无需 P 也可以运行</em>，他是一个<em>死循环</em>，每<code>20us~10ms</code>循环一次，循环完一次就 <code>sleep </code>一会，为什么会是一个<strong>变动的周期</strong>呢，主要是<em>避免空转</em>，如果每次循环都没什么需要做的事，那么 sleep 的时间就会加大。</p><ul><li>  <strong>释放</strong>闲置超过5分钟的 <code>span </code><strong>物理内存</strong>；</li><li>  如果超过2分钟没有<strong>垃圾回收，强制执行</strong>；</li><li>  将长时间未处理的 <code>netpoll </code><em>添加到全局队列</em>；</li><li>  向长时间运行的 G 任务<strong>发出抢占调度</strong>；</li><li>  <strong>收回</strong>因 <code>syscall </code><strong>长时间阻塞的 P</strong>；</li></ul><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/preempt-by-sysmon.png" class="" title="image-20210718155407628"><p><em>当 P 在 M 上执行时间超过10ms</em>，<code>sysmon </code>调用 <code>preemptone </code>将 G 标记为 <code>stackPreempt </code>。因此需要在某个地方触发检测逻辑，Go 当前是在<strong>检查栈是否溢出的地方判定</strong>(<code>morestack</code>())，M 会保存当前 G 的上下文，重新进入调度逻辑。</p><p>死循环：issues/11462</p><p>信号抢占：go1.14基于信号的<em>抢占式调度</em>实现原理</p><p>异步抢占，注册 <code>sigurg </code>信号，通过 <code>sysmon </code>检测，对 M 对应的线程发送信号，触发注册的 handler，它往当前 G 的 PC 中插入一条指令(调用某个方法)，在处理完 handler，G 恢复后，自己把自己推到了 global queue 中。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/preempt-by-sysmon-sig.png" class="" title="image-20210718155635185"><h3 id="Network-poller"><a href="#Network-poller" class="headerlink" title="Network poller"></a>Network poller</h3><p>Go <strong>所有的 I/O 都是阻塞的</strong>。然后通过 <code>goroutine + channel</code> 来<em>处理并发</em>。因此所有的 IO 逻辑都是直来直去的，你不再需要回调，不再需要 future，要的仅仅是 step by step。这对于代码的可读性是很有帮助的。</p><p><em>G 发起网络 I/O 操作也不会导致 M 被阻塞(仅阻塞G)，从而不会导致大量 M 被创建出来</em>。<strong>将异步 I/O 转换为阻塞 I/O 的部分称为 netpoller</strong>。<em>打开或接受连接都被设置为非阻塞模式。如果你试图对其进行 I/O 操作，并且文件描述符数据还没有准备好，G 会进入 gopark 函数，将当前正在执行的 G 状态保存起来，然后切换到新的堆栈上执行新的 G。</em></p><p>那什么时候 G 被调度回来呢？</p><ul><li>  <code>sysmon</code></li><li>  <code>schedule()</code>：M 找 G 的调度函数</li><li>  <code>GC</code>：start the world</li></ul><p>调用 netpoll() 在某一次调度 G 的过程中，处于就绪状态的 fd 对应的 G 就会被调度回来。</p><p>G 的 gopark 状态：G 置为 waiting 状态，等待显示 goready 唤醒，在 poller 中用得较多，还有锁、chan 等。</p><h3 id="Schedule-Affinity"><a href="#Schedule-Affinity" class="headerlink" title="Schedule Affinity"></a>Schedule Affinity</h3><p>在 chan 来回通信的 goroutine 会导致频繁的 blocks，即频繁地在本地队列中重新排队。然而，由于本地队列是 FIFO 实现，如果另一个 goroutine 占用线程，unblock goroutine 不能保证尽快运行。同时 Go 亲缘性调度的一些限制：Work-stealing、系统调用。</p><p>goroutine #9 在 chan 被阻塞后恢复。但是，它必须等待#2、#5和#4之后才能运行。goroutine #5将阻塞其线程，从而延迟goroutine #9，并使其面临被另一个 P 窃取的风险。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/image-20210718160233704.png" class="" title="image-20210718160233704"><p>针对 communicate-and-wait 模式，进行了<strong>亲缘性调度</strong>的优化。Go 1.5 在 P 中引入了 <code>runnext </code>特殊的一个字段，可以<strong>高优先级执行 unblock G</strong>。</p><p><em>goroutine #9现在被标记为下一个可运行的</em>。<strong>这种新的优先级排序允许 goroutine 在再次被阻塞之前快速运行</strong>。这一变化对运行中的标准库产生了总体上的积极影响，提高了一些包的性能。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/affinity-schedule.png" class="" title="image-20210718160318778"><h1 id="Goroutine-Lifecycle"><a href="#Goroutine-Lifecycle" class="headerlink" title="Goroutine Lifecycle"></a>Goroutine Lifecycle</h1><h3 id="Go程序启动"><a href="#Go程序启动" class="headerlink" title="Go程序启动"></a>Go程序启动</h3><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/runtime-main.png" class="" title="image-20210718160426412"><p>整个程序始于一段汇编，而在随后的<code> runtime·rt0_go</code>（也是汇编程序）中，会执行很多初始化工作。</p><ul><li>  <strong>绑定 m0 和 g0</strong>，<code>m0</code>就是<strong>程序的主线程</strong>，程序启动必然会拥有一个主线程，这个就是 m0。<code>g0</code> <strong>负责调度</strong>，即 <code>shedule() 函数</code>。</li><li><strong>创建 P</strong>，<strong>绑定 m0 和 p0</strong>，首先会<code>创建 GOMAXPROCS 个 P</code> ，存储在 <code>sched </code>的 <code>空闲链表(pidle)</code>。<br>  新建任务 <em>g 到 p0 本地队列</em>，<em>m0 的 g0 会创建一个 指向 runtime.main() 的 g</em> ，并<em>放到 p0 的本地队列</em>。</li><li>  <strong>runtime.main()</strong>: 启动 <code>sysmon </code>线程；启动 <code>GC</code> <code>协程</code>；执行 <code>init</code>，即代码中的各种 init 函数；执行 <code>main.main</code>(用户程序main) 函数。</li></ul><h3 id="OS-thread-创建"><a href="#OS-thread-创建" class="headerlink" title="OS thread 创建"></a>OS thread 创建</h3><p>准备运行的<strong>新 goroutine 将唤醒 P</strong> 以更好地分发工作。这个 <strong>P 将创建一个与之关联的 M 绑定到一个 OS thread</strong>。</p><p>go func() 中 触发 <code>Wakeup </code>唤醒机制：</p><p>有空闲的 P 而没有在 <code>spinning </code>状态的 M 时候, 需要去<strong>唤醒</strong>一个*空闲(睡眠)的 M *或者<strong>新建</strong>一个。当线程首次创建时，会执行一个特殊的 G，即 <em>g0，它负责管理和调度 G</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/OS-thread.png" class="" title="image-20210718160954428"><h3 id="g0"><a href="#g0" class="headerlink" title="g0"></a>g0</h3><p> Go 基于<em>两种断点将 G 调度到线程</em>上： </p><ul><li>  当<strong>G 阻塞</strong>时：系统调用、互斥锁或 chan。阻塞的 G 进入睡眠模式/进入队列，并允许 Go 安排和运行等待其他的 G。</li><li>  在<strong>函数调用期间</strong>，如果 G 必须<strong>扩展其堆栈</strong>。这个断点允许 Go 调度另一个 G 并避免运行 G 占用 CPU。</li></ul><p>在这两种情况下，<strong>运行调度程序的 g0 将当前 G 替换为另一个 G</strong>，即 ready to run。然后，选择的 G 替换 g0 并在线程上运行。与常规 G 相反，<strong>g0 有一个固定和更大的栈</strong>。</p><ul><li>  Defer 函数的分配</li><li>  GC 收集，比如 STW、扫描 G 的堆栈和标记、清除操作</li><li>  栈扩容，当需要的时候，由 g0 进行扩栈操作</li></ul><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/G0-schedule.png" class="" title="image-20210718161445297"><h3 id="Schedule"><a href="#Schedule" class="headerlink" title="Schedule"></a>Schedule</h3><p>在 Go 中，G 的切换相当轻便，其中需要<strong>保存的状态</strong>仅仅涉及以下<em>两个</em>：</p><ul><li>  Goroutine 在<em>停止运行前执行的指令</em>，程序<em>当前要运行的指令</em>是<em>记录在程序计数器（PC）中</em>的， G 稍后将在同一指令处恢复运行；</li><li>  G 的<em>堆栈</em>，以便在再次运行时<em>还原局部变量</em>；</li></ul><p>在切换之前，堆栈将被保存，以便在 G 再次运行时进行恢复.</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/schedule-time.png" class="" title="image-20210718161747355"><p>从 g 到 g0 或从 g0 到 g 的切换是相当迅速的，它们<em>只包含少量固定的指令</em>。相反，对于调度阶段，<strong>调度程序需要检查许多资源以便确定下一个要运行的 G</strong>。</p><ul><li>  当前 g 阻塞在 chan 上并切换到 g0：1、PC 和堆栈指针一起保存在内部结构中；2、将 g0 设置为正在运行的 goroutine；3、g0 的堆栈替换当前堆栈；</li><li>  g0 寻找新的 Goroutine 来运行</li><li>  g0 使用所选的 Goroutine 进行切换： 1、PC 和堆栈指针是从其内部结构中获取的；2、程序跳转到对应的 PC 地址；</li></ul><h3 id="Goroutine-Recycle"><a href="#Goroutine-Recycle" class="headerlink" title="Goroutine Recycle"></a>Goroutine Recycle</h3><p>G 很容易创建，栈很小以及快速的上下文切换。基于这些原因，开发人员非常喜欢并使用它们。然而，一个产生许多 <code>shortlive</code> 的 G 的程序<em>将花费相当长的时间来创建和销毁它们</em>。</p><p>每个 P 维护一个 <code>freelist G</code>，保持这个列表是<em>本地的</em>，这样做的好处是不使用任何锁来 push/get 一个空闲的 G。<em>当 G 退出当前工作时，它将被 push 到这个空闲列表中</em>。</p><p>为了更好地分发空闲的 G ，<strong>调度器</strong>也有自己的列表。它实际上有两个列表：<strong>一个包含已分配栈的 G，另一个包含释放过堆栈的 G（无栈）</strong>。</p><p>锁保护 central list，因为任何 M 都可以访问它。当本地列表长度超过64时，调度程序持有的列表从 P 获取 G。然后一半的 G 将移动到中心列表。需求回收 G 是一种节省分配成本的好方法。但是，由于堆栈是动态增长的，现有的G 最终可能会有一个大栈。因此，<em>当堆栈增长（即超过2K）时，Go 不会保留这些栈</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/go-recycle.png" class="" title="image-20210718162414057">]]></content>
      
      
      <categories>
          
          <category> Goroutine </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
            <tag> GMP </tag>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>go内存分配原理</title>
      <link href="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/"/>
      <url>/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="堆栈与逃逸分析"><a href="#堆栈与逃逸分析" class="headerlink" title="堆栈与逃逸分析"></a>堆栈与逃逸分析</h1><h3 id="堆栈定义"><a href="#堆栈定义" class="headerlink" title="堆栈定义"></a>堆栈定义</h3><p>Go 有两个地方可以分配内存：一个<strong>全局堆空间</strong>用来<em>动态分配</em>内存，另一个是每个 <code>goroutine </code>都有的<strong>自身栈空间</strong>。</p><h4 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h4><p> 栈区的内存一般由<strong>编译器自动进行分配和释放</strong>，其中存储着函数的<strong>入参</strong>以及<strong>局部</strong>变量，这些参数会随着函数的创建而创建，函数的返回而销毁。(通过 <code>CPU push &amp; release</code>)。<br>    <em>A function has direct access to the memory inside its frame, through the frame pointer, but access to memory outside its frame requires indirect access.</em></p><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>堆区的内存一般由<strong>编译器和工程师</strong>自己共同进行管理<strong>分配</strong>，交给 <code>Runtime GC</code> 来<strong>释放</strong>。堆上分配必须找到一块足够大的内存来存放新的变量数据。后续释放时，<em>垃圾回收器扫描堆空间寻找不再被使用的对象</em>。<br>    Anytime a value is shared outside the scope of a function’s stack frame, it will be placed (or allocated) on the heap.<br>栈分配廉价，堆分配昂贵。stack allocation is cheap and heap allocation is expensive.</p><h3 id="变量到底在堆还是栈上？"><a href="#变量到底在堆还是栈上？" class="headerlink" title="变量到底在堆还是栈上？"></a>变量到底在堆还是栈上？</h3><p>写过其他语言，比如 C 的同学都知道，有明确的栈和堆的相关概念。而 Go 声明语法并没有提到栈和堆，而是交给 Go 编译器决定在哪分配内存，保证程序的正确性，在 Go FAQ 里面提到这么一段解释：</p><p>从正确的角度来看，你不需要知道。Go 中的每个变量只要有引用就会一直存在。变量的存储位置(堆还是栈)和语言的语义无关。</p><p>存储位置对于写出高性能的程序确实有影响。如果可能，Go 编译器将为该函数的堆栈侦(stack frame)中的函数分配本地变量。但是如果编译器在函数返回后<strong>无法证明变量未被引用</strong>，则编译器必须在会被垃圾回收的堆上分配变量以避免悬空指针错误。此外，如果<em>局部变量非常大，将它存储在堆而不是栈上可能更有意义</em>。</p><p>在当前编译器中，<em>如果变量存在取址，则该变量是堆上分配的候选变量</em>。但是基础的<em>逃逸分析</em>可以将那些生存不超过函数返回值的变量识别出来，并且因此可以分配在栈上。</p><h3 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h3><p>“通过<strong>检查变量的作用域</strong>是否<strong>超出了它所在的栈</strong>来决定是否将它分配在堆上”的技术，其中“变量的作用域超出了它所在的栈”这种行为即被称为逃逸。逃逸分析在大多数语言里属于静态分析：在编译期由静态代码分析来决定一个值是否能被分配在栈帧上，还是需要“逃逸”到堆上。</p><ul><li><p>  <em>减少 GC 压力</em>，栈上的变量，随着函数退出后系统直接回收，不需要标记后再清除</p></li><li><p>  <em>减少内存碎片</em>的产生</p></li><li><p>  <em>减轻分配堆内存的开销</em>，提高程序的运行速度</p></li></ul><p>可以通过命令<code>go build -gcflags -m</code>发现变量是否逃逸到堆上。</p><h3 id="超过栈帧-stack-frame"><a href="#超过栈帧-stack-frame" class="headerlink" title="超过栈帧(stack frame)"></a>超过栈帧(stack frame)</h3><p>当一个函数被调用时，会在<strong>两个相关的帧边界</strong>间<strong>进行上下文切换</strong>。从调用函数切换到被调用函数，<em>如果函数调用时需要传递参数，那么这些参数值也要传递到被调用函数的帧边界中</em>。<em><strong>Go 语言中帧边界间的数据传递是按值传递的</strong></em>。任何在函数 <code>getRandom </code>中的变量在函数返回时，都将不能访问。<em>Go 查找所有变量超过当前函数栈侦的，把它们分配到堆上，避免 outlive 变量</em>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-stack.png" class="" title="image-20210722225325976"><p>上述情况中，num 变量不能指向之前的栈。</p><p>Go 查找所有变量超过当前函数栈侦的，把它们分配到堆上，避免 outlive 变量。</p><p>变量 tmp 在栈上分配，但是它包含了指向堆内存的地址，所以可以安全的从一个函数的栈侦复制到另外一个函数的栈帧。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/heap-alloc.png" class="" title="image-20210722225623130"><h3 id="逃逸案例"><a href="#逃逸案例" class="headerlink" title="逃逸案例"></a>逃逸案例</h3><p>还存在大量其他的 case 会出现逃逸，比较典型的就是 “<strong>多级间接赋值容易导致逃逸</strong>”，这里的多级间接指的是，<em>对某个引用类对象中的引用类成员进行赋值</em>（记住公式 <code>Data.Field = Value</code>，如果 Data, Field 都是引用类的数据类型，则会导致 Value 逃逸。这里的等号 = 不单单只赋值，也表示参数传递）。Go 语言中的引用类数据类型有 <code>func</code>, <code>interface</code>, <code>slice</code>, <code>map</code>, <code>chan</code>, <code>*Type</code> ：</p><ul><li>  一个值被分享到函数栈帧范围之外</li><li>  在 for 循环外申明，在 for 循环内分配，同理闭包</li><li>  发送指针或者带有指针的值到 channel 中</li><li>  在一个切片上存储指针或带指针的值</li><li>  slice 的背后数组被重新分配了</li><li>  在 interface 类型上调用方法</li></ul><p>….<strong>go build -gcflags ‘-m’</strong></p><h1 id="连续栈"><a href="#连续栈" class="headerlink" title="连续栈"></a>连续栈</h1><p>Go 应用程序运行时，<em>每个 goroutine 都维护着一个自己的栈区</em>，这个栈区只能自己使用不能被其他 goroutine 使用。<em>栈区的初始大小是2KB</em>(比 x86_64 架构下线程的默认栈2M 要小很多)，在 goroutine 运行的时候栈区会按<strong>照需要增长和收缩</strong>，占用的内存最大限制的默认值在64位系统上是<strong>1GB</strong>。</p><ul><li>  v1.0 ~ v1.1 — 最小栈内存空间为 4KB</li><li>  v1.2 — 将最小栈内存提升到了 8KB</li><li>  v1.3 — 使用连续栈替换之前版本的分段栈</li><li>  v1.4 — 将最小栈内存降低到了 2KB</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/segmented-stack.png" class="" title="image-20210722230300734"><h3 id="Hot-split问题"><a href="#Hot-split问题" class="headerlink" title="Hot split问题"></a>Hot split问题</h3><p>分段栈的实现方式存在 “<code>hot split</code>” 问题，如果栈快满了，那么下一次的函数调用会强制触发栈扩容。当函数返回时，新分配的 “stack chunk” 会被清理掉。如果这个函数调用产生的范围是在一个循环中，<em>会导致严重的性能问题，频繁的 alloc/free</em>。</p><p>Go 不得不在1.2版本把栈默认大小改为8KB，降低触发热分裂的问题，但是每个 goroutine 内存开销就比较大了。<em>直到实现了连续栈(contiguous stack)，栈大小才改为2KB</em>。 </p><h3 id="连续栈-Contigous-stacks"><a href="#连续栈-Contigous-stacks" class="headerlink" title="连续栈(Contigous stacks)"></a>连续栈(Contigous stacks)</h3><p>采用<strong>复制栈</strong>的实现方式，在热分裂场景中不会频发释放内存，即不像分配一个新的内存块并链接到老的栈内存块，而是<strong>会分配一个两倍大的内存块并把老的内存块内容复制到新的内存块里</strong>，当栈缩减回之前大小时，我们不需要做任何事情。</p><ul><li>  <code>runtime.newstack</code> <strong>分配</strong>更大的栈内存空间</li><li>  <code>runtime.copystack</code> 将旧栈中的内容<strong>复制</strong>到新栈中</li><li>  <strong>将指向旧栈对应变量的指针重新指向新栈</strong></li><li>  <code>runtime.stackfree</code> <strong>销毁</strong>并<strong>0</strong>旧栈的内存空间</li></ul><p>如果栈区的空间<strong>使用率不超过1/4</strong>，那么在<strong>垃圾回收</strong>的时候使用 <code>runtime.shrinkstack</code> 进行<strong>栈缩容</strong>，同样使用 <code>copystack</code>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/Contigous-stacks.png" class="" title="image-20210722230846677"><h3 id="栈扩容"><a href="#栈扩容" class="headerlink" title="栈扩容"></a>栈扩容</h3><p>Go <strong>运行时</strong>判断栈空间是否足够，所以在 <code>call function</code> 中会插入 <code>runtime.morestack</code>，但每个函数调用都判定的话，成本比较高。在编译期间通过计算 <code>sp、func stack framesize</code> 确定需要<strong>哪个函数调用中插入 runtime.morestack</strong>。</p><ul><li>  当函数是<strong>叶子节点</strong>，且<strong>栈帧小于等于 112</strong> ，不插入指令</li><li>  当<strong>叶子函数</strong>栈帧大小为 <code>120 -128</code> 或者 <strong>非叶子函数</strong>栈帧大小为 <code>0 -128</code>，<code>SP &lt; stackguard0</code></li><li>当函数栈帧大小为 <code>128 - 4096</code><pre><code>  `SP - framesize &lt; stackguard0 - StackSmall`</code></pre></li><li>大于 <code>StackBig</code><pre><code> ` SP-stackguard+StackGuard &lt;= framesize + (StackGuard-StackSmall)`</code></pre></li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/add-stacks.png" class="" title="image-20210722231223193"><h1 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h1><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><p><code>TCMalloc </code>是 <code>Thread Cache Malloc</code> 的简称，是Go 内存管理的起源，Go的内存管理是借鉴了TCMalloc：</p><ul><li><strong>内存碎片</strong><pre><code>  随着内存不断的申请和释放，内存上会存在大量的碎片，降低内存的使用率。为了解决内存碎片，可以**将2个连续的未使用的内存块合并，减少碎片**。</code></pre></li><li><strong>大锁</strong><pre><code>  同一进程下的所有线程共享相同的内存空间，它们申请内存时需要加锁，如果不加锁就存在同一块内存被2个线程同时访问的问题。</code></pre></li></ul><h3 id="内存布局"><a href="#内存布局" class="headerlink" title="内存布局"></a>内存布局</h3><p>需要先知道几个重要的概念：</p><ul><li>  <code>page</code>: 内存<strong>页</strong>，一块 <code>8K</code> 大小的内存空间。<strong>Go 与操作系统</strong>之间的内存<strong>申请和释放</strong>，都是以 <code>page </code>为单位的。</li><li>  <code>span</code>: 内存<strong>块</strong>，<em>一个</em>或<em>多个连续的 page 组成一个 span</em>。</li><li>  <code>sizeclass</code>: <em>空间规格</em>，每个 <code>span </code>都<em>带有</em>一个 <code>sizeclass</code>，标记着该 span 中的 page 应该如何使用。</li><li>  <code>object</code>: <em>对象</em>，用来存储一个变量数据内存空间，<em>一个 span 在初始化时，会被切割成一堆等大的 object</em>。假设 object 的大小是 16B，span 大小是 8K，那么就会把 span 中的 page 就会被初始化 8K / 16B = 512 个 object。</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/span-size-classes.png" class="" title="image-20210722233429021"><h3 id="小于32kb内存分配"><a href="#小于32kb内存分配" class="headerlink" title="小于32kb内存分配"></a>小于32kb内存分配</h3><p>当程序里发生了 32kb 以下的小块内存申请时，Go 会从一个叫做的 <code>mcache </code>的<strong>本地缓存</strong>给程序分配内存。这样的一个内存块里叫做 <code>mspan</code>，它是要给程序分配内存时的分配单元。</p><p>在 Go 的调度器模型里，每个线程  M 会绑定给一个处理器 P，在<strong>单一粒度的时间里只能最多处理运行一个 goroutine</strong>，<strong>每个 P</strong> 都会<strong>绑定一个</strong>上面说的本地缓存 <code>mcache</code>。当需要进行内存分配时，当前运行的 <code>goroutine </code>会从 <code>mcache </code>中查找可用的 <code>mspan</code>。从本地 <code>mcache </code>里<em>分配</em>内存时<strong>不需要加锁</strong>，这种分配策略效率更高。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/alloc-with-mcache.png" class="" title="image-20210722233807537"><p>申请内存时都分给他们一个 <code>mspan </code>这样的单元会不会产生浪费。其实 <code>mcache </code>持有的这一系列的<code>mspan </code>并不都是统一大小的，而是按照大小，从<code>8b 到 32kb </code>分了大概 <strong>67*2</strong> 类的 <code>mspan</code>。</p><p>每个内存页分为<strong>多级固定大小</strong>的“空闲列表”，这有助于减少碎片。类似的思路在<code> Linux Kernel</code>、<code>Memcache </code>都可以见到 <code>Slab-Allactor</code>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/alloc-with-mcache1.png" class="" title="image-20210722233953150"><p>如果分配内存时 <code>mcachce </code>里<strong>没有空闲的对口 sizeclass 的 mspan</strong> 了，Go 里还为每种类别的 <code>mspan </code>维护着一个 <code>mcentral</code>。</p><p><code>mcentral </code>的作用是<strong>为所有 mcache 提供切分好的 mspan 资源</strong>。每个 <code>central </code>会持有一种<em>特定大小</em>的<strong>全局 mspan 列表</strong>，包括<em>已分配</em>出去的和<em>未分配</em>出去的。 每个 <code>mcentral </code>对应一种 <code>mspan</code>，当<strong>工作线程</strong>的 <code>mcache </code>中没有合适(也就是特定大小的)的mspan 时就<strong>会从 mcentral 去获取</strong>。</p><p><code>mcentral </code>被<em>所有的工作线程</em><strong>共同享有</strong>，存在多个 <strong>goroutine 竞争</strong>的情况，因此从 mcentral 获取资源时<strong>需要加锁</strong>。mcentral 里维护着两个双向链表，<code>nonempty </code>表示链表里还有<em>空闲的 mspan 待分配</em>。<code>empty</code> 表示这条链表里的 <em>mspan 都被分配了</em><code>object </code>或缓存 <code>mcache </code>中。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/central-lists-mspan.png" class="" title="image-20210722234358905"><p>程序申请内存的时候，mcache 里已经没有合适的空闲 mspan了，那么工作线程就会像下图这样去 mcentral 里去申请。<code>mcache </code>从 <code>mcentral </code><em>获取</em>和<em>归还</em> <code>mspan </code>的流程：</p><ul><li>  <strong>获取</strong> <em>加锁</em>；从 <code>nonempty </code>链表<em>找到一个可用的mspan</em>；并将其<em>从 nonempty 链表删除</em>；将取出的 <em>mspan 加入到 empty</em> 链表；将 <em>mspan 返回给工作线程</em>；<em>解锁</em>。</li><li>  <strong>归还</strong> <em>加锁</em>；将 <code>mspan </code>从 <code>empty </code>链表<em>删除</em>；将<code>mspan </code><em>加入</em>到 <code>nonempty </code>链表；<em>解锁</em>。</li></ul><p><code>mcentral </code>是 sizeclass 相同的 span 会以链表的形式组织在一起, 就是指该 span 用来存储哪种大小的对象。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/span-replace-from-central.png" class="" title="image-20210722234818604"><p>当 <strong>mcentral 没有空闲的 mspan 时，会向 mheap 申请</strong>。而 <strong>mheap 没有资源时，会向操作系统申请新内存</strong>。mheap 主要用于<em>大对象</em>的内存分配，以及<em>管理未切割的 mspan</em>，用于给 mcentral 切割成小对象。<br>mheap 中含有<em>所有规格的 mcentral</em>，所以<em>当一个 mcache 从 mcentral 申请 mspan 时，只需要在独立的 mcentral 中使用锁，并不会影响申请其他规格的 mspan</em>。</p><p>所有 <code>mcentral </code>的<em>集合</em>则是<em>存放于</em> <code>mheap </code>中的。 <code>mheap </code>里的 <code>arena </code>区域是<strong>真正的堆区</strong>，运行时会将 <code>8KB</code> 看做<em>一页</em>，这些内存页中存储了所有在<strong>堆上初始化的对象</strong>。运行时使用二维的 <code>runtime.heapArena</code> 数组管理所有的内存，每个 <code>runtime.heapArena</code> 都会<strong>管理 64MB 的内存</strong>。<br>如果 arena 区域没有足够的空间，会调用 <code>runtime.mheap.sysAlloc</code> 从<em>操作系统中申请</em>更多的内存。（如下图：Go 1.11 前的内存布局）</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-strcuture.png" class="" title="image-20210722235715115"><p>图中的空间大小，是 Go 向操作系统申请的虚拟内存地址空间，操作系统会将该段地址空间预留出来不做它用；而不是真的创建出这么大的虚拟内存，在页表中创建出这么大的映射关系。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/scan.png" class="" title="image-20210722235921766"><h3 id="小于16byte内存分配"><a href="#小于16byte内存分配" class="headerlink" title="小于16byte内存分配"></a>小于16byte内存分配</h3><p>对于<strong>小于16字节</strong>的对象(且<strong>无指针</strong>)，Go 语言将其划分为了<code>tiny </code>对象。划分 <code>tiny </code>对象的主要目的是为了<strong>处理极小的字符串</strong>和<strong>独立的转义变量</strong>。对 json 的基准测试表明，使用 tiny 对象减少了12%的分配次数和20%的堆大小。tiny 对象会被放入<code>class </code>为<em>2</em>的 <code>span </code>中。</p><ul><li>  首先<em>查看</em>之前分配的元素中是否<em>有空余的空间</em></li><li>  如果当前要分配的<em>大小不够</em>，例如要分配16字节的大小，这时就需要<em>找到下一个</em>空闲的元素</li></ul><p><code>tiny </code>分配的第一步是<strong>尝试利用分配过的前一个元素的空间</strong>，达到<em>节约内存</em>的目的。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/tiny-memory.png" class="" title="image-20210723000345774"><h3 id="大于32kb内存分配"><a href="#大于32kb内存分配" class="headerlink" title="大于32kb内存分配"></a>大于32kb内存分配</h3><p>Go 没法使用工作线程的本地缓存 <code>mcache </code>和全局中心缓存 <code>mcentral </code>上管理<em>超过32KB的内存</em>分配，所以对于那些超过32KB的内存申请，会直接从堆上(<code>mheap</code>)上分配<em>对应的数量</em>的内存页(<em>每页大小是8KB</em>)给程序。</p><ul><li>  <code>freelist</code></li><li>  <code>treap</code></li><li>  <code>radix tree + pagecache</code></li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/large-memory-alloc.png" class="" title="image-20210723001300487"><h3 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h3><p>一般<em>小对象</em>通过 <code>mspan </code><em>分配内存</em>；<em>大对象</em>则直接由 <code>mheap </code><em>分配</em>内存。</p><ul><li>  Go 在程序<em>启动时</em>，会向<em>操作系统申请一大块内存</em>，由 <em>mheap 结构全局管理</em>(现在 Go 版本不需要连续地址了，所以不会申请一大堆地址，多个64M内存组成)</li><li>  Go 内存管理的<em>基本单元</em>是 <code>mspan</code>，<em>每种 mspan 可以分配特定大小的 object</em></li><li>  <code>mcache</code>, <code>mcentral</code>, <code>mheap </code>是 Go 内存管理的三大组件，<code>mcache </code>管理线程在<em>本地缓存</em>的 <code>mspan</code>；<code>mcentral </code>管理<em>全局的 mspan</em>供所有线程</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-alloc.png" class="" title="image-20210723001733960"><p>1、使用<strong>缓存提高效率</strong>。在存储的整个体系中到处可见缓存的思想，Go 利用缓存一是<strong>减少了系统调用</strong>的次数，二是<strong>降低了锁的粒度</strong>、<strong>减少加锁的次数</strong>。</p><p>2、以<strong>空间换时间</strong>，提高<strong>内存管理效率</strong>。空间换时间是一种常用的性能优化思想，这种思想其实非常普遍，比如<code>Hash</code>、<code>Map</code>、<code>二叉排序树</code>等数据结构的本质就是空间换时间。</p>]]></content>
      
      
      <categories>
          
          <category> Goroutine </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
            <tag> Heap </tag>
            
            <tag> Stack </tag>
            
            <tag> Memory </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
