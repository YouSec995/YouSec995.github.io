<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YouSec</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-08-22T09:29:12.752Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>yousec</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>操作系统笔记之内核初始化</title>
    <link href="http://example.com/2021/08/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%86%85%E6%A0%B8%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
    <id>http://example.com/2021/08/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%86%85%E6%A0%B8%E5%88%9D%E5%A7%8B%E5%8C%96/</id>
    <published>2021-08-22T09:24:57.000Z</published>
    <updated>2021-08-22T09:29:12.752Z</updated>
    
    <content type="html"><![CDATA[<h1 id="内核的初始化"><a href="#内核的初始化" class="headerlink" title="内核的初始化"></a>内核的初始化</h1><p>内核初始化，就是我们操作系统的内核初始化。那么操作系统初始化需要初始化哪些东西？是按照什么步骤进行的？带着孜孜不倦的态度去探索了…</p><p>先来个大概的印象：</p><img src="/2021/08/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%86%85%E6%A0%B8%E5%88%9D%E5%A7%8B%E5%8C%96/%E5%86%85%E6%A0%B8%E5%88%9D%E5%A7%8B%E5%8C%96%E5%86%85%E5%AE%B9.png" class="" title="image-20210822154947311"><p>从中可以知道初始化的内容包含进程初始化（0、1、2）、中断处理初始化、内存管理初始化、调度管理初始化。</p><h3 id="进程初始化"><a href="#进程初始化" class="headerlink" title="进程初始化"></a>进程初始化</h3><p>首先，OS的目的是为了处理各种进程，但是OS本身也可以看做是一个跟CPU等硬件打交道的进程，因此在操作系统中必须先有一个进程：<strong>0号进程</strong>。这是OS创建的第一个进程，也是进程列表中的第一个进程。通过指令<code>set_task_end_magic(&amp;init_task)</code>来创建。OS中我们知道创建进程都是通过fork或者kernel_thread产生进程，但这个进程却不是，它也是唯一一个不是的。而进程列表（Process List）可以看做一个管理进程的工具，里面存放着所有的进程。</p><h3 id="中断初始化"><a href="#中断初始化" class="headerlink" title="中断初始化"></a>中断初始化</h3><p>在有了进程之后，我们如果有进程进行了中断或者其他处理，那么就需要进程系统调用，而系统调用也是通过发送中断的方式进行的。这就需要进行中断的初始化，通过函数<code>trap_init()</code>进行初始化，里面设置好了很多<strong>中断门</strong>。</p><h3 id="内存初始化"><a href="#内存初始化" class="headerlink" title="内存初始化"></a>内存初始化</h3><p>同样，进程的运行离不开内存（各种代码啊数据啊等等等），所以需要内存的初始化。通过函数<code>mm_init()</code>来初始化内存管理。</p><h3 id="调度初始化"><a href="#调度初始化" class="headerlink" title="调度初始化"></a>调度初始化</h3><p>进程在运行中可能会需要切换，这时候就需要对进程进行调度了，通过函数<code>sched_init()</code>来初始化调度管理模块。</p><h3 id="文件系统初始化"><a href="#文件系统初始化" class="headerlink" title="文件系统初始化"></a>文件系统初始化</h3><p>我们需要存取的数据太多的时候，不可能全部都放入在内存中，这时候就需要一个存放这些数据的地方：文件。通过<code>vfs_caches_init()</code>来初始化基于内存的文件系统<code>rootfs</code>。</p><p>最后就是OS调用rest_init()初始化其他方面了。</p><h1 id="1号进程初始化"><a href="#1号进程初始化" class="headerlink" title="1号进程初始化"></a>1号进程初始化</h1><p>在OS调用rest_init()的时候，首先第一个需要干的大事就是调用<code>kernel_thread(kernel_init, NULL, CLONE_FS)</code>创建系统第二个进程，这个进程就是<strong>1号进程</strong>。</p><p>我们都知道OS是分为用户态与内核态的（不知道的强行知道），这个1号进程就是运行的第一个用户进程。如果我们将0号进程比作师父，1号进程就是大师兄，而大师兄也会开枝散叶，就会形成一个门派（这个门派我就叫他<strong>进程树</strong>派）。</p><p>但是俗话说教会徒弟饿死师父，OS不能把所有的东西都完全交给1号进程去管理，只有把非核心的一些东西交给1号进程（核心资源自己保留，核心内存自己保留），也就是类似古代皇帝不能将所有权限都给了你的属下，不然它们会造反王朝就会分崩离析（蓝屏警告）。因此x86提供了一种分层的权限机制，将区域分成了四个Ring，越往里权限越高。</p><img src="/2021/08/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%86%85%E6%A0%B8%E5%88%9D%E5%A7%8B%E5%8C%96/%E6%9D%83%E9%99%90%E5%88%86%E5%B1%82%E6%9C%BA%E5%88%B6.png" class="" title="image-20210822162153901"><p>OS很机灵的用了这个机制，将关键资源的代码放在Ring0，这就是我们耳熟能详、常常被八股提到的<strong>内核态</strong>；而讲普通的程序代码就放在Ring3，这也是我们常常听到的<strong>用户态</strong>。我们一般的程序也就是跑在用户态的。</p><p>这里有个问题，就是大徒弟解决不了的问题必须要师父解决，也就是说用户态的资源没办法去解决问题了，需要用到核心的内核态资源去运行，这时候怎么去访问呢？比如发送一个网络包，需要去内核中访问。而这时候就需要暂停当前的运行，调用系统调用来运行内核中的代码了。首先，内核将从系统调用传过来的包在网卡上排队，一直等待轮到的时候就发送，发送完了之后代表系统调用结束，再返回用户态，让暂停的程序继续跑。</p><p>那么，上面提到了这个程序要暂停，那么是怎么实现的呢？我们都知道程序跑的就是数据与数据的计算，所以暂停是不是就需要将这些跑了的数据给记录下来？再次运行的时候接着这些数据继续运行就可以了。再有就是程序跑到哪儿了，代码段执行到哪一个指令了，这也需要保存起来，这个都是保存在寄存器里面的。所以，在暂停的那一刻，我们需要将CPU中寄存器的值全部存在一个进程管理容易获取的地方，当进程恢复的时候将这些值恢复回去继续运行。所以整个过程可以总结为：</p><p><strong>用户态-&gt;系统调用-&gt;保存寄存器-&gt;内核态执行系统调用-&gt;恢复寄存器-&gt;返回用户态</strong></p><h3 id="内核态到用户态"><a href="#内核态到用户态" class="headerlink" title="内核态到用户态"></a>内核态到用户态</h3><p>上面在初始化1号进程的时候，也就是在执行kernel_thread这个函数的时候，我们还是在内核态的（这时候还没用户态呢），那么如何从内核态切换到用户态呢？</p><p>在调用kernel_thread这个函数的时候有一个参数kernel_init，这也是个函数，在kernel_init中有一段代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ramdisk_execute_command) &#123; </span><br><span class="line">    ret = run_init_process(ramdisk_execute_command);</span><br><span class="line">    ...... </span><br><span class="line">&#125;</span><br><span class="line">...... </span><br><span class="line">    <span class="keyword">if</span> (!try_to_run_init_process(<span class="string">&quot;/sbin/init&quot;</span>) || </span><br><span class="line">        !try_to_run_init_process(<span class="string">&quot;/etc/init&quot;</span>) || </span><br><span class="line">        !try_to_run_init_process(<span class="string">&quot;/bin/init&quot;</span>) || </span><br><span class="line">        !try_to_run_init_process(<span class="string">&quot;/bin/sh&quot;</span>)) </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>可以发现1号进程运行的是一个文件（linux一切皆文件是不是又符合了），而在run_init_process中发现都会调用do_execve。需要注意的是，execve是一个系统调用，其作用就是执行一个文件，前面加一个do一般就是指内核系统调用实现。而在调用do_execve的时候，会执行“内核态系统调用-&gt;恢复寄存器-&gt;返回用户态”这个过程中的部分，从内核态执行系统调用开始。在经过一系列的调用之后最终会调用一个函数start_thread函数，如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span></span></span><br><span class="line"><span class="function"><span class="title">start_thread</span><span class="params">(struct pt_regs *regs, <span class="keyword">unsigned</span> <span class="keyword">long</span> new_ip, <span class="keyword">unsigned</span> <span class="keyword">long</span> new_sp)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">set_user_gs(regs, <span class="number">0</span>);</span><br><span class="line">regs-&gt;fs  = <span class="number">0</span>;</span><br><span class="line">regs-&gt;ds  = __USER_DS;</span><br><span class="line">regs-&gt;es  = __USER_DS;</span><br><span class="line">regs-&gt;ss  = __USER_DS;</span><br><span class="line">regs-&gt;cs  = __USER_CS;</span><br><span class="line">regs-&gt;ip  = new_ip;</span><br><span class="line">regs-&gt;sp  = new_sp;</span><br><span class="line">regs-&gt;flags  = X86_EFLAGS_IF;</span><br><span class="line">force_iret();</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL_GPL(start_thread);</span><br></pre></td></tr></table></figure><p>其中register代表的是寄存器，pt_regs这个机构体保存的就是用户态的上下文，里面将用户态的代码段<code>CS</code>设置为<code>__USER_CS</code>，将用户太的数据段<code>DS</code>设置为<code>__USER_DS</code>，以及指令指针寄存器IP、栈寄存器SP。这就是保存寄存器的步骤。</p><p>最后的 iret 是干什么的呢？它是用于从系统调用中返回。这个时候会恢复寄存器。从哪里恢复呢？按说是从进入系统调用的时候，保存的寄存器里面拿出。好在上面的函数补上了寄存器。CS 和指令指针寄存器 IP 恢复了，指向用户态下一个要执行的语句。DS 和函数栈指针 SP 也被恢复了，指向用户态函数栈的栈顶。所以，下一条指令，就从用户态开始运行了。</p><h1 id="2号进程初始化"><a href="#2号进程初始化" class="headerlink" title="2号进程初始化"></a>2号进程初始化</h1><p>从上可知用户态进程已经有人管理了，那么内核态的进程有没有一个类似的大师兄来进程管理呢？没有就说不过去了，所以rest_init的第二个大事情就是创建第三个进程，<strong>2号进程</strong>。</p><p>通过函数kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES)来创建进程。注意这里创建进程使用的是thread，可以翻译成线程。明明是创建的进程为什么会用线程的字来创建呢？</p><p>我们从用户态来看，创建一个进程就是分配资源（内存啊、文件啊等等），若只有一个线程来执行就是这个进程的主线程，若是有多个线程来并行执行就是多线程。但是从内核来看，无论是进程还是线程，都被统一称之为任务（task），使用的都是相同的数据结构，平放在同一个链表中。这里创建内核进程的函数<code>kthreadd</code>，其负责所有内核的线程的调度和管理，是内核态所有线程（或者说任务）运行的祖先。</p><p>现在用户态和内核态的进程都有人管了，可以去真正的运行一些进程了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;内核的初始化&quot;&gt;&lt;a href=&quot;#内核的初始化&quot; class=&quot;headerlink&quot; title=&quot;内核的初始化&quot;&gt;&lt;/a&gt;内核的初始化&lt;/h1&gt;&lt;p&gt;内核初始化，就是我们操作系统的内核初始化。那么操作系统初始化需要初始化哪些东西？是按照什么步骤进行的？带着孜</summary>
      
    
    
    
    <category term="操作系统" scheme="http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="OS" scheme="http://example.com/tags/OS/"/>
    
    <category term="内核态" scheme="http://example.com/tags/%E5%86%85%E6%A0%B8%E6%80%81/"/>
    
    <category term="用户态" scheme="http://example.com/tags/%E7%94%A8%E6%88%B7%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>操作系统笔记之CPU的认知</title>
    <link href="http://example.com/2021/08/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8BCPU%E7%9A%84%E8%AE%A4%E7%9F%A5/"/>
    <id>http://example.com/2021/08/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8BCPU%E7%9A%84%E8%AE%A4%E7%9F%A5/</id>
    <published>2021-08-21T07:34:15.000Z</published>
    <updated>2021-08-21T07:36:16.142Z</updated>
    
    <content type="html"><![CDATA[<p>本篇主要介绍CPU的组成以及记录下其中关于寄存器的知识。以x86为例进行说明。</p><h1 id="CPU的组成"><a href="#CPU的组成" class="headerlink" title="CPU的组成"></a>CPU的组成</h1><p>我们知道现在的电脑组成一般包含CPU、内存、USB、硬盘、网卡、显卡、声卡等等，其中CPU和内存较为重要，CPU（Central Processing Unit，中央处理器）是一台电脑的核心，可以视作一个人的大脑，可以说所有设备都是围绕它来展开的（计算机的计算二字全都在CPU里了，你说它核心不核心）。</p><p>而这些设备之间的连接血管或者经络是一个叫做<strong>总线</strong>(Bus)的东西。其连接的逻辑图如下所示：</p><img src="/2021/08/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8BCPU%E7%9A%84%E8%AE%A4%E7%9F%A5/CPU%E7%A1%AC%E4%BB%B6%E9%80%BB%E8%BE%91%E8%BF%9E%E6%8E%A5%E5%9B%BE.png" class="" title="image-20210817222132414"><p>对于其他的设备而言，<strong>内存</strong>是相对来说最为重要的。CPU是拥有计算能力的，但是我们在计算的时候需要计算什么数据呢（也就是数据在哪儿）？计算的结果又存放在哪儿呢？由于CPU造价昂贵（各位可以对比下配置电脑的时候CPU和内存条的价格就心中有数了），并且其主要功能是“计算”二字，所以不可能将存储大量数据的功能也放置在CPU中（并不是说CPU中就没有一点儿数据了），这个时候就需要一个跟CPU进行“沟通”并且速度不能太慢的硬件–内存。</p><h3 id="CPU是如何计算的？"><a href="#CPU是如何计算的？" class="headerlink" title="CPU是如何计算的？"></a>CPU是如何计算的？</h3><img src="/2021/08/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8BCPU%E7%9A%84%E8%AE%A4%E7%9F%A5/CPU%E8%BF%90%E8%A1%8C%E5%9B%BE.png" class="" title="image-20210821135127784"><p>CPU是负责计算的，那么一定可以想到CPU中是拥有一个计算能力的硬件组成，一般我们把其成为<strong>计算单元</strong>，它的责任就只有<code>算</code>这一个单调的能力，比如做加法、位移等。但是这依旧存在一个问题，它计算的数据是从哪儿来的？结果需要放到哪儿？</p><p>上面介绍过内存解决了数据从哪儿来、存放在哪儿的问题，但是现在又有一个问题，若每次的计算数据都是通过总线去内存中拿，因为内存速度还远比不上CPU的计算速度，这就会导致计算的时间远小于取数据的时间，不能够“榨干”CPU性能，就像人只用了幼儿园的大脑，完全是浪费行为（浪费可耻）。所以，CPU中有了计算的硬件之后，还需要有一个能够跟得上计算能力的存储结构，我们把它叫做<strong>数据单元</strong>。数据单元其特点就是存取数据飞一般的感觉，用来暂时存放数据和运算结果，其包括了<strong>CPU缓存</strong>和<strong>寄存器组</strong>。</p><p>好了，现在有了计算能力的计算单元，也有了能跟上计算能力的存储结构数据单元，那么就可以进行计算了…然后怎么去计算呢？也就是说该计算什么不该计算什么呢？所以CPU光有计算单元、数据单元是不能够有效的进行目的性计算的，必须有一个能够控制计算的存在，去控制指挥计算，我们把这个硬件称为<strong>控制单元</strong>。<em>控制单元负责获取下一条指令并且去执行这条指令。这个指令会指导运算单元取出数据单元中的某些数据进行计算，之后放在数据单元中去。</em></p><p>所以，总的来说CPU分为计算单元（计算能力）、数据单元（存放数据）、控制单元（怎么去计算）三部分组成，并且依靠这三个部分相互合作协调去计算目的指令的值。</p><h3 id="CPU与内存的合作"><a href="#CPU与内存的合作" class="headerlink" title="CPU与内存的合作"></a>CPU与内存的合作</h3><p>一个程序运行时，会有独立的内存空间，程序会被加载自己的内存中形成<strong>代码段</strong>，代码段中可以认为存放的是需要执行的指令、指令集，也就是CPU的控制单元需要执行的对象。</p><p>程序在运行时，还需要对一些数据进行操作并且会产生一些结果，这些数据都存放在内存的<strong>数据段</strong>中。</p><p><em>那么问题来了，CPU是如何执行这些指令、操作这些数据、写回结果到内存中呢？</em></p><p>首先指令怎么取？为了解决这个问题，CPU的控制单元中（为什么是控制单元呢？因为其职责就是控制呀）设置了一个<strong>指令指针寄存器</strong>，里面存放了下一条指令在内存中的地址。这样就可以去内存中将要执行的指令取过来。但是取过来之后放在哪儿呢（不可能是指令指针寄存器了）？CPU的控制单元又提供了一个指令寄存器，用来存放将要执行的指令。</p><p>现在有了指令了，那么计算单元怎么去计算呢？这得从这条指令结构说起：要执行的这条指令被分为了两部分，一部分是要做什么操作（计算需求），一部分是要操作什么（数据需求）。所以这条指令会把第一部分交给计算单元去进行计算，将第二部分交给数据单元。</p><p>对于一个进程现在已经可以进行CPU运算了，但是当存在多个进程的时候呢？为此，CPU在控制单元中设置了两个寄存器：一个保存当前处理进程的代码段的起始地址，一个保存进程的数据段起始地址。这两个寄存器中写的是A进程的地址就运行的是A进程指令，是B进程的地址就运行的是B进程指令，而这个切换执行指令的行为就是<strong>进程切换</strong>。</p><p>到此，我们发现内存跟CPU之间交互数据都是靠的总线。但是总线传输的数据也可以分为两类：一类是地址数据，也就是想获取内存中哪个位置的数据，这类总线被称为<strong>地址总线</strong>；一类是内存的真正的数据，这类叫做<strong>数据总线</strong>。</p><p>地址总线确定了CPU可以访问<strong>内存的范围有多大</strong>，比如地址总线为两位，那么可以访问的地址只有00 01 10 11这四个位置，超过这四个位置的就无法区分了。</p><p>数据总线确定了一次能够拿多少个数据进来。比如是两位数据总线，那么一次只能拿两位数进来，若想获取更多的数，必须要更多次数来拿取。</p><h3 id="控制单元、计算单元、数据单元的组成"><a href="#控制单元、计算单元、数据单元的组成" class="headerlink" title="控制单元、计算单元、数据单元的组成"></a>控制单元、计算单元、数据单元的组成</h3><p>作为一个假装求知若渴的人，我就在想上面介绍的数据单元、控制单元、计算单元到底是什么组成的呢？当然是二极管啊…是直接由二极管组成的吗？还是说由其他寄存器组成？这样想了就去看看⑧</p><p>以早期8086处理器为模型. …</p><p>首先看看数据单元：</p><img src="/2021/08/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8BCPU%E7%9A%84%E8%AE%A4%E7%9F%A5/%E6%95%B0%E6%8D%AE%E5%8D%95%E5%85%83%E7%BB%84%E6%88%90.png" class="" title="image-20210821140911489"><p>上面说过CPU需要暂存数据，为了达到这个目的芯片设计师在8086处理器中有8个16位的通用寄存器，也就是上上图的CPU中的数据单元，分别是AX、BX、CX、DX、SP、BP、SI、DI。这些寄存器主要就是为了暂存数据。</p><p>想想当时计算机CPU的资源多珍贵，而我们的存储的数据不光有16位的，还有一些小数据4位、8位等，因此为了更加充分压榨CPU，就将其中的四个寄存器AX、BX、CX、DX分别分成两个八位寄存器来使用，分别是上面的AH、AL、BH、BL、CH、CL、DH、DL，其中H表示高位high，L表示地位low。这样长数据端数据都能够暂存了。</p><p>接下来是控制单元：</p><img src="/2021/08/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8BCPU%E7%9A%84%E8%AE%A4%E7%9F%A5/CPU%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83.png" class="" title="image-20210821142048469"><p>首先是其他寄存器。over</p><p>其次，我们主要关注IP（Instruction Pointer）寄存器，它就是上上上（CPU运行图）个图中的控制单元的指令指针寄存器，其指向<strong>代码段下一条指令</strong>的位置。CPU能够不断的从内存中找到指令就是靠它了，找到之后会加载到CPU的指令队列中（有没有类似的熟悉味道？OS接收缓冲、kafka接收缓冲消息？思想有点儿类似哈），之后交给运算单元去计算执行。这样就保证了<strong>一个</strong>进程在CPU中的执行，那么多个进程存在的时候怎么办呢？怎么切换呢？</p><p>首先，我们知道每个进程都分为代码段和数据段，那么肯定有两个寄存器指向代码段和数据段，也就是CS（代码段寄存器）和DS（数据段寄存器），通过CS可以找到代码在内存中的位置，通过DS可以找到数据在内存中的位置。从上图可知，还有两个寄存器SS、ES。这两个也是段寄存器，带着存在即合理的说法去找找它们“合理的理由”。由于我们程序中存在一种特殊的数据结构—栈，其数据的存取只能从一端进行，为了适应这种特殊的数据存取也就除了相应的寄存器SS（stack register，栈寄存器）。凡是与函数相关的操作，都与栈紧密相关（所以我认为这可能是存在栈寄存器的一个重要原因，未考证求认证）。</p><p>从上面知道可以通过DS找到内存中的数据并加载到通用寄存器中，那么是怎么加载的呢？对于一个段（从段寄存器中加载）都有一个段的起始地址，而段的具体位置是一个数据量称之为偏移量（offset）。在DS、CS中都存放着段的起始地址，代码段的偏移量存放在IP寄存器中（所以说IP存放着指令地址），数据段的偏移量放在通用寄存器中。</p><p>这里注意有一个问题存在：IP寄存器和通用寄存器都是16位的，但是8086的总线是20位的，那么这里就会“差4位”了，需要怎么凑齐呢？其方法就是“<strong>起始地址*16+偏移量</strong>”，也就是把CS、DS中的值左移4位变成20位了，再加上16位的偏移量就可以得到20位的数据地址了。所以我们可以知道8086的最大的内存（能区分的地址大小）为2^20=1M，超过这个空间就不能识别了。而一个段因为只有16位，所以一个段的最大地址为2^16=64kb。LOL直接卡死，pass。</p><h3 id="32位处理器"><a href="#32位处理器" class="headerlink" title="32位处理器"></a>32位处理器</h3><p>计算机发展日新月异，原来的8086处理器早已不能满足各大玩家的需求，相应出来了32位、64位处理器，以32位处理器为例进行说明。</p><p>32位的地址总线，可以识别的内存大小为2^32=4G。所以原来的架构是远远不够的了，但是又不能丢弃原来的架构（丢弃了就不兼容，顾客不满意，顾客就是上帝，上帝抛弃你，GG），因此就需要让其兼容原来的20位的地址总线的架构。</p><p>首先是8个通用寄存器，可以直接将这八个通用寄存器扩展到32位，但是还是要保留16位、8位的使用方式；而指向下一条指令地址的指令指针寄存器IP也扩展为32位，同样也可以兼容16位的。</p><img src="/2021/08/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E4%B9%8BCPU%E7%9A%84%E8%AE%A4%E7%9F%A5/32%E4%BD%8DCPU%E9%80%9A%E7%94%A8%E5%AF%84%E5%AD%98%E5%99%A8.png" class="" title="image-20210821151821335"><p>而改动比较大的就是段寄存器了。为原来的段寄存器位数，并不是一个段的起始地址，也不是按照8位或16位这样来进行扩展的，而是为了满足地址总线弄了一个20位地址，这样每次都需要左移四位。为了解决这个问题，只能重新进行定义了。首先为了尽可能的兼容，CS、DS、DS、ES仍然是16位的，但是其不再是段的起始地址（左移4位后），其映射的是内存中的一个地址，这个内存中内容称为选择子。段的起始地址就保存在内存这个地方，这个地方是一个表格，表格中的一项是段描述符，也就是真正的段起始地址。这样就是先从段寄存器中拿到一个内存中的表格的一项，再从表格中的一项拿到段起始地址（是不是又是中间层解决问题的思想）。但是这样确实还是不兼容。</p><p>我们将前面一种模式（20位地址）称为实模式，后面这种称为保护模式。当32位系统刚刚启动的时候CPU是处于实模式的，这个时候是和原来的20位是兼容的。当需要更多的内存的时候，可以进行模式的切换到32位的保护模式下运行。这样通过切换模式来实现了兼容。</p><p>参考：《计算机组成原理》《趣谈Linux操作系统》《UINX高级环境编程》</p><p>说明：本文主要是记录自己学习笔记，加深自己理解，有些比喻不太恰当的地方请轻喷。错误的知识请使劲儿。因此<strong>本文只做参考与理解</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本篇主要介绍CPU的组成以及记录下其中关于寄存器的知识。以x86为例进行说明。&lt;/p&gt;
&lt;h1 id=&quot;CPU的组成&quot;&gt;&lt;a href=&quot;#CPU的组成&quot; class=&quot;headerlink&quot; title=&quot;CPU的组成&quot;&gt;&lt;/a&gt;CPU的组成&lt;/h1&gt;&lt;p&gt;我们知道现在的</summary>
      
    
    
    
    <category term="操作系统" scheme="http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="寄存器" scheme="http://example.com/tags/%E5%AF%84%E5%AD%98%E5%99%A8/"/>
    
    <category term="处理器" scheme="http://example.com/tags/%E5%A4%84%E7%90%86%E5%99%A8/"/>
    
    <category term="OS" scheme="http://example.com/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>HTTP协议笔记</title>
    <link href="http://example.com/2021/08/10/HTTP%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2021/08/10/HTTP%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0/</id>
    <published>2021-08-09T16:35:11.000Z</published>
    <updated>2021-08-09T16:38:23.318Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h1><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>HTTP是一种<strong>超文本传输协议</strong>，也就是<code>Hyper Text Transfer Protocl</code>。 </p><p>协议：它是一个在<strong>计算机中</strong>的协议，它使用计算机能够<em>识别的语言</em>确立了一种<strong>计算机之间</strong>可以<em>交流</em>（通信）的<strong>规范</strong>，以及相关的各种<strong>控制</strong>和错误等<em>处理方式</em>（<strong>行为约定</strong>、<strong>规范</strong>）。</p><p>传输：从一个点到另一个点。说明HTTP是一个双向协议，并且允许传输过程进行中转（也就是说HTTP传输是不关心中间层经历了什么的，后面可以随意添加TCP层、IP层等都是基于此，甚至SSL/TLS也是基于此特性）。</p><p>超文本：这是指HTTP传输的<strong>内容</strong>为超文本。以前计算机中的文本是指<em>简单的字符</em>，但现在本文已经扩展到<em>图片</em>、<em>视频</em>、<em>压缩包</em>等等，这些在现代的计算机中都被看做文本。而超文本就是<em>超越了普通的文本</em>，是<em>文字、图片、视频等混合体</em>并且拥有<strong>超链接</strong>，能<em>从一个超文本跳转到另一个超文本</em>。常见的超文本有<code>HTML</code>。</p><p>总的来说，<strong>HTTP就是计算机中专门在计算机之间传输文字、视频、图片、音频等超文本数据的规范和约定</strong>。</p><h3 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h3><p>HTTP共有五大类状态码，如下图所示：<img src="/2021/08/10/HTTP%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0/HTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" class="" title="image-20210809222814626"></p><ul><li>  1XX</li></ul><p>1xx 类状态码属于<strong>提示信息</strong>，是协议处理中的一种中间状态，实际用到的比较少。</p><ul><li>  2XX</li></ul><p><code>2xx</code> 类状态码表示服务器<strong>成功</strong>处理了客户端的请求，也是我们最愿意看到的状态。</p><p>「<strong>200 OK</strong>」是最常见的成功状态码，表示一切正常。如果是非 <code>HEAD</code> 请求，服务器返回的响应头都会有 body 数据。</p><p>「<strong>204 No Content</strong>」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。</p><p>「<strong>206 Partial Content</strong>」是应用于 HTTP 分块下载或断电续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。</p><ul><li>  3XX</li></ul><p><code>3xx</code> 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是<strong>重定向</strong>。</p><p>「<strong>301 Moved Permanently</strong>」表示<strong>永久</strong>重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。</p><p>「<strong>302 Moved Permanently</strong>」表示<strong>临时</strong>重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。</p><p>301 和 302 都会在响应头里使用字段 <code>Location</code>，指明后续要跳转的 URL，浏览器会<strong>自动重定向</strong>新的 URL。</p><ul><li>  4XX</li></ul><p><code>4xx</code> 类状态码表示客户端发送的<strong>报文有误</strong>，服务器无法处理，也就是错误码的含义。</p><p>「<strong>400 Bad Request</strong>」表示客户端请求的报文有错误，但只是个笼统的错误。</p><p>「<strong>403 Forbidden</strong>」表示服务器禁止访问资源，并不是客户端的请求出错。</p><p>「<strong>404 Not Found</strong>」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。</p><ul><li>  5XX</li></ul><p><code>5xx</code> 类状态码表示客户端请求报文正确，但是<strong>服务器处理时内部发生了错误</strong>，属于服务器端的错误码。</p><p>「<strong>500 Internal Server Error</strong>」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。</p><p>「<strong>501 Not Implemented</strong>」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。</p><p>「<strong>502 Bad Gateway</strong>」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。</p><p>「<strong>503 Service Unavailable</strong>」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。</p><h3 id="常见字段"><a href="#常见字段" class="headerlink" title="常见字段"></a>常见字段</h3><p>HTTP中常见的字段有<em>Host</em>、<em>Content-Length</em>、<em>Connection</em>、<em>Content-Type</em>、<em>Content-Encoding</em>。</p><ul><li>  Host</li></ul><p>客户端发送请求时，用来指定服务器的<strong>域名</strong>。</p><p>有了Host字段之后，可以将请求发往同一台服务器上的不同网站。</p><ul><li>  Content-Length</li></ul><p>这是服务器在返回数据时会携带的字段，表示本次响应的<strong>数据的长度</strong>。</p><ul><li>  Connection</li></ul><p>这个字段常用于客户端要求与服务端进行TCP持久连接，以便其他请求的复用。</p><p>在HTTP1.1版本之后默认的都是持久连接，但是为了兼容老版本的HTTP协议，需要指定Connection字段为<strong>keep-alive</strong>。</p><ul><li>  Content-Type</li></ul><p>这个字段主要用于服务器在响应时告诉客户端本次使用什么<strong>格式的数据</strong>。</p><p>示例：Content-Type: text/html;charset=utf-8</p><ul><li>  Content-Encoding</li></ul><p>这个字段是为了说明数据报文的压缩方法。表示服务器返回了什么<strong>格式的压缩</strong>。</p><h3 id="Get-与-Post"><a href="#Get-与-Post" class="headerlink" title="Get 与 Post"></a>Get 与 Post</h3><p><code>Get</code> 方法的含义是请求<strong>从服务器获取资源</strong>，这个资源可以是静态的文本、页面、图片视频等。而<code>POST</code> 方法则是相反操作，它向 <code>URI</code> 指定的资源提交数据，数据就放在报文的 body 里。</p><p><em>HTTP协议中幂等和安全</em>：</p><ul><li>  幂等：在HTTP中，执行多次相同的操作结果一定是相同的。</li><li>  安全：这个请求的任意内容不会破坏服务器上的资源。</li></ul><p>很明显 <strong>GET 方法就是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。</p><p><strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。</p><h3 id="HTTP-1-1优缺点"><a href="#HTTP-1-1优缺点" class="headerlink" title="HTTP 1.1优缺点"></a>HTTP 1.1优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>HTTP最突出的优点就是<strong>简单、灵活且易于扩展、应用广泛和跨平台</strong>。</p><ul><li>  <strong>简单</strong>：HTTP基本<em>报文格式</em>上来看，都是header + body的格式，并且头部信息也是key - value的简单文本形式，很容易理解，学习和使用的门槛很低。</li><li>  <strong>灵活且易于扩展</strong>：开发人员可对其进行<em>自定义</em>和<em>扩展</em>，比如在协议中的各类请求方法、URL/URI、状态码、头字段等都没有被固定死。同时HTTP在OSI的第七层应用层，其下层可随意进行变化。比较典型的就是在TCP中间增加了SSL/TLS安全传输层，甚至HTTP/3将TCP改为基于UDP的QUIC。</li><li>  <strong>应用广泛和跨平台</strong>：从台式机的浏览器到移动端的APP，从新闻、贴吧、游戏到金融，并且其天然具有跨平台的优势。</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>其缺点可以从HTTP的发展结合来看，不断的发展就是不断的去完善它补足其缺点，可以先说出其缺点：<strong>无状态、明文传输、不安全</strong>。</p><ul><li>  无状态：无状态的好处是<strong>服务器不会去记忆HTTP的状态</strong>，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的CPU和内存用来对外提供服务。但正因此不记录状态，当处理关联性十分强的业务时操作会变得十分棘手。比如登录B站后若每一次都需要进行身份验证，这样的体验感除了差就是更差了吧。</li></ul><p>一般面对这种无状态的简单解决方式是使用<code>cookie</code>技术来解决。</p><p><code>Cookie</code> 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。</p><p>相当于，<strong>在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了</strong>。</p><ul><li>  明文传输</li></ul><p>明文意味着在传输过程中的信息，是可<em>方便阅读</em>的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的<em>便利性</em>。</p><p>但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于<strong>信息裸奔</strong>。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能<em>被窃取</em>，如果里面有你的账号密码信息，那<strong>你号没了</strong>。</p><img src="/2021/08/10/HTTP%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0/image-20210809233344869.png" class="" title="image-20210809233344869"><ul><li>  不安全</li></ul><p>HTTP比较严重的就是不安全的问题了，主要体现在如下三个方面：</p><ol><li> <strong>明文交流</strong>（通信），内容很容易被窃听。比如，<strong>账号信息容易泄漏，那你号没了。</strong></li><li> <strong>无身份验证</strong>，很可能对端是伪装的（类似抠脚大汉伪装女装大佬，你还以为爱情来了）。<strong>访问假的淘宝、拼多多，那你钱没了。</strong></li><li> <strong>数据完整性</strong>无法保证，不知道是否被篡改（本来通知你上清华，给你改了上蓝翔）。<strong>网页上植入垃圾广告，视觉污染，眼没了。</strong></li></ol><p>HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 <code>SSL/TLS</code> 层，使得在安全上达到了极致。</p><h3 id="HTTP1-1性能"><a href="#HTTP1-1性能" class="headerlink" title="HTTP1.1性能"></a>HTTP1.1性能</h3><p>HTTP 协议是基于 <strong>TCP/IP</strong>，并且使用了<strong>请求 - 应答</strong>的通信模式，所以性能的关键就在这<strong>两点</strong>里。</p><p><em>1. 长连接</em></p><p>早期 HTTP/1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无畏的 TCP 连接建立和断开，增加了通信开销。</p><p>为了解决上述 TCP 连接问题，HTTP/1.1 提出了<strong>长连接</strong>的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。</p><p>持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。</p><p><em>2. 管道网络传输</em></p><p>HTTP/1.1 采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。</p><p>即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以<strong>减少整体的响应时间。</strong></p><p>举例来说，客户端需要请求两个资源。以前的做法是，在同一个TCP连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。</p><p>但是这样还存在一个问题：服务器是同步的响应（按顺序），只有先响应了A请求，完成后才会响应B。要是前面的回应特别的慢，后面许多请求都会排队等着，这就是<strong>队头堵塞</strong>。</p><p><em>3. 队头阻塞</em></p><p>因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「<strong>队头阻塞</strong>」。<strong>好比上班的路上塞车</strong>。</p><p>总的看下来，其性能只能说一般，远远达不到高效二字，而其后的HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。</p><h3 id="HTTP与HTTPS区别"><a href="#HTTP与HTTPS区别" class="headerlink" title="HTTP与HTTPS区别"></a>HTTP与HTTPS区别</h3><ol><li> 传输方式：HTTP 是超文本传输协议，信息是<strong>明文传输</strong>，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够<strong>加密传输</strong>。</li><li> 建立连接复杂度：HTTP 连接建立相对简单， TCP <strong>三次握手</strong>之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行** SSL/TLS 的握手**过程，才可进入加密报文传输。</li><li> 端口：HTTP 的端口号是 80，HTTPS 的端口号是 443。</li><li> 传输成本：HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</li></ol><h3 id="HTTPS对HTTP的优化"><a href="#HTTPS对HTTP的优化" class="headerlink" title="HTTPS对HTTP的优化"></a>HTTPS对HTTP的优化</h3><p>HTTP 由于是明文传输，所以安全上存在以下三个风险：</p><ul><li>  <strong>窃听风险</strong>，比如通信链路上可以获取通信内容，用户号容易没。</li><li>  <strong>篡改风险</strong>，比如强制入垃圾广告，视觉污染，用户眼容易瞎。</li><li>  <strong>冒充风险</strong>，比如冒充淘宝网站，用户钱容易没。</li></ul><p>HTTP<strong>S</strong> 在 HTTP 与 TCP 层之间加入了 <code>SSL/TLS</code> 协议，能够很好的解决上述问题。</p><ul><li>  信息加密：交互信息因为加密无法被窃取。</li><li>  校验机制：因为指纹原因无法篡改内容，篡改了不能正常显示。</li><li>  身份证书：能够证明其身份，让淘宝是真正的淘宝。</li></ul><h3 id="HTTPS的安全机制"><a href="#HTTPS的安全机制" class="headerlink" title="HTTPS的安全机制"></a>HTTPS的安全机制</h3><ul><li>  <strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li><li>  <strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li><li>  将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li></ul><p><em>1. 混合加密</em></p><p>通过<strong>混合加密</strong>的方式可以保证信息的<strong>机密性</strong>，解决了窃听的风险。</p><p>HTTPS 采用的是<strong>对称加密</strong>和<strong>非对称加密</strong>结合的「混合加密」方式：</p><ul><li>  在通信建立前采用<strong>非对称加密</strong>的方式交换「会话秘钥」，后续就不再使用非对称加密。</li><li>  在通信过程中全部使用<strong>对称加密</strong>的「会话秘钥」的方式加密明文数据。</li></ul><p>采用「混合加密」的方式的原因：</p><ul><li>  <strong>对称加密</strong>只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。</li><li>  <strong>非对称加密</strong>使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。</li></ul><p><em>2. 摘要算法</em></p><p><strong>摘要算法</strong>用来实现<strong>完整性</strong>，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。也就是将数据”abc”进行加密生成指纹，若篡改了数据为”Abc”，则接收方生成指纹跟发送的指纹不一样则说明数据被篡改了不可信。</p><p>客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同<br>加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。</p><p><em>3. 数字证书</em></p><p>客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。</p><p>这就存在些问题，如何保证公钥不被篡改和信任度？</p><p>所以这里就需要借助第三方权威机构 <code>CA</code> （数字证书认证机构），将<strong>服务器公钥放在数字证书</strong>（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。</p><h3 id="HTTPS建立连接过程"><a href="#HTTPS建立连接过程" class="headerlink" title="HTTPS建立连接过程"></a>HTTPS建立连接过程</h3><p>SSL/TLS 协议基本流程：</p><ul><li>  客户端向服务器索要并验证服务器的公钥。</li><li>  双方协商生产「会话秘钥」。</li><li>  双方采用「会话秘钥」进行加密通信。</li></ul><p>前两步也就是 SSL/TLS 的建立过程，也就是握手阶段。</p><p>SSL/TLS 的「握手阶段」涉及<strong>四次</strong>通信，可见下图：</p><img src="/2021/08/10/HTTP%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0/HTTPS%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B.webp" class="" title="a"><p>SSL/TLS 协议建立的详细流程：</p><p><em>1. ClientHello</em></p><p>首先，由客户端向服务器发起加密通信请求，也就是 <code>ClientHello</code> 请求。</p><p>在这一步，客户端主要向服务器发送以下信息：</p><p>（1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。</p><p>（2）客户端生产的随机数（<code>Client Random</code>），后面用于生产「会话秘钥」。</p><p>（3）客户端支持的密码套件列表，如 RSA 加密算法。</p><p><em>2. SeverHello</em></p><p>服务器收到客户端请求后，向客户端发出响应，也就是 <code>SeverHello</code>。服务器回应的内容有如下内容：</p><p>（1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。</p><p>（2）服务器生产的随机数（<code>Server Random</code>），后面用于生产「会话秘钥」。</p><p>（3）确认的密码套件列表，如 RSA 加密算法。</p><p>（4）服务器的数字证书。</p><p><em>3.客户端回应</em></p><p>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。</p><p>如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：</p><p>（1）一个随机数（<code>pre-master key</code>）。该随机数会被服务器公钥加密。</p><p>（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</p><p>上面第一项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，<strong>各自生成</strong>本次通信的「会话秘钥」。</p><p><em>4. 服务器的最后回应</em></p><p>服务器收到客户端的第三个随机数（<code>pre-master key</code>）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发生最后的信息：</p><p>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p><p>至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p><h3 id="HTTP1-1与HTTP1-0-比较"><a href="#HTTP1-1与HTTP1-0-比较" class="headerlink" title="HTTP1.1与HTTP1.0 比较"></a>HTTP1.1与HTTP1.0 比较</h3><p>HTTP/1.1 相比 HTTP/1.0 性能上的改进：</p><ul><li>  使用 TCP <strong>长连接</strong>的方式改善了 HTTP/1.0 短连接造成的性能开销。</li><li>  支持 <strong>管道（pipeline）网络传输</strong>，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li></ul><p>但 HTTP/1.1 还是有性能瓶颈：</p><ul><li>  请求 / 响应<strong>头部</strong>（<code>Header</code>）<strong>未经压缩</strong>就发送，首部信息越多延迟越大。只能压缩 <code>Body</code> 的部分；</li><li>  发送<strong>冗长的首部</strong>。每次互相发送相同的首部造成的浪费较多；</li><li>  服务器是<strong>按请求的顺序响应</strong>的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；</li><li>  没有请求<strong>优先级控制</strong>；</li><li>  请求只能从客户端开始，服务器只能<strong>被动响应</strong>。</li></ul><h3 id="HTTP2-0与HTTP1-1比较"><a href="#HTTP2-0与HTTP1-1比较" class="headerlink" title="HTTP2.0与HTTP1.1比较"></a>HTTP2.0与HTTP1.1比较</h3><p>HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。</p><p>那 HTTP/2 相比 HTTP/1.1 性能上的改进：</p><p><em>1. 头部压缩</em></p><p>HTTP/2 会<strong>压缩头</strong>（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的分</strong>。</p><p>这就是所谓的 <code>HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了。</p><p><em>2. 二进制格式</em></p><p>HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式。</strong></p><p>头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧和数据帧</strong>。</p><p>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</p><p><em>3. 数据流</em></p><p>HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。</p><p>每个请求或回应的所有数据包，称为一个数据流（<code>Stream</code>）。</p><p>每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数</p><p>客户端还可以<strong>指定数据流的优先级</strong>。优先级高的请求，服务器就先响应该请求。</p><p><em>4. 多路复用</em></p><p>HTTP/2 是可以在<strong>一个连接中并发多个请求或回应，而不用按照顺序一一对应</strong>。</p><p>移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，<strong>降低了延迟，大幅度提高了连接的利用率</strong>。</p><p>举例来说，在一个 TCP 连接里，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程非常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。</p><p><em>5. 服务器推送</em></p><p>HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以<strong>主动</strong>向客户端发送消息。</p><p>举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，<strong>减少延时的等待</strong>，也就是服务器推送（Server Push，也叫 Cache Push）。</p><h3 id="HTTP2与HTTP3比较"><a href="#HTTP2与HTTP3比较" class="headerlink" title="HTTP2与HTTP3比较"></a>HTTP2与HTTP3比较</h3><p>HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。</p><p>所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong>。</p><ul><li>  HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了</li><li>  HTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。</li></ul><p>这都是基于 TCP 传输层的问题，所以 <strong>HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！</strong></p><p>UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。</p><p>大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。</p><ul><li>  QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，<strong>其他流不会受到影响</strong>。</li><li>  TL3 升级成了最新的 <code>1.3</code> 版本，头部压缩算法也升级成了 <code>QPack</code>。</li><li>  HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 <code>TLS/1.3</code> 的三次握手。QUIC 直接把以往的 TCP 和 <code>TLS/1.3</code> 的 6 次交互<strong>合并成了 3 次，减少了交互次数</strong>。</li></ul><img src="/2021/08/10/HTTP%E5%8D%8F%E8%AE%AE%E7%AC%94%E8%AE%B0/QUIC%E4%BA%A4%E4%BA%92.webp" class="" title="a"><p>所以， QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP/2 的多路复用的协议。</p><p>QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题。所以 HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。</p><p>==reference：图解HTTP；HTTP的前世今；小林coding==</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;HTTP协议&quot;&gt;&lt;a href=&quot;#HTTP协议&quot; class=&quot;headerlink&quot; title=&quot;HTTP协议&quot;&gt;&lt;/a&gt;HTTP协议&lt;/h1&gt;&lt;h3 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="网络协议" scheme="http://example.com/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="面试" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
    <category term="HTTP" scheme="http://example.com/tags/HTTP/"/>
    
    <category term="HTTPS" scheme="http://example.com/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>redis笔记</title>
    <link href="http://example.com/2021/08/03/redis%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2021/08/03/redis%E7%AC%94%E8%AE%B0/</id>
    <published>2021-08-03T15:08:40.000Z</published>
    <updated>2021-08-03T15:10:22.273Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redis的主从复制"><a href="#redis的主从复制" class="headerlink" title="redis的主从复制"></a>redis的主从复制</h1><p>当存在多台redis服务器的时候，会有一台主服务器master，以及若干台从服务器slaves。一般说，都是master进行写操作，slaves进行读操作。</p><p>那么，master与slaves之间是怎么进行数据同步的呢？这就是redis主从复制的由来。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>通过数据复制，redis一个master可以挂载多个slave，每个slave下面还可以挂载次一级的slave，形成多级嵌套结构。<strong>所有的写操作都在master进行，master执行完成后，会将写指令分发给挂在自己下面的slave，slave会进一步分发写指令给自己次一级的slave。</strong></p><p>因此多节点保存数据的方式，在任何一个节点异常都不会导致数据的丢失，同时N个slave节点可以提升redis的读能力N倍。这样一个master写slave读的结构能大大提高redis的读写能力。</p><p>redis存在一个<strong>复制积压缓冲</strong>，当master在分发写指令给slave时，同时将写指令复制到积压缓冲去，这样做是防止slave在短时间断开重连时，只要slave的复制位置点仍在积压缓冲中就可以继续在复制位置点之后继续复制，大大提升了复制效率。因此，redis复制分为<strong>全量复制</strong>和<strong>增量复制</strong>。</p><p>每次复制的时候会有一个复制id，master与slave之间通过复制id进行匹配，防止slave挂到错误的master。</p><h3 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h3><p>在redis2.8之前，只支持全量复制。全量复制时，master会将内存数据通过bgsave存入rdb中，同时会构建内存快照期间的写指令，存放到<strong>复制缓冲</strong>中，当rdb构建完成后，将rdb和复制缓冲中的数据全部发送给slave，slave会完全的重新创建一份数据。</p><p>这种复制需要的数据量大，因此对master性能损耗大，耗时长在传递rdb时会占用大量宽带，进而对整个系统性能和资源访问都产生较大的影响。</p><h3 id="增量复制"><a href="#增量复制" class="headerlink" title="增量复制"></a>增量复制</h3><p>增量复制是master只发送上次复制位置之后的写指令，不需要构建rdb，传输的内容少，因此不管是对master还是slave负荷都很小，占用的宽带也小，对系统影响几乎可以忽略。</p><ul><li>redis2.8-4.0</li></ul><p>在redis2.8之后，redis引入了psync，增加了一个<strong>复制积压缓冲</strong>，在将写指令发送给slave时，同时写在复制积压缓存中去。</p><p>例子：若slave在短时断开重连后，会上报master runid以及复制偏移量，master会检测runid与自己的runid是否一致并且偏移量是否在master的复制积压缓冲中，则master进行增量同步。但是若在重启时丢失了slave或master在切换之后runid会发生变化，这时仍然会进行全量复制。</p><ul><li>redis4.0</li></ul><p>针对以前的psync问题，redis引入了psync2。主从复制抛弃了runid来复制，而使用replid(复制id)作为复制判断依据。同时在构建rdb时会将replid当做辅助信息存入rdb中。重启slave时只需要加载rdb即可得到master的replid。</p><p>同时，每个redis处理拥有replid之外，还有个replid2。redis启动时，会创建一个长度为40的随机字符串，作为replid的初始值，在建立主从链接后，会用master的replid替换自己的replid，同时replid2会存储上次master的replid。这样在切换master时，若master与slave的replid不同，但只要slave的replid与master的replid2相同，同时复制偏移量仍然在复制积压缓冲中，就可以增量复制。</p><h2 id="redis复制流程"><a href="#redis复制流程" class="headerlink" title="redis复制流程"></a>redis复制流程</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">A[从库链接主库] --&gt; B[上报信息及探测]--&gt;C[ping]--&gt;D[auth]</span><br><span class="line">D[auth]--&gt;E[replconf 上报ip/port]--&gt;F[replconf 校验版本]--&gt;G[psync 准备同步]--&gt;H&#123;增量同步?&#125;</span><br><span class="line">H--&gt; | Y | H1[主库发送复制缓冲] --&gt; ret[从库接受指令并执行]</span><br><span class="line">H--&gt; | N | H2[主库发送rdb+复制缓冲]--&gt;H3[从库接受rdb文件]--&gt;H4[从库清空已有数据]--&gt;H5[从库加载rdb文件]--&gt;H6[从库重建client修正复制状态]--&gt;H1</span><br></pre></td></tr></table></figure><ol><li>slave与master建立链接,先发送ping指令,若正常则返回pong,说明master可用.若redis设置了密码,则进行密码校验.</li><li>slave继续通过replconfpsync2进行复制版本校验;之后从库将自己的replid、复制偏移发送给master，正式开始准备数据同步。</li><li>master收到psync指令后判断是否进行增量复制。</li><li>若slave的replid与master的replid或replid2相等，且复制偏移量仍在复制积压偏移中，则进行增量同步。master会发送continue响应，并返回master的replid。slave会将master的replid替换为自己的replid，并将之前的replid设置为replid2。之后master继续发送指令给slave完成数据同步。</li><li>对于全量复制，master会返回fullresync响应，附带replid以及复制偏移，之后master构建rdb，并将rdb与复制缓冲发送给slave。</li><li>全量复制的slave首先会清理嵌套复制，并关闭其所有子slave链接，清理自己的复制积压缓冲。之后slave会构建临时rdb文件，并从master连接中读取rdb的实际数据并写入自己rdb中，在接受完毕数据之后则将临时rdb文件改名为rdb的真正名字。接下来slave会清空老数据(即删除本地DB中的所有数据)，并暂时停止接收数据，全力加载rdb中的数据，将其写到内存中去。当rdb加载完毕之后，slave会重新利用连接的socket与master建立client，并在此注册读事件，就可以开始接收master的写指令了。此时，slave 还会将 master 的 replid 和复制偏移设为自己的复制 id 和复制偏移 offset，并将自己的 replid2 清空，因为，slave 的所有嵌套 子slave 接下来也需要进行全量复制。最后，slave 就会打开 aof 文件，在接受 master 的写指令后，执行完毕并写入到自己的 aof 中。</li></ol><h2 id="读写分离以及存在的问题"><a href="#读写分离以及存在的问题" class="headerlink" title="读写分离以及存在的问题"></a>读写分离以及存在的问题</h2><p>在主从复制上实现的读写分离，可以实现redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点可以提高数据冗余程度以及最大化读负载能力），在读负载较大的场景下可以大大提高redis的并发量。但在使用redis读写分离时也需要注意以下问题：</p><h3 id="延迟与不一致"><a href="#延迟与不一致" class="headerlink" title="延迟与不一致"></a>延迟与不一致</h3><p>由于主从复制命令是异步传播的，那么一定会出现延迟和数据不一致情况。</p><p>若应用对延迟、不一致接受程度较低，可优化的方法：</p><ul><li>优化主从节点之间的网络环境（如同机房部署）；</li><li>监控主从节点之间的延迟（通过offset），若从节点延迟过大，则不再通过该节点读取数据；</li><li>使用集群，同时扩展读负载和写负载等。</li></ul><p>在命令传播阶段以外可能数据不一致情况更加严重，如连接在数据同步阶段、从节点失去与主节点的连接时等等。从节点的<code>slave-server-stale-data</code>便与此相关（其控制从节点的表现）：若为<code>yes</code>（默认），则从节点仍能响应客户端的命令；若为<code>no</code>，则只响应客户端的info、slaveof命令。若对数据一致性要求较高，则设置为<code>no</code>。</p><h3 id="数据过期"><a href="#数据过期" class="headerlink" title="数据过期"></a>数据过期</h3><p>在单机版的redis中存在两种删除策略：</p><ul><li>惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断其是否过期，如果过期则删除。</li><li>定期删除：服务器会定期删除过期数据，但是考虑到内存和CPU的折中（频繁的释放内存会对内存和CPU不友好），该删除的频率和执行时间都受到了限制。</li></ul><p>在主从复制场景下，为了数据一致性，从节点不会主动删除数据，都是主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除都不能保证及时的对从节点过期删除，因此客户端读取数据时很容易读取到过期的数据。</p><p>在redis3.2中，从节点读取数据时增加了对数据是否过期的判断：若该数据已过期则不返回给客户端。</p><h3 id="故障切换"><a href="#故障切换" class="headerlink" title="故障切换"></a>故障切换</h3><p>在没有使用哨兵的读写分离情况下，读写连接不同的redis节点。当主节点或从节点出现问题而发生故障时，需要及时修改应用程序读写redis的连接，连接的切换可手动执行，也可写监控程序进行切换。但前者响应慢、容易出错，后者实现复杂、成本并不低。</p><p>因此建议使用哨兵，使主从节点切换尽量自动化，并减少对应用程序的侵入。</p><h2 id="复制超时"><a href="#复制超时" class="headerlink" title="复制超时"></a>复制超时</h2><h3 id="超时判断意义"><a href="#超时判断意义" class="headerlink" title="超时判断意义"></a>超时判断意义</h3><p>在主从复制的连接时和连接后，主从节点都有判断连接是否超时，其意义在于：</p><ul><li>主节点判断超时：若超时，主节点会释放相应的各种资源；主节点也能判断当前有效从节点个数，有助于保证数据安全。</li><li>从节点判断超时：若超时，从节点可以及时的与主节点重新建立连接，避免与主节点数据长期不一致。</li></ul><h3 id="判断机制"><a href="#判断机制" class="headerlink" title="判断机制"></a>判断机制</h3><p>主从复制超时判断的核心在于<code>repl-timeout</code>参数，该参数规定了超时时间的阈值(默认60s)，对于主节点和从节点同时有效，其超时触发条件：</p><ul><li>主节点：每秒一次调用复制定时函数<code>replicationCron()</code>，在其中判断当前时间距离上次收到各个节点REPLCONF ACK的时间，是否超过了repl-timeout值，若超过了则释放相关从节点连接。</li><li>从节点：从节点判断同样是在复制定时函数中判断，其如下：<ul><li>建立连接阶段：若距离上次收到主节点信息时间已经超过repl-timeout，则释放连接；</li><li>数据同步阶段：收到主节点的RDB文件超时，则停止数据同步并释放连接；</li><li>命令传播阶段：距离上次收到主节点的PING命令或数据时间超过repl-timeout则释放连接。</li></ul></li></ul><p>注意：在进行慢查询时可能会导致的阻塞：在从节点或主节点进行了一些慢查询，导致服务阻塞，阻塞期间无法响应复制连接中对方节点的请求，可能会导致复制超时。</p><h2 id="复制缓冲区溢出"><a href="#复制缓冲区溢出" class="headerlink" title="复制缓冲区溢出"></a>复制缓冲区溢出</h2><p>除了复制超时会导致复制中断外，复制缓冲区溢出同样会导致复制中断。</p><p>在全量复制阶段，主节点会将执行的写命令放到复制缓冲区中，该缓冲区存放的数据包括了以下几个时间段内主节点执行的写命令：bgsave生成RDB文件、RDB文件由主节点发往从节点、从节点清空老数据并载入RDB文件中的数据。当主节点数据量较大，或者主从节点之间网络延迟较大时，可能导致该缓冲区的大小超过了限制，此时主节点会断开与从节点之间的连接；这种情况可能引起全量复制-&gt;复制缓冲区溢出导致连接中断-&gt;重连-&gt;全量复制-&gt;复制缓冲区溢出导致连接中断……的循环。</p><p>复制缓冲区的大小由client-output-buffer-limit slave {hard limit} {soft limit} {soft seconds}配置，默认值为client-output-buffer-limit slave 256MB 64MB 60，其含义是：如果buffer大于256MB，或者连续60s大于64MB，则主节点会断开与该从节点的连接。该参数是可以通过config set命令动态配置的（即不重启Redis也可以生效）。</p><p><strong>注意：复制缓冲区是客户端输出缓冲区的一种，主节点会为每个从节点分配一个复制缓冲区；而复制积压缓冲区主节点只有一个，无论它有多少个从节点。</strong></p><h1 id="redis的五种对象类型"><a href="#redis的五种对象类型" class="headerlink" title="redis的五种对象类型"></a>redis的五种对象类型</h1><p>redis有五种对象类型，每种结构至少有两种编码方式。这样做的好处是：一方面接口与实现分离，当需要增加或改变内部编码时用户不会收到影响；另一方面可以根据不同场景切换内部编码，提高效率。</p><p><strong>注意：redis内部编码转换只有在写入时完成，且转换过程不可逆，只能从小内存向大内存编码转换。</strong></p><h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><h3 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h3><p>字符串是redis最基础的编码，因为<strong>所有的键</strong>都是字符串类型，且字符串之外的其他集中复杂类型的元素也是字符串。</p><p><strong>字符串长度不能超过512M。</strong></p><h3 id="内部编码"><a href="#内部编码" class="headerlink" title="内部编码"></a>内部编码</h3><p>redis字符串内部编码根据大小不同有三种编码方式：</p><ul><li><code>int</code>：8字节的长整型。字符串值是整型时，这个值用long整型表示。</li><li><code>embstr</code>：&lt;=<code>39字节</code>的字符串。embstr与raw都是用SDS与redisObject保存数据。区别在于embstr只分配一次内存空间（因此RedisObject和sds是连续的），而raw需要分配两次内存空间（分别为RedisObject与sds分配）。好处：embstr分配和销毁时都只创建、销毁一次空间，并且对象数据连在一起方便查找。坏处：当字符串增加长度需要重新分配内存时，整个RedisObject和sds都需要重新分配空间。<strong>因此redis中的embstr实现为只读。</strong></li><li><code>raw</code>：&gt;39字节的字符串。</li></ul><p>可以通过以下命令查看编码类型：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; object encoding key</span><br></pre></td></tr></table></figure><p>embstr与raw为什么区分是39字节呢？</p><p><code>RedisObject</code>的长度是16字节，<code>sds</code>长度是9+<code>字符串长度</code>，jemalloc正好可以分配64字节内存单元，所以：16 + 9 + 39 = 64 字节。</p><h3 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h3><p><em>当int数据不再是整数，或大小超过了long的范围时，自动转化为raw。</em></p><p>而对于<code>embstr</code>，由于其实现是只读的，因此在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了39个字节。</p><p>所以当我们存储的字符串需要进行转换时可以直接指定字符串为raw减少一次字符串转换。</p><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="概括-1"><a href="#概括-1" class="headerlink" title="概括"></a>概括</h3><p>列表(list)用来存储多个有序字符串，每个字符串称为元素。一个list可以存储<code>2^23-1</code>个元素。</p><p>redis中list支持<strong>两端插入和弹出</strong>，可以获得<strong>指定位置/范围</strong>的元素，可以充当<em>数组</em>、<em>队列</em>、<em>栈</em>等。</p><h3 id="内部编码-1"><a href="#内部编码-1" class="headerlink" title="内部编码"></a>内部编码</h3><p>list的内部编码可以是*压缩列表(ziplist)<em>、</em>双端链表(linkedlist)*。</p><p><strong>双端</strong>链表：由一个<code>list</code>和多个<code>listNode</code>组成。其保存了<em>表头表尾</em>指针，并且每个节点都有指<em>向前</em>一指针和<em>后</em>一指针，链表还保存了列表的<em>长度</em>，还有标识保存的<em>值的类型</em>字段。而链表中每个节点指向的是type为<strong>字符串的RedisObject</strong>。</p><p><strong>压缩</strong>列表：压缩列表是为了节约空间而开发的，由一系列特殊编码的<strong>连续内存块</strong>组成的顺序数据类型结构。其虽然空间节约，但是在操作<em>增删修改</em>时复杂度过高，所以只有在<em>节点数量较少的情况下</em>使用。</p><h3 id="编码转换-1"><a href="#编码转换-1" class="headerlink" title="编码转换"></a>编码转换</h3><p>只有同时满足下面<code>两个</code>条件时，才会使<code>用压缩</code>列表：列表中<code>元素数量小于512</code>个；列表中<code>所有字符串对象都不足64字节</code>。如果有一个条件不满足，则使用双端列表；且编码只可能由压缩列表转化为双端链表，反方向则不可能。</p><h2 id="哈希"><a href="#哈希" class="headerlink" title="哈希"></a>哈希</h2><h3 id="概括-2"><a href="#概括-2" class="headerlink" title="概括"></a>概括</h3><p>哈希不光是redis对外提供的数据类型的一种，也是redis作为Key-Value数据库使用的数据结构。</p><p>在这里用<em>内层哈希</em>代表redis对外提供的一种数据类型，<em>外层哈希</em>代表redis作为K-V数据库所使用的数据结构。</p><h3 id="内部编码-2"><a href="#内部编码-2" class="headerlink" title="内部编码"></a>内部编码</h3><p>*内层的哈希(redis对外提供的五种数据结构之一)使用的内部编码为压缩列表(ziplist)和哈希表(hashtable)<em>。</em>外层的哈希（redis使用的key-value数据库使用的数据结构）只使用了哈希表(hashtable)*。</p><p><code>hashtable</code>：一个hashtable由一个<code>dick</code>结构、两个<code>dicktht</code>结构、一个<code>dickEntry</code>指针数组（<code>bucket</code>）和多个<code>dickEntry</code>结构组成。</p><img src="/2021/08/03/redis%E7%AC%94%E8%AE%B0/hashtable.png" class="" title="image-20210719223407310"><p>从底层向上依次介绍数据结构（x64）：</p><ul><li><strong>dictEntry</strong></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="keyword">struct</span> dictEntry&#123;</span><br><span class="line">    void *key;<span class="comment">// 键值对中的键8byte</span></span><br><span class="line">    union&#123;</span><br><span class="line">        void *val;</span><br><span class="line">        uint64_tu64;</span><br><span class="line">        int64_ts64;</span><br><span class="line">    &#125;v;<span class="comment">//  键值对中的值，有三种类型，使用union实现8byte</span></span><br><span class="line">    <span class="keyword">struct</span> dictEntry *next;<span class="comment">// 指向下一个dickEntry，用于解决哈希冲突8byte</span></span><br><span class="line">&#125;dictEntry;<span class="comment">// 一共24byte</span></span><br></pre></td></tr></table></figure><ul><li><strong>bucket</strong></li></ul><p><code>bucket</code>是一个<code>数组</code>，原始是一个指向<code>dickEntry</code>的指针，其大小为<code>len</code>，len满足<code>dictEntry&lt;len&lt;=2^n</code>条件取n最小值另len=2^n。例如：有1000个dickEntry，则大小len为1024。</p><ul><li><strong>dictht</strong></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="keyword">struct</span> dictht&#123;</span><br><span class="line">    dictEntry **table;<span class="comment">// 指向dictEntry的指针</span></span><br><span class="line">    unsigned long size;<span class="comment">// 哈希表的大小，即bucket的大小</span></span><br><span class="line">    unsigned long sizemask;<span class="comment">// 大小为size-1，决定健在table中存储的位置</span></span><br><span class="line">    unsigned long used;<span class="comment">// 已使用的dictEntry数量</span></span><br><span class="line">&#125;dictht;</span><br></pre></td></tr></table></figure><ul><li><strong>dict</strong></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="keyword">struct</span> dict&#123;</span><br><span class="line">    dictType *<span class="keyword">type</span>;<span class="comment">// 与privdata一起来适应不同的键值对类型，创建多态字典</span></span><br><span class="line">    void *privdata;</span><br><span class="line">    <span class="comment">// ht与trehashindx用于rehash，即当hash需要扩展和缩容时使用。</span></span><br><span class="line">    dictht ht[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">int</span> trehashidx;</span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure><p><code>ht</code>是一个包含<code>两个项的数组</code>，每项都指向一个<code>dictht</code>结构，这也是Redis的哈希会有1个dict、2个dictht结构的原因。<strong>通常情况下，所有的数据都是存在放dict的ht[0]中，ht[1]只在rehash的时候使用</strong>。dict进行rehash操作的时候，将ht[0]中的所有数据rehash到ht[1]中。然后将ht[1]赋值给ht[0]，并清空ht[1]。</p><h3 id="编码转换-2"><a href="#编码转换-2" class="headerlink" title="编码转换"></a>编码转换</h3><p>在hash中只有满足：<strong>哈希元素数量小于512个</strong> &amp;&amp;<strong>所有键值对的键和值都小于64byte</strong>时才可以用ziplist。否则只能使用hashtable编码。并且编码<em>只能由ziplist转换为hashtable</em>。</p><h2 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>集合（set）与列表类似，都是用来保存多个字符串，但是其内部的元素是<strong>无序</strong>的，并且其元素<strong>不存在重复</strong>现象。</p><p>一个集合可以拥有<code>2^32-1</code>个元素，并且redis还支持求<strong>交集、并集、差集</strong>。</p><h3 id="内部编码-3"><a href="#内部编码-3" class="headerlink" title="内部编码"></a>内部编码</h3><p>set内部编码为<em>整数集合或哈希表</em>。</p><p>set在使用<code>hashtable</code>时值会被全部置为<code>NULL</code>。</p><p>整数集合（intset）结构：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="keyword">struct</span> intset&#123;</span><br><span class="line">    uint32_t encoding;<span class="comment">// 存储类型</span></span><br><span class="line">    uint32_t length;<span class="comment">// 元素个数</span></span><br><span class="line">    int8_t contents[];  <span class="comment">// 存储内存</span></span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure><p>整数集合适用于集合所有元素都是整数且集合元素数量较小的时候，与哈希表相比，整数集合的优势在于集中存储，节省空间。</p><h3 id="编码转换-3"><a href="#编码转换-3" class="headerlink" title="编码转换"></a>编码转换</h3><p>使用intset条件：<strong>元素个数小于512</strong> &amp;&amp; <strong>所有元素类型都是整数</strong>。</p><p>且编码只能由<code>intset</code>转换为<code>hashtable</code>。</p><h2 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h2><h3 id="概括-3"><a href="#概括-3" class="headerlink" title="概括"></a>概括</h3><p>与集合唯一不同的就是zset中的<strong>元素是有序</strong>的，其值也不能重复。zset其为每个元素配一个<code>score</code>作为排序依据。</p><h3 id="内部编码-4"><a href="#内部编码-4" class="headerlink" title="内部编码"></a>内部编码</h3><p><code>zset</code>内部编码使用<code>ziplist</code>或<strong>跳跃表</strong>（<code>skiplist</code>）。</p><p>skiplist是一种有序的数据结构，通过在每个节点维持多个指向其他节点的指针，从而达到快速访问的目的。除了跳跃表，实现有序数据结构的另一种典型实现是平衡树；大多数情况下，跳跃表的效率可以和平衡树媲美，且<strong>跳跃表实现比平衡树简单很多多多多</strong>，因此redis中选用跳跃表代替平衡树。跳跃表支持平均O(logN)、最坏O(N)的复杂点进行节点查找，并支持顺序操作。Redis的跳跃表实现由<code>zskiplist</code>和<code>zskiplistNode</code>两个结构组成：前者用于保存<em>跳跃表信息（如头结点、尾节点、长度等）</em>，后者用于表示<em>跳跃表节点</em>。</p><h3 id="编码转换-4"><a href="#编码转换-4" class="headerlink" title="编码转换"></a>编码转换</h3><p>使用ziplist条件：<strong>zset中元素小于128个</strong> &amp;&amp; <strong>zset中的元素长度都小于64byte</strong>。</p><p>编码只能由<code>ziplist</code>转换为<code>skiplist</code>。</p><h1 id="redis内存应用"><a href="#redis内存应用" class="headerlink" title="redis内存应用"></a>redis内存应用</h1><h2 id="估算redis内存使用量"><a href="#估算redis内存使用量" class="headerlink" title="估算redis内存使用量"></a>估算redis内存使用量</h2><p>需要了解redis内部编码以及常用的数据结构。</p><p>Redis是<code>Key-Value</code>数据库，因此对每个键值对都会有一个<code>dictEntry</code>，里面存储了指<em>向Key和Value的指针</em>；<em>next指向下一个dictEntry</em>，与本Key-Value无关。其中<strong>key指向sds存储键</strong>，<strong>value指向redisObject存储值</strong>。</p><img src="/2021/08/03/redis%E7%AC%94%E8%AE%B0/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B.png" class="" title="image-20210719220214746"><h3 id="redisObject"><a href="#redisObject" class="headerlink" title="redisObject"></a>redisObject</h3><p>Redis对象有5种类型；无论是哪种类型，Redis都不会直接存储，而是通过redisObject对象进行存储。</p><p>redisObject对象非常重要，Redis对象的类型、内部编码、内存回收、共享对象等功能，都需要redisObject支持。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="keyword">struct</span> redisObject &#123;</span><br><span class="line">　　unsigned <span class="keyword">type</span>:<span class="number">4</span>;<span class="comment">// 对象类型</span></span><br><span class="line">　　unsigned encoding:<span class="number">4</span>;<span class="comment">// 内部编码</span></span><br><span class="line">　　unsigned lru:REDIS_LRU_BITS; <span class="comment">/* lru time (relative to server.lruclock) */</span></span><br><span class="line">　　<span class="keyword">int</span> refcount;<span class="comment">// 对象被引用次数</span></span><br><span class="line">　　void *ptr;<span class="comment">// 指向具体的数据</span></span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure><p>在64位系统中，一个redisObject对象大小为16byte：<code>4bit + 4bit + 24bit + 4byte + 8byte = 16byte</code>。</p><h3 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h3><p>Redis没有直接使用C字符串(即以空字符’\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> sdshdr &#123;</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">len</span>;<span class="comment">// buf已使用长度</span></span><br><span class="line">    <span class="keyword">int</span> free;<span class="comment">// buf未使用长度</span></span><br><span class="line">    char buf[];<span class="comment">// 字节数组，用来存储字符串</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>buf数组的长度=free+len+1（其中1表示字符串结尾的空字符）；所以，一个SDS结构占据的空间为：free所占长度+len所占长度+ buf数组的长度=4+4+free+len+1=free+len+9。</p><h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><p>以最简单的字符串类型进行说明：</p><p>假设有90000个键值对，key大小为7byte，每个value大小也为7byte，key与value都不是整数，那么这90000个k-v所占用的内存空间大小是多少？</p><p>可以确定其编码方式为embstr，小于39byte。</p><p>每个dictEntry占据的空间：</p><ol><li>一个dictEntry占用24字节，jemalloc会分配32byte；</li><li>一个key7字节，SDS（key）需要7+9=16byte，jemalloc会分配16byte；</li><li>一个RedisObject，16字节，jemalloc会分配16byte；</li><li>一个value7字节，SDS（value）需要7+9=16byte，jemalloc会分配16byte</li></ol><p>综上：一个dictEntry需要<code>32 + 16 + 16 +16 = 80byte</code>。</p><p>bucket大小：小于90000的2^n最小值，为131072，每个元素为8byte（指针大小为8byte），一共需要：</p><p><code>90000*80 + 131072*8 = 8248576</code>。</p><p>作为对比将key和value的长度由7字节增加到8字节，则对应的SDS变为17个字节，jemalloc会分配32个字节，因此每个dictEntry占用的字节数也由80字节变为112字节。此时估算这90000个键值对占据内存大小为：<code>90000*112 + 131072*8 = 11128576</code>。</p><h2 id="优化内存占用"><a href="#优化内存占用" class="headerlink" title="优化内存占用"></a>优化内存占用</h2><p>（1）<strong>利用jemalloc特性进行优化</strong></p><p>上一小节所讲述的90000个键值便是一个例子。由于jemalloc分配内存时数值是不连续的，因此key/value字符串变化一个字节，可能会引起占用内存很大的变动；在设计时可以利用这一点。</p><p>例如，如果key的长度如果是8个字节，则SDS为17字节，jemalloc分配32字节；此时将key长度缩减为7个字节，则SDS为16字节，jemalloc分配16字节；则每个key所占用的空间都可以缩小一半。</p><p>（2）使<strong>用整型/长整型</strong></p><p>如果是整型/长整型，Redis会使用int类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型。</p><p>（3）<strong>共享对象</strong></p><p>利用共享对象，可以减少对象的创建（同时减少了redisObject的创建），节省内存空间。目前redis中的共享对象只包括10000个整数（0-9999）；可以通过调整REDIS_SHARED_INTEGERS参数提高共享对象的个数；例如将REDIS_SHARED_INTEGERS调整到20000，则0-19999之间的对象都可以共享。</p><p>考虑这样一种场景：论坛网站在redis中存储了每个帖子的浏览数，而这些浏览数绝大多数分布在0-20000之间，这时候通过适当增大REDIS_SHARED_INTEGERS参数，便可以利用共享对象节省内存空间。</p><p>（4）<strong>避免过度设计</strong></p><p>然而需要注意的是，不论是哪种优化场景，都要考虑内存空间与设计复杂度的权衡；而设计复杂度会影响到代码的复杂度、可维护性。</p><p>如果数据量较小，那么为了节省内存而使得代码的开发、维护变得更加困难并不划算；还是以前面讲到的90000个键值对为例，实际上节省的内存空间只有几MB。但是如果数据量有几千万甚至上亿，考虑内存的优化就比较必要了。</p><h2 id="关注内存碎片率"><a href="#关注内存碎片率" class="headerlink" title="关注内存碎片率"></a>关注内存碎片率</h2><p>内存碎片率是一个重要的参数，对redis 内存的优化有重要意义。</p><p>如果<em>内存碎片率过高（jemalloc在1.03左右比较正常）</em>，说明内存碎片多，内存浪费严重；这时便可以**考虑重启redis服务(redis安全重启)**，在内存中对数据进行重排，减少内存碎片。</p><p>如果内存碎片率小于1，说明redis内存不足，部分数据使用了虚拟内存（即swap）；由于虚拟内存的存取速度比物理内存差很多（2-3个数量级），此时redis的访问速度可能会变得很慢。因此必须设法增大物理内存（可以增加服务器节点数量，或提高单机内存），或减少redis中的数据。</p><p>要减少redis中的数据，除了选用合适的数据类型、利用共享对象等，还有一点是要设置合理的数据回收策略（maxmemory-policy），当内存达到一定量后，根据不同的优先级对内存进行回收。</p><h1 id="redis高可用"><a href="#redis高可用" class="headerlink" title="redis高可用"></a>redis高可用</h1><p>在Redis中，实现高可用的技术主要包括持久化、复制、哨兵和集群，下面分别说明它们的作用，以及解决了什么样的问题。</p><p>持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。</p><p>复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。</p><p>哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。</p><p>集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。</p><h1 id="redis-持久化"><a href="#redis-持久化" class="headerlink" title="redis 持久化"></a>redis 持久化</h1><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>Redis持久化分为RDB持久化和AOF持久化：前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存到硬盘（类似于MySQL的binlog）；由于AOF持久化的实时性更好，即当进程意外退出时丢失的数据更少，因此AOF是目前主流的持久化方式，不过RDB持久化仍然有其用武之地。</p><h2 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h2><p>RDB持久化是将当前进程中的数据生成快照保存到硬盘(因此也称作快照持久化)，保存的文件后缀是rdb；当Redis重新启动时，可以读取快照文件恢复数据。</p><h3 id="触发条件"><a href="#触发条件" class="headerlink" title="触发条件"></a>触发条件</h3><ul><li>手动触发</li></ul><p>save命令和bgsave命令都可以生成RDB文件。</p><p>save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。</p><p>bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程(即Redis主进程)则继续处理请求。</p><p>bgsave命令执行过程中，只有fork子进程时会阻塞服务器，而对于save命令，整个过程都会阻塞服务器，因此save已基本被废弃，线上环境要杜绝save的使用；后文中也将只介绍bgsave命令。此外，在自动触发RDB持久化时，Redis也会选择bgsave而不是save来进行持久化；下面介绍自动触发RDB持久化的条件。</p><ul><li>自动触发</li></ul><p>save m n</p><p>自动触发最常见的情况是在配置文件中通过save m n，指定当m秒内发生n次变化时，会触发bgsave。</p><p>save 900 1的含义是：当时间到900秒时，如果redis数据发生了至少1次变化，则执行bgsave；save 300 10和save 60 10000同理。当三个save条件满足任意一个时，都会引起bgsave的调用。</p><p>Redis的save m n，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的。</p><p>serverCron是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查 save m n 配置的条件是否满足，如果满足就执行bgsave。</p><p>dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。</p><p>save m n的原理如下：每隔100ms，执行serverCron函数；在serverCron函数中，遍历save m n配置的保存条件，只要有一个条件满足，就进行bgsave。对于每一个save m n条件，只有下面两条同时满足时才算满足：</p><p>（1）当前时间 - lastsave &gt; m</p><p>（2）dirty &gt;= n</p><ul><li>其他触发时机</li></ul><p>在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点；</p><p>执行shutdown命令时，自动执行rdb持久化。</p><h3 id="RDB常用设置"><a href="#RDB常用设置" class="headerlink" title="RDB常用设置"></a>RDB常用设置</h3><p>save m n：bgsave自动触发的条件；如果没有save m n配置，相当于自动的RDB持久化关闭，不过此时仍可以通过其他方式触发</p><p>stop-writes-on-bgsave-error yes：当bgsave出现错误时，Redis是否停止执行写命令；设置为yes，则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；设置为no，则Redis无视bgsave的错误继续执行写命令，当对Redis服务器的系统(尤其是硬盘)使用了监控时，该选项考虑设置为no</p><p>rdbcompression yes：是否开启RDB文件压缩</p><p>rdbchecksum yes：是否开启RDB文件的校验，在写入文件和读取文件时都起作用；关闭checksum在写入文件和启动文件时大约能带来10%的性能提升，但是数据损坏时无法发现</p><p>dbfilename dump.rdb：RDB文件名</p><p>dir ./：RDB文件和AOF文件所在目录</p><h2 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h2><h3 id="开启AOF"><a href="#开启AOF" class="headerlink" title="开启AOF"></a>开启AOF</h3><p>Redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：</p><p>appendonly yes</p><h3 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h3><p>由于需要记录Redis的每条写命令，因此AOF不需要触发，下面介绍AOF的执行流程。</p><p>AOF的执行流程包括：</p><ul><li><strong>命令追加</strong>(append)：将Redis的写命令追加到缓冲区aof_buf；</li><li><strong>文件写入</strong>(write)和<strong>文件同步</strong>(sync)：根据不同的同步策略将aof_buf中的内容同步到硬盘；</li><li><strong>文件重写</strong>(rewrite)：定期重写AOF文件，达到压缩的目的</li></ul><h4 id="命令追加"><a href="#命令追加" class="headerlink" title="命令追加"></a>命令追加</h4><p>Redis先将写命令追加到缓冲区，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为Redis负载的瓶颈。</p><h4 id="文件：写入write与同步sync函数"><a href="#文件：写入write与同步sync函数" class="headerlink" title="文件：写入write与同步sync函数"></a>文件：写入write与同步sync函数</h4><p>为了提高文件写入效率，在现代操作系统中，当用户调用write函数将数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但也带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失；因此<code>系统</code>同时提供了<code>fsync</code>、<code>fdatasync</code>等同步函数，可以<em>强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保数据的安全性</em>。</p><p>AOF<em>缓存区的同步文件</em>策略由参数<code>appendfsync</code>控制，各个值的含义如下：</p><ul><li><p><code>always</code>：命令写入aof_buf后立即调用系统fsync操作同步到AOF文件，fsync完成后线程返回。这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈，Redis只能支持大约几百TPS写入，严重降低了Redis的性能；即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令，而且会大大降低SSD的寿命。</p></li><li><p><code>no</code>：命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步；同步由操作系统负责，通常同步周期为30秒。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。</p></li><li><p><code>everysec</code>：命令写入aof_buf后调用系统write操作，write完成后线程返回；fsync同步文件操作由专门的线程每秒调用一次。<strong>everysec是前述两种策略的折中，是性能和数据安全性的平衡，因此是Redis的默认配置，也是我们推荐的配置</strong>。</p></li></ul><h4 id="文件重写"><a href="#文件重写" class="headerlink" title="文件重写"></a>文件重写</h4><p>文件重写是指定期重写AOF文件，减小AOF文件的体积。需要注意的是，AOF重写是<strong>把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取、写入操作!</strong></p><ul><li><p>文件重写之所以能够压缩AOF文件，原因在于：</p></li><li><p><em>过期的数据不再写入文件</em></p></li><li><p><em>无效的命令不再写入文件</em>：如有些数据被重复设值(set mykey v1, set mykey v2)、有些数据被删除了(sadd myset v1, del myset)等等</p></li></ul><p>多条命令可以合并为一个：如sadd myset v1, sadd myset v2, sadd myset v3可以合并为sadd myset v1 v2 v3。不过为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量在redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD中定义，不可更改，3.0版本中值是64。</p><p>文件重写的触发，分为手动触发和自动触发：</p><p>手动触发：直接调用bgrewriteaof命令，该命令的执行与bgsave有些类似：都是fork子进程进行具体的工作，且都只有在fork时阻塞。</p><p>自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数，以及aof_current_size和aof_base_size状态确定触发时机。</p><h3 id="AOF常用配置总结"><a href="#AOF常用配置总结" class="headerlink" title="AOF常用配置总结"></a>AOF常用配置总结</h3><p>appendonly no：是否开启AOF</p><p>appendfilename “appendonly.aof”：AOF文件名</p><p>dir ./：RDB文件和AOF文件所在目录</p><p>appendfsync everysec：fsync持久化策略</p><p>no-appendfsync-on-rewrite no：AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时</p><p>CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡</p><p>auto-aof-rewrite-percentage 100：文件重写触发条件之一</p><p>auto-aof-rewrite-min-size 64mb：文件重写触发提交之一</p><p>aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件</p><h2 id="RDB与AOF优缺点"><a href="#RDB与AOF优缺点" class="headerlink" title="RDB与AOF优缺点"></a>RDB与AOF优缺点</h2><h3 id="RDB持久化-1"><a href="#RDB持久化-1" class="headerlink" title="RDB持久化"></a>RDB持久化</h3><p>优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。</p><p>缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。</p><h3 id="AOF持久化-1"><a href="#AOF持久化-1" class="headerlink" title="AOF持久化"></a>AOF持久化</h3><p>与RDB持久化相对应，AOF的优点在于支持<strong>秒级持久化、兼容性好</strong>，缺点是<strong>文件大、恢复速度慢、对性能影响大</strong>。</p><h2 id="持久化策略选择"><a href="#持久化策略选择" class="headerlink" title="持久化策略选择"></a>持久化策略选择</h2><p>在介绍持久化策略之前，首先要明白无论是RDB还是AOF，持久化的开启都是要付出性能方面代价的：对于RDB持久化，一方面是bgsave在进行fork操作时Redis主进程会阻塞，另一方面，子进程向硬盘写数据也会带来IO压力；对于AOF持久化，向硬盘写数据的频率大大提高(everysec策略下为秒级)，IO压力更大，甚至可能造成AOF追加阻塞问题（后面会详细介绍这种阻塞），此外，AOF文件的重写与RDB的bgsave类似，会有fork时的阻塞和子进程的IO压力问题。相对来说，由于AOF向硬盘中写数据的频率更高，因此对Redis主进程性能的影响会更大。</p><p>下面的讨论也只是作为参考，实际方案可能更复杂更具多样性。</p><ol><li><p>如果Redis中的数据完全丢弃也没有关系（如Redis完全用作DB层数据的cache），那么无论是单机，还是主从架构，都可以不进行任何持久化。</p></li><li><p>在单机环境下（对于个人开发者，这种情况可能比较常见），如果可以接受十几分钟或更多的数据丢失，选择RDB对Redis的性能更加有利；如果只能接受秒级别的数据丢失，应该选择AOF。</p></li><li><p>但在多数情况下，我们都会配置主从环境，slave的存在既可以实现数据的热备，也可以进行读写分离分担Redis读请求，以及在master宕掉后继续提供服务。</p></li></ol><p>在这种情况下，一种可行的做法是：</p><p><em>master：完全关闭持久化</em>（包括RDB和AOF），这样可以让master的性能达到最好</p><p><em>slave：关闭RDB，开启AOF（如果对数据安全要求不高，开启RDB关闭AOF也可以）</em>，<em>并定时对持久化文件进行备份（如备份到其他文件夹，并标记好备份的时间）；然后关闭AOF的自动重写，然后添加定时任务，在每天Redis闲时（如凌晨12点）调用bgrewriteaof。</em></p><p>这里需要解释一下，为什么开启了主从复制，可以实现数据的热备份，还需要设置持久化呢？因为在一些特殊情况下，主从复制仍然不足以保证数据的安全，例如：</p><p>master和slave进程同时停止：考虑这样一种场景，如果master和slave在同一栋大楼或同一个机房，则一次停电事故就可能导致master和slave机器同时关机，Redis进程停止；如果没有持久化，则面临的是数据的完全丢失。</p><p>master误重启：考虑这样一种场景，master服务因为故障宕掉了，如果系统中有自动拉起机制（即检测到服务停止后重启该服务）将master自动重启，由于没有持久化文件，那么master重启后数据是空的，slave同步数据也变成了空的；如果master和slave都没有持久化，同样会面临数据的完全丢失。需要注意的是，即便是使用了哨兵(关于哨兵后面会有文章介绍)进行自动的主从切换，也有可能在哨兵轮询到master之前，便被自动拉起机制重启了。因此，应尽量避免“自动拉起机制”和“不做持久化”同时出现。</p><ol start="4"><li>异地灾备：上述讨论的几种持久化策略，针对的都是一般的系统故障，如进程异常退出、宕机、断电等，这些故障不会损坏硬盘。但是对于一些可能导致硬盘损坏的灾难情况，如火灾地震，就需要进行异地灾备。例如对于单机的情形，可以定时将RDB文件或重写后的AOF文件，通过scp拷贝到远程机器，如阿里云、AWS等；对于主从的情形，可以定时在master上执行bgsave，然后将RDB文件拷贝到远程机器，或者在slave上执行bgrewriteaof重写AOF文件后，将AOF文件拷贝到远程机器上。一般来说，由于RDB文件文件小、恢复快，因此灾难恢复常用RDB文件；异地备份的频率根据数据安全性的需要及其他条件来确定，但最好不要低于一天一次。</li></ol><h2 id="fork阻塞：CPU阻塞"><a href="#fork阻塞：CPU阻塞" class="headerlink" title="fork阻塞：CPU阻塞"></a>fork阻塞：CPU阻塞</h2><p>在Redis的实践中，众多因素限制了Redis单机的内存不能过大，例如：</p><ul><li>当面对请求的暴增，需要<em>从库扩容</em>时，Redis内存过大会导致<strong>扩容时间太长</strong>；</li><li>当<em>主机宕机</em>时，切换主机后需<em>要挂载从库</em>，Redis内存过大导致<strong>挂载速度过慢</strong>；</li><li>以及<strong>持久化过程中的fork操作</strong>，下面详细说明。</li></ul><p>父进程通过fork操作可以创建子进程；子进程创建后，父子进程共享代码段，不共享进程的数据空间，但是子进程会获得父进程的数据空间的副本。在操作系统fork的实际实现中，基本都采用了写时复制技术，即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间；但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分(内存的一页)制作一个副本。</p><p>虽然fork时，子进程不会复制父进程的数据空间，但是会<strong>复制内存页表</strong>（页表相当于内存的索引、目录）；父进程的数据空间越大，内存页表越大，fork时复制耗时也会越多。</p><p>在Redis中，无论是<code>RDB</code>持久化的<code>bgsave</code>，还是<code>AOF</code>重写的<code>bgrewriteaof</code>，都需要fork出子进程来进行操作。如果Redis内存过大，会导致fork操作时<strong>复制内存页表耗时过多</strong>；而Redis主进程在进行fork时，是完全阻塞的，也就意味着无法响应客户端的请求，会造成请求延迟过大。</p><p>为了减轻fork操作带来的阻塞问题，除了控制Redis单机内存的大小以外，还可以<em>适度放宽AOF重写</em>的触发条件、选用<em>物理机</em>或<em>高效支持fork操作的虚拟化技术</em>等，例如使用Vmware或KVM虚拟机，不要使用Xen虚拟机。</p><h2 id="AOF追加阻塞：硬盘阻塞"><a href="#AOF追加阻塞：硬盘阻塞" class="headerlink" title="AOF追加阻塞：硬盘阻塞"></a>AOF追加阻塞：硬盘阻塞</h2><p>在AOF中，如果AOF缓冲区的文件同步策略为everysec，则：<em>在主线程中，命令写入aof_buf后调用系统write操作，write完成后主线程返回；fsync同步文件操作由专门的文件同步线程每秒调用一次。</em></p><p>如果硬盘负载过高，那么fsync操作可能会超过1s；如果Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快；如果此时Redis进程异常退出，丢失的数据也会越来越多，可能远超过1s。</p><p>为此，Redis的处理策略是这样的：主线程每次<strong>进行AOF会对比上次fsync成功的时间</strong>；如果距上次<em>不到2s，主线程直接返回</em>；如果<em>超过2s，则主线程阻塞直到fsync同步完成</em>。因此，如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞；此外，<strong>使用everysec配置，AOF最多可能丢失2s的数据，而不是1s。</strong> </p><h1 id="集群作用"><a href="#集群作用" class="headerlink" title="集群作用"></a>集群作用</h1><p>集群，即Redis Cluster。</p><p>集群由多个节点(Node)组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责<strong>读写请求</strong>和集群<strong>信息的维护</strong>；从节点只进行<strong>主节点数据和状态信息的复制</strong>。</p><p>作用可归纳为两点：数据分区和高可用</p><h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>数据分区(或称数据分片)是集群最<strong>核心</strong>的功能。</p><p>集群将数据分散到多个节点：一方面突破了Redis<strong>单机内存大小</strong>的限制，存储容量大大增加；另一方面每个主节点都可以<strong>对外提供读服务和写服务</strong>，大大提高了集群的响应能力。</p><h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><p>集群支持<strong>主从复制</strong>和<strong>主节点的自动故障转移</strong>（与哨兵类似）：当任一节点发生故障时，集群仍然可以对外提供服务。</p><h1 id="集群的搭建"><a href="#集群的搭建" class="headerlink" title="集群的搭建"></a>集群的搭建</h1><p>集群的搭建可以分为四步：</p><ul><li>  （1）<strong>启动节点</strong>：将节点以集群模式启动，此时节点是独立的，并没有建立联系；</li><li>  （2）<strong>节点握手</strong>：让独立的节点连成一个网络；</li><li>  （3）<strong>分配槽</strong>：将16384个槽分配给主节点；</li><li>  （4）<strong>指定主从关系</strong>：为从节点指定主节点。</li></ul><p>实际上，<em>前三步</em>完成后集群便<em>可对外提供服务</em>；但<em>指定从节点</em>后，集群才能够<em>提供真正高可用</em>的服务。</p><h2 id="启动节点"><a href="#启动节点" class="headerlink" title="启动节点"></a>启动节点</h2><p>集群节点的启动仍然是使用<code>redis-server</code>命令，但需要使用<strong>集群模式启动</strong>。下面是port:7000节点的配置文件（只列出了节点正常工作关键配置，其他配置(如开启AOF)可以参照单机节点进行）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">redis-7000.conf</span></span><br><span class="line">port 7000</span><br><span class="line">cluster-enabled yes# 启动集群模式</span><br><span class="line">cluster-config-file &quot;node-7000.conf&quot;# 指定集群配置文件的位置</span><br><span class="line">logfile &quot;log-7000.log&quot;</span><br><span class="line">dbfilename &quot;dump-7000.rdb&quot;</span><br><span class="line">daemonize yes</span><br></pre></td></tr></table></figure><p><strong>当Redis节点以集群模式启动时，会首先寻找是否有集群配置文件，如果有则使用文件中的配置启动，如果没有，则初始化配置并将配置保存到文件中。</strong>集群配置文件由Redis节点维护，不需要人工修改。</p><p>编辑好配置文件后，使用redis-server命令启动该节点：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis-7000.conf</span><br></pre></td></tr></table></figure><p>需要特别注意，在<strong>启动节点阶段，节点是没有主从关系的，因此从节点不需要加slaveof配置</strong>。</p><h2 id="节点握手"><a href="#节点握手" class="headerlink" title="节点握手"></a>节点握手</h2><p>节点启动以后是相互独立的，并不知道其他节点存在；需要进行节点握手，将独立的节点组成一个网络。</p><p>节点握手使用cluster meet {ip} {port}命令实现。</p><h2 id="分配槽"><a href="#分配槽" class="headerlink" title="分配槽"></a>分配槽</h2><p>在Redis集群中，借助槽实现数据分区。</p><p><strong>集群有16384个槽，槽是数据管理和迁移的基本单位。当数据库中的16384个槽都分配了节点时，集群处于上线状态（ok）；如果有任意一个槽没有分配节点，则集群处于下线状态（fail）。</strong></p><p>分配槽使用cluster addslots命令，执行下面的命令将槽（编号0-16383）全部分配完毕：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7000 cluster addslots &#123;0..5461&#125;</span><br><span class="line">redis-cli -p 7001 cluster addslots &#123;5462..10922&#125;</span><br><span class="line">redis-cli -p 7002 cluster addslots &#123;10923..16383&#125;</span><br></pre></td></tr></table></figure><h2 id="指定主从关系"><a href="#指定主从关系" class="headerlink" title="指定主从关系"></a>指定主从关系</h2><p>集群中指定主从关系不再使用slaveof命令，而是使用cluster replicate命令；参数使用节点id。</p><p>通过cluster nodes获得几个主节点的节点id后，执行下面的命令为每个从节点指定主节点：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 8000 cluster replicate be816eba968bc16c884b963d768c945e86ac51ae</span><br><span class="line"><span class="meta">#</span><span class="bash"> 8000从节点端口 be816eba968bc16c884b963d768c945e86ac51ae主节点id</span></span><br></pre></td></tr></table></figure><h1 id="集群设计方案"><a href="#集群设计方案" class="headerlink" title="集群设计方案"></a>集群设计方案</h1><p>设计集群方案时，至少要考虑以下因素：</p><p>（1）<strong>高可用要求</strong>：根据故障转移的原理，至少需要3个主节点才能完成故障转移，且3个主节点不应在同一台物理机上；每个主节点至少需要1个从节点，且主从节点不应在一台物理机上；因此<strong>高可用集群至少包含6个节点</strong>。</p><p>（2）<strong>数据量和访问量</strong>：估算应用需要的数据量和总访问量(考虑业务发展，留有冗余)，结合每个主节点的容量和能承受的访问量(可以通过benchmark得到较准确估计)，计算需要的<strong>主节点数量</strong>。</p><p>（3）<strong>节点数量限制</strong>：Redis官方给出的<strong>节点数量限制为1000</strong>，主要是考虑节点间通信带来的消耗。在实际应用中应尽量避免大集群；如果节点数量不足以满足应用对Redis数据量和访问量的要求，可以考虑：(1)业务分割，大集群分为多个小集群；(2)减少不必要的数据；(3)调整数据过期策略等。</p><p>（4）<strong>适度冗余</strong>：Redis可以在不影响集群服务的情况下增加节点，因此节点数量适当冗余即可，不用太大。</p><h1 id="集群的基本原理"><a href="#集群的基本原理" class="headerlink" title="集群的基本原理"></a>集群的基本原理</h1><p>集群最核心的功能是数据分区，因此首先介绍<strong>数据的分区规则</strong>；然后介绍<strong>集群实现的细节</strong>：通信机制和数据结构；最后以cluster meet(节点握手)、cluster addslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。</p><h2 id="集群数据分区方案"><a href="#集群数据分区方案" class="headerlink" title="集群数据分区方案"></a>集群数据分区方案</h2><p>数据分区有顺序分区、哈希分区等，其中哈希分区由于其天然的随机性，使用广泛；<em>集群的分区方案便是哈希分区的一种。</em></p><p>哈希分区的基本思路是：<strong>对数据的特征值（如key）进行哈希，然后根据哈希值决定数据落在哪个节点</strong>。常见的哈希分区包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。</p><p>衡量数据分区方法好坏的标准有很多，其中比较重要的<strong>两个因素</strong>是(1)<strong>数据分布是否均匀</strong>(2)<strong>增加或删减节点对数据分布的影响</strong>。由于哈希的随机性，哈希分区基本可以保证数据分布均匀；因此在比较哈希分区方案时，重点要看增减节点对数据分布的影响。</p><h3 id="哈希取余分区"><a href="#哈希取余分区" class="headerlink" title="哈希取余分区"></a>哈希取余分区</h3><p>哈希取余分区思路非常简单：计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。该方案最大的问题是，当<strong>新增或删减</strong>节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。</p><h3 id="一致性哈希分区"><a href="#一致性哈希分区" class="headerlink" title="一致性哈希分区"></a>一致性哈希分区</h3><p>一致性哈希算法将整个哈希值空间组织成一个虚拟的圆环，范围为0-2^32-1；对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。</p><p>一致性哈希分区的主要问题在于，当节点数量较少时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡。</p><h3 id="带虚拟节点的一致性哈希"><a href="#带虚拟节点的一致性哈希" class="headerlink" title="带虚拟节点的一致性哈希"></a>带虚拟节点的一致性哈希</h3><p>该方案在一致性哈希分区的基础上，引入了虚拟节点的概念。<strong>Redis集群使用的便是该方案，其中的虚拟节点称为槽（slot）</strong>。槽是介于数据和实际节点之间的虚拟概念；<strong>每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据</strong>。引入槽以后，数据的映射关系由数据hash-&gt;实际节点，变成了数据<strong>hash-&gt;槽-&gt;实际节点</strong>。</p><p><strong>在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小。</strong></p><p>在Redis集群中，槽的数量为<strong>16384</strong>。</p><p>下面这张图很好的总结了Redis集群将数据映射到实际节点的过程：</p><img src="/2021/08/03/redis%E7%AC%94%E8%AE%B0/%E5%93%88%E5%B8%8C%E6%A7%BD%E5%AF%B9%E5%BA%94%E5%AE%9E%E9%99%85%E6%95%B0%E6%8D%AE%E8%A7%86%E5%9B%BE.png" class="" title="1174710-20190802191100758-1110624103"><p>（1）Redis对数据的特征值（一般是key）计算哈希值，使用的算法是CRC16。</p><p>（2）根据哈希值，计算数据属于哪个槽。</p><p>（3）根据槽与节点的映射关系，计算数据属于哪个节点。</p><h2 id="节点间通信机制"><a href="#节点间通信机制" class="headerlink" title="节点间通信机制"></a>节点间通信机制</h2><h3 id="两个端口"><a href="#两个端口" class="headerlink" title="两个端口"></a>两个端口</h3><p>在哨兵系统中，节点分为数据节点和哨兵节点：前者存储数据，后者实现额外的控制功能。<strong>在集群中，没有数据节点与非数据节点之分：所有的节点都存储数据，也都参与集群状态的维护</strong>。为此，集群中的每个节点，都提供了两个TCP端口：</p><ul><li>  <strong>普通端口</strong>：即我们在前面指定的端口(7000等)。普通端口主要用于为客户端提供服务（与单机节点类似）；但在节点间数据迁移时也会使用。</li><li>  <strong>集群端口</strong>：端口号是<strong>普通端口+10000</strong>（10000是固定值，无法改变），如7000节点的集群端口为17000。<strong>集群端口只用于节点之间的通信</strong>，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。</li></ul><h3 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h3><p>节点间通信，按照通信协议可以分为几种类型：单对单、广播、Gossip协议等。重点是广播和Gossip的对比。</p><p>广播是指向集群内所有节点发送消息；优点是集群的<strong>收敛速度快</strong>(集群收敛是指集群内所有节点获得的集群信息是一致的)，缺点是每条消息都要发送给所有节点，<strong>CPU、带宽等消耗较大</strong>。</p><p>Gossip协议的特点是：在节点数量有限的网络中，每个节点都<strong>“随机”</strong>的<strong>与部分节点通信</strong>（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。Gossip协议的优点有<strong>负载(比广播)低、去中心化、容错性高</strong>(因为通信有冗余)等；缺点主要是集群的<strong>收敛速度慢</strong>。</p><h3 id="消息类型"><a href="#消息类型" class="headerlink" title="消息类型"></a>消息类型</h3><p><em>集群中的节点采用固定频率（每秒10次）的定时任务进行通信相关的工作：判断是否需要发送消息及消息类型、确定接收节点、发送消息等。</em>如果集群状态发生了变化，如增减节点、槽状态变更，通过节点间的通信，所有节点会很快得知整个集群的状态，使集群收敛。</p><p>节点间发送的消息主要分为5种：meet消息、ping消息、pong消息、fail消息、publish消息：</p><ul><li>  <strong>MEET</strong>消息：在节点<strong>握手阶段</strong>，当节点收到客户端的<code>CLUSTER MEET</code>命令时，会向新加入的节点发送MEET消息，请求新节点加入到当前集群；新节点收到MEET消息后会回复一个PONG消息。</li><li>  <strong>PING</strong>消息：集群里<strong>每个节点每秒钟会选择部分节点发送PING消息，接收者收到消息后会回复一个PONG消息</strong>。PING消息的<em>内容是自身节点和部分其他节点的状态信息</em>；作用是彼此<strong>交换信息</strong>，以及<strong>检测节点是否在线</strong>。PING消息使用Gossip协议发送，接收节点的选择兼顾了收敛速度和带宽成本，具体规则如下：(1)<em>随机找5个节点，在其中选择最久没有通信的1个节点(2)扫描节点列表，选择最近一次收到PONG消息时间大于cluster_node_timeout/2的所有节点，防止这些节点长时间未更新。</em></li><li>  <strong>PONG</strong>消息：PONG消息封装了<strong>自身状态</strong>数据。可以分为两种：第一种是在<strong>接到MEET/PING消息后回复的PONG消息</strong>；第二种是指节点向集群<strong>广播PONG消息</strong>，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播PONG消息。</li><li>  <strong>FAIL</strong>消息：当一个<strong>主节点判断另一个主节点进入FAIL状态</strong>时，会向集群<em>广播这一FAIL消息</em>；接收节点会将这一FAIL消息保存起来，便于后续的判断。</li><li>  <strong>PUBLISH</strong>消息：节点收到<code>PUBLISH</code>命令后，<strong>会先执行</strong>该命令，<strong>然后向集群广播</strong>这一消息，<em>接收节点也会执行</em>该PUBLISH命令。</li></ul><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>节点需要专门的数据结构来存储集群的状态。所谓集群的状态，是一个比较大的概念，包括：集群是否处于上线状态、集群中有哪些节点、节点是否可达、节点的主从状态、槽的分布……</p><p>节点为了存储集群状态而提供的数据结构中，最关键的是<code>clusterNode</code>和<code>clusterState</code>结构：前者记录了<strong>一个节点的状态</strong>，后者记录了<strong>集群作为一个整体的状态</strong>。</p><p><strong>clusterNode</strong></p><p>clusterNode结构保存了一个节点的当前状态，包括创建时间、节点id、ip和端口号等。<em>每个节点都会用一个clusterNode结构记录自己的状态，并为集群内所有其他节点都创建一个clusterNode结构来记录节点状态。</em></p><p>下面列举了clusterNode的部分字段，并说明了字段的含义和作用：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">clusterNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//节点创建时间</span></span><br><span class="line">    <span class="keyword">mstime_t</span> ctime;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//节点id</span></span><br><span class="line">    <span class="keyword">char</span> name[REDIS_CLUSTER_NAMELEN];</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//节点的ip和端口号</span></span><br><span class="line">    <span class="keyword">char</span> ip[REDIS_IP_STR_LEN];</span><br><span class="line">    <span class="keyword">int</span> port;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//节点标识：整型，每个bit都代表了不同状态，如节点的主从状态、是否在线、是否在握手等</span></span><br><span class="line">    <span class="keyword">int</span> flags;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//配置纪元：故障转移时起作用，类似于哨兵的配置纪元</span></span><br><span class="line">    <span class="keyword">uint64_t</span> configEpoch;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//槽在该节点中的分布：占用16384/8个字节，16384个比特；每个比特对应一个槽：比特值为1，则该比特对应的槽在节点中；比特值为0，则该比特对应的槽不在节点中</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> slots[<span class="number">16384</span>/<span class="number">8</span>];</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//节点中槽的数量</span></span><br><span class="line">    <span class="keyword">int</span> numslots;</span><br><span class="line"> </span><br><span class="line">    …………</span><br><span class="line"> </span><br><span class="line">&#125; clusterNode;</span><br></pre></td></tr></table></figure><p>除了上述字段，clusterNode还包含节点连接、主从复制、故障发现和转移需要的信息等。</p><p><strong>clusterState</strong></p><p>clusterState结构保存了在当前节点视角下，<strong>集群所处的状态</strong>。主要字段包括：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">clusterState</span> &#123;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">//自身节点</span></span><br><span class="line">    clusterNode *myself;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//配置纪元</span></span><br><span class="line">    <span class="keyword">uint64_t</span> currentEpoch;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//集群状态：在线还是下线</span></span><br><span class="line">    <span class="keyword">int</span> state;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//集群中至少包含一个槽的节点数量</span></span><br><span class="line">    <span class="keyword">int</span> size;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//哈希表，节点名称-&gt;clusterNode节点指针</span></span><br><span class="line">    dict *nodes;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//槽分布信息：数组的每个元素都是一个指向clusterNode结构的指针；如果槽还没有分配给任何节点，则为NULL</span></span><br><span class="line">    clusterNode *slots[<span class="number">16384</span>];</span><br><span class="line"> </span><br><span class="line">    …………</span><br><span class="line">     </span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure><p>除此之外，clusterState还包括故障转移、槽迁移等需要的信息。</p><h2 id="集群命令实现"><a href="#集群命令实现" class="headerlink" title="集群命令实现"></a>集群命令实现</h2><p>以<code>cluster meet</code>(节点握手)、<code>cluster addslots</code>(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。</p><p>假设要向A节点发送<code>cluster meet</code>命令，将<em>B节点加入到A所在的集群</em>，则A节点收到命令后，执行的操作如下：</p><ol><li><p> <em>A</em>为B<em>创建一个clusterNode结构</em>，并将其<em>添加到clusterState的nodes</em>字典中</p></li><li><p> A向B发送<code>MEET</code>消息-一次握手</p></li><li><p> <em>B收到MEET</em>消息后，会为A<em>创建一个clusterNode结构</em>，并将其<em>添加到clusterState的nodes</em>字典中</p></li><li><p> B回复A一个<code>PONG</code>消息-一次握手</p></li><li><p> A收到B的PONG消息后，便知道B已经成功接收自己的MEET消息</p></li><li><p> 然后，A向B返回一个PING消息-一次握手</p></li><li><p> B收到A的PING消息后，便知道A已经成功接收自己的PONG消息，握手完成</p></li><li><p> 之后，<em>A</em>通过Gossip协议<em>将B的信息广播给集群内其他节点</em>，<em>其他节点也会与B握手</em>；一段时间后，集群收敛，B成为集群内的一个普通节点</p></li></ol><p>通过上述过程可以发现，集群中两个节点的握手过程与TCP类似，都是三次握手：A向B发送MEET；B向A发送PONG；A向B发送PING。保证可靠性</p><p><strong>cluster addslots</strong></p><p>集群中<em>槽的分配信息，存储在clusterNode的slots数组和clusterState的slots数组中</em>；二者的区别在于：前者存储的是<strong>该节点中分配了哪些槽</strong>，后者存储的是<strong>集群中所有槽分别分布在哪个节点</strong>。</p><p>cluster addslots命令接收一个槽或多个槽作为参数，例如在A节点上执行cluster addslots {0..10}命令，是将编号为0-10的槽分配给A节点，具体执行过程如下：</p><ol><li><p> <em>遍历输入槽，检查它们是否都没有分配，如果有一个槽已分配，命令执行失败；方法是检查输入槽在clusterState.slots[]中对应的值是否为NULL。</em></p></li><li><p> <em>遍历输入槽，将其分配给节点A；方法是修改clusterNode.slots[]中对应的比特为1，以及clusterState.slots[]中对应的指针指向A节点</em></p></li><li><p> A节点执行完成后，通过节点通信机制<em>通知其他节点</em>，所有节点都会知道0-10的槽分配给了A节点</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;redis的主从复制&quot;&gt;&lt;a href=&quot;#redis的主从复制&quot; class=&quot;headerlink&quot; title=&quot;redis的主从复制&quot;&gt;&lt;/a&gt;redis的主从复制&lt;/h1&gt;&lt;p&gt;当存在多台redis服务器的时候，会有一台主服务器master，以及若干台从</summary>
      
    
    
    
    <category term="redis" scheme="http://example.com/categories/redis/"/>
    
    
    <category term="redis主从复制" scheme="http://example.com/tags/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
    <category term="redis高可用" scheme="http://example.com/tags/redis%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
    <category term="redis集群" scheme="http://example.com/tags/redis%E9%9B%86%E7%BE%A4/"/>
    
    <category term="redis数据类型" scheme="http://example.com/tags/redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
    
    <category term="redis编码" scheme="http://example.com/tags/redis%E7%BC%96%E7%A0%81/"/>
    
    <category term="redis持久化" scheme="http://example.com/tags/redis%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>kafka</title>
    <link href="http://example.com/2021/08/03/kafka%E5%85%AB%E8%82%A1%E6%96%87/"/>
    <id>http://example.com/2021/08/03/kafka%E5%85%AB%E8%82%A1%E6%96%87/</id>
    <published>2021-08-03T15:04:44.000Z</published>
    <updated>2021-08-03T15:06:21.727Z</updated>
    
    <content type="html"><![CDATA[<p>面试角度看kafka</p><p>取材于微信公众号《码哥字节》。</p><h1 id="讲一讲分布式消息中间件"><a href="#讲一讲分布式消息中间件" class="headerlink" title="讲一讲分布式消息中间件"></a>讲一讲分布式消息中间件</h1><h3 id="什么是分布式消息中间件"><a href="#什么是分布式消息中间件" class="headerlink" title="什么是分布式消息中间件"></a>什么是分布式消息中间件</h3><p>分布式消息是一种<strong>通信</strong>机制，与RPC、HTTP、RMI等不一样，消息中间件采用<strong>分布式中间代理</strong>的方式进行通信。如上图所示，采用了消息中间件之后，上游业务系统发送消息，先存储在消息中间件，让然后右消息中间件将消息分发到对应的业务模块应用（<strong>分布式生产者–消费者</strong> 模式）。这种异步方式，减少了服务之间的耦合度。</p><h3 id="消息中间件的作用"><a href="#消息中间件的作用" class="headerlink" title="消息中间件的作用"></a>消息中间件的作用</h3><p>在系统架构中引用额外的组件，必然会提高系统的架构复杂度和运维的难度。那么使用分布式消息中间件有什么优势？消息中间件在系统中又起什么作用？</p><ul><li>  解耦</li><li>  数据冗余</li><li>  扩展性</li><li>  削峰</li><li>  可恢复性</li><li>  顺序保证</li><li>  缓冲</li><li>  异步通信</li></ul><p>消息中间件的<em>使用场景</em>是什么？<strong>异步</strong>通信，消息<strong>存储</strong>处理。</p><p>消息中间件<em>选型</em>？<strong>语言</strong>，<strong>协议</strong>、HA、<strong>数据可靠性</strong>、<strong>性能</strong>、<strong>事务</strong>、生态、<strong>简易</strong>、<strong>推拉</strong>模式。</p><h1 id="kafka基本概念和架构"><a href="#kafka基本概念和架构" class="headerlink" title="kafka基本概念和架构"></a>kafka基本概念和架构</h1><p>kafka架构中的一般概念：</p><ul><li><p>  <code>Producer</code>：生产者。也就是消息发送的一方。生产者负责创建消息，然后将其发送到kafka。</p></li><li><p>  <code>Consumer</code>：消费者。也就是接收消息的一方。消费者连接到kafka上接收消息，然后对消息进行处理。</p></li><li><p>  <code>Consumer Group</code>：一个<em>消费者组</em>可以包含一个或多个消费者。使用<em>多分区 + 多消费者</em>方式能极大的提高数据下游的<strong>处理速度</strong>，<strong>同一消费组不会重复消费消息</strong>；同样的，不同消费组中的消费者消费消息时是互不影响的。kafka就是通过消费组的方式实现消息<strong>P2P模式</strong>和<strong>广播模式</strong>。</p></li><li><p>  <code>Broker</code>：服务代理节点。Broker是kafka的服务节点，即kafka的<em>服务器</em>。</p></li><li><p>  <code>Topic</code>：Kafka中的<em>消息以Topic为单位进行划分</em>，生产者将消息发送到特定的Topic，而消费者负责订阅Topic的消息进行消费。</p></li><li><p>  <code>Partition</code>：Topic是一个<em>逻辑概念</em>，它可以<strong>区分为多个分区</strong>，<em>每个分区只属于单个主题</em>。<em>同一主题下不同分区包含的消息是不同的</em>，分区在<strong>存储层面</strong>可以看作一个<strong>可追加的日志（log）文件</strong>，消息在被追加到分区日志文件的时候都会分配一个特定的<strong>偏移量（offset）</strong>。</p></li><li><p>  <code>Replication</code>：<code>副本</code>。是kafka保证<strong>数据高可用</strong>的方式，kafka同一partition的数据可以在多个broker上存在多个副本，通常只有<em>主副本</em>对外提供<strong>读写服务</strong>，当主副本所在broker崩溃或发生网络异常时，kafka会在Controller的管理下<strong>重新选择新的Leader副本</strong>对外提供读写服务。</p></li><li><p><code>Record</code>：<em>实际写入kafka中并可以被读取的消息记录</em>。每个record包含了<code>key</code>、<code>value</code>、<code>timestamp</code>。</p><p>  <strong>kafka Topic Partition (offset) Layout：</strong></p>  </li></ul><p><em>kafka将topic进行分区，分区可以并发读写。</em></p><p><strong>Kafka Consumer Offset:</strong></p><h2 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h2><ul><li><p>  Broker注册：Broker是分布式部署并且之间相互独立。zookeeper用来管理注册到集群的所有broker节点。</p></li><li><p>  Topic注册：在kafka中同一个topic的消息会被分成多个分区并将其分配在多个broker上，这些分区信息以及与broker的对应关系也都是由zookeeper维护。</p></li><li><p>  生产者负载均衡：由于同一个topic消息会被分区并将其分不到多个broker上，因此，生产者需要将这些消息合理的发送到这些分布式的broker上。</p></li><li><p>消费者负载均衡：与生产者类似，kafka的消费者同样需要进行负载均衡来实现多个消费者合理的从对应的broker上接收消息。每个消费者组包含若干消费者，每条消息都只会发给一个消费者组中的一个消费者。不同消费者组消费自己topic的消息，互不干扰。</p></li></ul><h3 id="简单讲下kafka架构"><a href="#简单讲下kafka架构" class="headerlink" title="简单讲下kafka架构"></a>简单讲下kafka架构</h3><p>producer、Consumer、Consumer Group、Topic、Partition</p><h3 id="kafka是推模式还是拉模式，推拉的区别"><a href="#kafka是推模式还是拉模式，推拉的区别" class="headerlink" title="kafka是推模式还是拉模式，推拉的区别"></a>kafka是推模式还是拉模式，推拉的区别</h3><p>kafka producer向broker发送消息时push模式，Consumer消费采取的是pull模式。使用拉取模式，让Consumer自己管理offset，可以提供读取性能。</p><h3 id="kafka如何广播"><a href="#kafka如何广播" class="headerlink" title="kafka如何广播"></a>kafka如何广播</h3><p>Consumer Group</p><h3 id="kafka消息是否有序的"><a href="#kafka消息是否有序的" class="headerlink" title="kafka消息是否有序的"></a>kafka消息是否有序的</h3><p>Topic级别无序，partition级别有序</p><h3 id="kafka是否支持读写分离"><a href="#kafka是否支持读写分离" class="headerlink" title="kafka是否支持读写分离"></a>kafka是否支持读写分离</h3><p>不支持。只有leader对外提供读写功能</p><h3 id="kafka如何保证数据高可用"><a href="#kafka如何保证数据高可用" class="headerlink" title="kafka如何保证数据高可用"></a>kafka如何保证数据高可用</h3><p>主从副本，ack，HW</p><h3 id="kafka中zookeeper的作用"><a href="#kafka中zookeeper的作用" class="headerlink" title="kafka中zookeeper的作用"></a>kafka中zookeeper的作用</h3><p>对集群的管理，元数据的管理</p><h3 id="是否支持事务"><a href="#是否支持事务" class="headerlink" title="是否支持事务"></a>是否支持事务</h3><p>0.11后支持</p><h3 id="分区数是否可以减少"><a href="#分区数是否可以减少" class="headerlink" title="分区数是否可以减少"></a>分区数是否可以减少</h3><p>不可以，不然会丢失数据</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;面试角度看kafka&lt;/p&gt;
&lt;p&gt;取材于微信公众号《码哥字节》。&lt;/p&gt;
&lt;h1 id=&quot;讲一讲分布式消息中间件&quot;&gt;&lt;a href=&quot;#讲一讲分布式消息中间件&quot; class=&quot;headerlink&quot; title=&quot;讲一讲分布式消息中间件&quot;&gt;&lt;/a&gt;讲一讲分布式消息中间件&lt;</summary>
      
    
    
    
    <category term="kafka" scheme="http://example.com/categories/kafka/"/>
    
    
    <category term="kafka" scheme="http://example.com/tags/kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="zookeeper" scheme="http://example.com/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>tcp_ip八股文</title>
    <link href="http://example.com/2021/08/03/tcp-ip%E5%85%AB%E8%82%A1%E6%96%87/"/>
    <id>http://example.com/2021/08/03/tcp-ip%E5%85%AB%E8%82%A1%E6%96%87/</id>
    <published>2021-08-03T15:00:18.000Z</published>
    <updated>2021-09-14T07:55:08.324Z</updated>
    
    <content type="html"><![CDATA[<h1 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h1><p>udp协议属于传输层协议。</p><h2 id="udp报文协议"><a href="#udp报文协议" class="headerlink" title="udp报文协议"></a>udp报文协议</h2><table><thead><tr><th align="center">16位源端口号</th><th align="center">16位目的端口号</th></tr></thead><tbody><tr><td align="center">16位UDP长度</td><td align="center">16为UDP校验和</td></tr><tr><td align="center">数据内容</td><td align="center">数据内容</td></tr></tbody></table><p>0                                                                        15 16                                                                                            31</p><p>源端口：0<del>65535，1</del>1024为保留端口，为标准的服务端口</p><p>UDP长度：header + data 总长度</p><p>UDP校验和：伪头部、头部、data 三部分的校验和</p><p>数据内容：上层应用的数据，可以没有数据</p><ul><li>若校验和失败，就会丢弃数据</li></ul><h2 id="UDP协议的特点"><a href="#UDP协议的特点" class="headerlink" title="UDP协议的特点"></a>UDP协议的特点</h2><ul><li><p>无链接</p><p>  只需知道对端的IP和PORT就可以发送数据，不需要建立链接</p></li><li><p>不可靠</p><p>  没有确认机制，没有重传机制。若因为网络原因没有发送到对端，UDP协议层也不会返回任何错误给应用层。</p></li><li><p>面向数据报</p><p>  应用层交给UDP多长的报文，UDP就会直接传送过去，不会进行拆分。接收时也是一次性接受全部传送的数据报。</p></li><li><p>UDP存在接收缓冲区，单步存在发送缓冲区</p><p>  UDP在发送数据时没有缓冲区，会直接将数据传递给内核，内核会直接调用网卡进行传输。因为UDP不需要保证可靠机制，所以报文丢失之后不需要再重新发送。而UDP虽然有接受缓冲区，但是不会保证收到的数据顺序，缓冲区满了之后就会将新接收的报文丢弃。</p></li><li><p>双全工通信</p><p>  UDP可同时接收和发送数据报文。</p></li></ul><p>UDP协议首部有一个16位的长度，说明UDP最长可以发送64k数据(包含首部)，超过之后就需要我们手工在应用层分包。</p><h2 id="常见的UDP协议"><a href="#常见的UDP协议" class="headerlink" title="常见的UDP协议"></a>常见的UDP协议</h2><ul><li>NFS：网络文件传输协议</li><li>TFTP：简单文件传输协议</li><li>DHCP：动态主机配置协议</li><li>DNS：域名解析协议</li><li>自定义的UDP协议等</li></ul><h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><p>TCP全称为<strong>传输控制</strong>协议，必需对数据的传输进行控制。</p><h2 id="tcp协议报文格式"><a href="#tcp协议报文格式" class="headerlink" title="tcp协议报文格式"></a>tcp协议报文格式</h2><ul><li><p>源/目的端口：标识数据从哪儿来要去哪儿</p></li><li><p>32位序号：序号保证了可靠传输。TCP将传输的每一个字节都编号了，序号是本报文段数据的第一个字节编号。例如：一个报文段序号是300，其数据部分共有100字节，则下一个报文段序号为401。</p></li><li><p>32位徐仁序列号：每一个ACK对应这个确认号，它指明下一个期待收到的字节序号。其表明之前收到的所有数据都已经正确无误。确认号只有当ACK标志为1的时候才有效。<strong>建立连接时，SYN报文的ACK标志为0</strong>。</p></li><li><p>4位首部长度(数据偏移)：表示该TCP头部有多少个32位bit，所以TCP头部大长度是<strong>15*4=60</strong>。TCP默认报文大小为20字节。</p></li><li><p>6个标志位：</p><ul><li>URG:它为了标志紧急指针是否有效。</li><li>ACK：标识确认号是否有效。</li><li>PSH:提示接收端应用程序立即将接收缓冲区的数据拿走。</li><li>RST：它是为了处理异常连接的， 告诉连接不一致的一方，我们的连接还没有建立好， 要求对方重新建立连接。我们把携带RST标识的称为复位报文段。</li><li>SYN：请求建立连接；把携带SYN标识的称为同步报文段。</li><li>FIN：通知对端本段要关闭链接了；把携带FIN标识的称为结束报文段。</li></ul></li><li><p>16位紧急指针：当有些报文想优先被处理时(原来是按序处理)，设置紧急指针指向该报文，同时将紧急指针有效位置1。</p></li><li><p>16位窗口大小：若发送方发送速度大于接收方发送速度(比如发送方发送大量数据)，这时可能会导致大量数据丢失，接收方可以发送消息给发送方让其发送慢一点，这就是<strong>流量控制</strong>。接收方将自己接受缓冲器剩余空间的大小告诉发送方叫做<strong>16位窗口大小</strong>。窗口大小最大是2^16^，也就是64k。</p></li><li><p>16位校验和：发送端填充，<code>CRC</code>校验。</p></li></ul><h2 id="TCP确认应答机制"><a href="#TCP确认应答机制" class="headerlink" title="TCP确认应答机制"></a>TCP确认应答机制</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant 主机A</span><br><span class="line">participant 主机B</span><br><span class="line">主机A-&gt;&gt;主机B:数据：1~1000</span><br><span class="line">主机B-&gt;&gt;主机A:确认应答，下一个是1001</span><br><span class="line">主机A-&gt;&gt;主机B:数据：1001~2000</span><br><span class="line">主机B-&gt;&gt;主机A:确认应答，下一个是2001</span><br></pre></td></tr></table></figure><p>发送端放一条数据到接收端，接收端在收到一条报文后，向发送端发送一条<code>ACK</code>确认报文，告诉发送端已经成功的接收到了消息，并且希望收到的下一个序列号是多少。这个确认号就是下一个报文的序列号。</p><h2 id="超时重传机制"><a href="#超时重传机制" class="headerlink" title="超时重传机制"></a>超时重传机制</h2><p>注：虚线标识未可达，实线表示到达。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant 主机A</span><br><span class="line">participant 主机B</span><br><span class="line"> 主机A--&gt;&gt;主机B:数据：1~1000</span><br><span class="line"> Note right of 主机A:数据1到1000未到达主机B</span><br><span class="line"> Note left of 主机A:一段特定的时间间隔过后</span><br><span class="line">  主机A-&gt;&gt;主机B:数据：1~1000</span><br><span class="line">  主机B-&gt;&gt;主机A:确认应答，下一个是1001</span><br></pre></td></tr></table></figure><p>在传输过程中的超时重传机制。A给B发送数据，若A在一定时间没有收到B的确认应答消息，会进行重发。其中可能存在B没有收到A的消息，这时B不会应答；也可能是B的应答A没有收到，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant A</span><br><span class="line">participant B</span><br><span class="line">A-&gt;&gt;B:数据：1~1000</span><br><span class="line">B--&gt;&gt;A:确认应答，下一个是1001</span><br><span class="line">Note right of A:未收到B发送的确认应答消息</span><br><span class="line">Note left of A:一段时间间隔之后</span><br><span class="line">A-&gt;&gt;B:数据：1~1000</span><br><span class="line">B-&gt;&gt;A:确认应答，下一个是1001</span><br></pre></td></tr></table></figure><p>此时主机B就会收到很多重复的包，可以利用前面的16位序列号将重复的包识别出来并丢弃，这样就做到了数据去重的效果。</p><p>超时时间的确认：</p><p>​    若超时时间间隔设置的太长，会影响整体重传的效率；若设置的时间间隔太短，就可能会频繁的发送重复的包。TCP为了保证不同的网络传输效率的高效，会动态的计算这个时间间隔。</p><p>​    在linux中，以500ms为一个时间单位进行控制。若超过500ms没有收到应答，则重发一次；若重发一次之后仍未等待到确认应答，则等待2*500ms进行重发，下一次重发为4*500ms。依次类推，成指数级增长。当累计到一定次数，则认为网络或者对端主机出现异常，关闭链接。</p><h1 id="三次握手与四次挥手"><a href="#三次握手与四次挥手" class="headerlink" title="三次握手与四次挥手"></a>三次握手与四次挥手</h1><h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p>三次握手也就是建立连接的过程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant Client</span><br><span class="line">participant Server</span><br><span class="line">Note over Client,Server:CLOSED</span><br><span class="line">Note over Server:LISTEN</span><br><span class="line">Client -&gt;&gt; Server:连接请求：SYN=1,seq=x</span><br><span class="line">Note over Client:SYN-SENT</span><br><span class="line">Server -&gt;&gt; Client:SYN=1,ACK=1,seq=y,ack=x+1</span><br><span class="line">Note over Server:SYN-RCVD</span><br><span class="line">Client -&gt;&gt; Server:ACK=1,seq=x+1,ack=y+1</span><br><span class="line">Note over Client,Server:ESTABLISHED</span><br><span class="line">Note left of Server:数据传输开始</span><br></pre></td></tr></table></figure><ol><li>服务器由CLOSED状态转换为LISTEN(监听)状态。</li><li>客户端发送连接请求报文到服务端。此时报文中的同步标志位SYN置为1，选择一个初始序列号seq=x，并将客户端置为SYN-SENT(同步已发送态)状态。注意，TCP规定SYN不能携带数据，但是会消耗一个序列号。</li><li>TCP服务端收到报文，如果同意连接则发送应答确认报文。其中，确认报文的SYN=1，ACK=1，确认序列号为x+1，服务端也会初始化生成一个序列号y，此时服务端进入SYN-RCVD(同步收到态)状态。这个报文同样不能携带数据，但是也会消耗一个序列号。</li><li>TCP客户端收到确认报文后，还需要向服务器应答一个确认报文(为了链接的可靠性)。其中，ACK=1，确认序列号ack=y+1，自己的序列号req=x+1。</li><li>连接建立，CS之间可以相互通信收发数据。</li></ol><h3 id="第三次握手的意义："><a href="#第三次握手的意义：" class="headerlink" title="第三次握手的意义："></a>第三次握手的意义：</h3><p>​    主要是为了防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送的第一个请求连接并且没有丢失，只是因为在网络中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时之前滞留的那一次请求连接，因为网络通畅了, 到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的费。 </p><p>​    如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。</p><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">participant Client</span><br><span class="line">participant Server</span><br><span class="line">Note over Client,Server:ESTABLISHED</span><br><span class="line">Note left of Client:主动关闭链接</span><br><span class="line">Client -&gt;&gt; Server:连接请求：FIN=1,seq=u</span><br><span class="line">Note over Client:FIN-WAIT1</span><br><span class="line">Server -&gt;&gt; Client:ACK=1,seq=v,ack=u+1</span><br><span class="line">Note over Server:CLOSE-WAIT</span><br><span class="line">Note over Client:FIN-WAIT2</span><br><span class="line">Server -&gt;&gt; Client:数据传输</span><br><span class="line">Server -&gt;&gt; Client:FIN=1,ACK=1,seq=w,ack=u+1</span><br><span class="line">Note over Server:LAST-ACK</span><br><span class="line">Client -&gt;&gt; Server:ACK=1,seq=u+1,ack=w+1</span><br><span class="line">Note over Client:TIME-WAIT (2MSL)</span><br><span class="line">Note over Client,Server:CLOSED</span><br></pre></td></tr></table></figure><p>在建立连接后，两边都可以断开连接。</p><p>此时客户端和服务器都是处于ESTABLISHED状态，然后客户端主动断开连接，服务器被动断开连接。</p><ol><li>客服端发送释放连接报文FIN，这时客户端不再发送数据。此时FIN=1,序列号seq=u(等于前面已发送的数据的最后一个字节的序号加1)，客户端进入FIN-WAIT-1状态。TCP规定及时FIN报文不携带数据也要消耗一个序列号。</li><li>服务端收到FIN报文，发出确认报文ACK。其中ACK=1,确认序列号ack=u+1，并且带上自己的序列号v。此时服务端进入CLOSE-WAIT(关闭等待)状态。 此时， TCP服务器会通知上层的应用，客服端向服务器方向释放了连接，处于半关闭状态，即客户端没有数据需要发送了但服务端可以发送数据到客户端让客户端处理。</li><li>客服端收到服务端发送的ACK报文后，客户端进入FIN-WAIT-2状态。等待服务端发送FIN释放报文。</li><li>服务端将所有数据发送完之后，向客户端发送FIN释放报文。其中，FIN=1，ACK=1，此时自己的序列号seq=w，确认序列号ack=u+1。此时服务端进入了LAST-ACK(最终确认)状态，等待客户端的确认报文。</li><li>客户端收到服务端的FIN释放报文，必需发出确认ACK报文。其中ACK=1，确认序列号ack=w+1，自己的序列号req=u+1。此时客户端进入了TIME-WAIT(时间等待)状态，必需经过2*MSL(最长报文寿命时间段)之后才能进入CLOSED状态。</li></ol><h3 id="第四次握手为什么要等待2MSL时长"><a href="#第四次握手为什么要等待2MSL时长" class="headerlink" title="第四次握手为什么要等待2MSL时长"></a>第四次握手为什么要等待2MSL时长</h3><ul><li><p>ACK报文的可靠性</p><p>  保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。</p></li><li><p>去除无效报文</p><p>  防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。</p></li></ul><h3 id="为什么握手要三次，挥手要四次"><a href="#为什么握手要三次，挥手要四次" class="headerlink" title="为什么握手要三次，挥手要四次"></a>为什么握手要三次，挥手要四次</h3><p>​    建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。 </p><p>​    而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。</p><h3 id="建链之后，客户端故障了怎么处理"><a href="#建链之后，客户端故障了怎么处理" class="headerlink" title="建链之后，客户端故障了怎么处理"></a>建链之后，客户端故障了怎么处理</h3><p>​    TCP设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p><p>此种机制类似心跳检测机制。</p><h3 id="TIME-WAIT状态解读"><a href="#TIME-WAIT状态解读" class="headerlink" title="TIME-WAIT状态解读"></a>TIME-WAIT状态解读</h3><p>​        当我们实现一个TCP服务器时，我们把这个服务器运行起来然后再将服务器关闭掉，再次重新启动服务器会发现一个问题：就是不能马上再次绑定这个端口号和ip，需要等一会才可以重新绑定，其实等的这一会就是TIME_WAIT状态。</p><ul><li>TCP协议规定主动关闭连接的一方要处于TIME_ WAIT状态，等待两个MSL的时间后才能回到CLOSED状态。</li><li>当我们使用Ctrl-C终止了server，server是主动关闭连接的一方在TIME_WAIT期间仍然不能再次监听同样的server端口。</li><li>MSL在RFC1122中规定为两分钟(120s)，但是各操作系统的实现不同，在Centos7上默认配置的值是60s可以通过cat /proc/sys/net/ipv4/tcp_fin_timeout查看MSL的值。</li></ul><p>解决TIME_WAIT状态引起的bind失败的方法：</p><p>​        在server的TCP连接没有完全断开之前不允许重新绑定，也就是TIME_WAIT时间没有过，但是这样不允许立即绑定在某些情况下是不某些特定场景的：</p><ul><li>服务器需要处理非常大量的客户端的连接 (每个连接的生存时间可能很短，但是每秒都有很大数量的客户 端来请求)</li><li>这个时候如果由服务器端主动关闭连接(比如某些客户端不活跃，就需要被服务器端主动清理掉)，这样服务器端就会产生大量TIME_WAIT状态。</li><li>如果客户端的请求量很大，就可能导致TIME_WAIT的连接数很多，每个连接都会占用一个通信五元组(源ip, 源端口, 目的ip, 目的端口, 协议)。其中服务器的ip和端口和协议是固定的，如果新来的客户端连接的ip和端口号和TIME_WAIT占用的连接重复就造成等待。</li></ul><p>解决方法：使用setsockopt()设置socket描述符的选项SO_REUSEADDR为1，表示<strong>允许创建端口号相同但IP地址不同的多个socket描述符</strong>。</p><h1 id="滑动窗口机制"><a href="#滑动窗口机制" class="headerlink" title="滑动窗口机制"></a>滑动窗口机制</h1><p>​        <strong>确认应答策略</strong>对每一个发送的数据段都要给一个ACK确认应答，接收方收到ACK后再发送下一个数据段，但是这样做有一个比较大的缺点，就是<strong>性能较差</strong>，尤其是数据往返的时间较长的时候。</p><p>​        考虑一次发送多条数据，它是将多个段的等待时间重叠在一起。</p><p>​        窗口大小指的是无需等待确认应答而可以继续发送数据的最大值。若需要发送12个报文段。发送前四个段的时候，不需要等待任何ACK直接发送即可。当收到第一个ACK后滑动窗口向后移动，继续发送第五个段的数据，然后依次类推。<strong>操作系统内核为了维护</strong>这个滑动窗口，需要开辟<strong>发送缓冲区</strong>来记录当前还有哪些数据没有应答。只有确认应答过的数据，才能从缓冲区删掉，窗口越大，则网络的吞吐率就越高。滑动窗口<strong>左边代表已经发送过并且确认</strong>，可以从发送缓冲区中删除了，滑动窗口<strong>里边代表发送出去但是没有确认</strong>，滑动窗口<strong>右边代表还没有发送的</strong>数据。</p><h2 id="快重传"><a href="#快重传" class="headerlink" title="快重传"></a>快重传</h2><p>若出现丢包现象该怎么处理呢？</p><ol><li><p>数据到达接收方但丢失了应答报文？</p><p> ​    可以根据后面的应答ACK确认。假设发送了1~1000的数据，接收方接收到了但是返回的应答报文丢失。发送方继续发送1001——2000收到确认ACK 2001，则认为1-1000发送成功并成功接收了。</p></li><li><p>数据包之间丢失报文？</p><p> 当某一段报文1001-2000丢失后，发送端会一直收到1001的这样的ACK确认(就像在提醒发送端我想要的报文是1001开头)，若发送端连续三次收到这样的确认ACK，就会将1001-2000报文重发。这个时候接收端收到1001报文之后就会收到当前的报文段6001(假设前面发送到6000了，被放到了内核缓冲区中)。<strong>这种机制就叫做快重传</strong>。</p><p> ​    快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。由于不需要等待设置的重传计时器到期，能尽早重传未被确认的报文段，能提高整个网络的吞吐量。</p></li></ol><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>​        因为接收端的处理数据能力有限，因各种原因接收端的缓冲区被填满，如果这个时候发送端继续发送就会发生丢包现象，然后引起丢包重传等一系列连锁反应。因此要根据接收端处理数据的能力来控制发送端的发送速度。这就叫<strong>流量控制</strong>。</p><ol><li>接收端将自己可以接受的缓冲区大小放在TCP首部的窗口大小字段，通过ACK确认应答报文通知发送端。</li><li>窗口大小越大，说明吞吐量越大，当缓冲区快满了的时候，就会将窗口值设置为一个更小的值通知给发送端。</li><li>当窗口大小为0之后，发送端在接收到ACK确认报文之后就不会发送数据了。但是会定期发送一个<em>窗口探测数据端</em>(防止缓冲区满了之后无法继续通信)，使接收端把窗口大小发送给发送端。</li></ol><p>象，然后引起丢包重传等一系列连锁反应。因此要根据接收端处理数据的能力来控制发送端的发送速度。这就叫<strong>流量控制</strong>。</p><ol><li>接收端将自己可以接受的缓冲区大小放在TCP首部的窗口大小字段，通过ACK确认应答报文通知发送端。</li><li>窗口大小越大，说明吞吐量越大，当缓冲区快满了的时候，就会将窗口值设置为一个更小的值通知给发送端。</li><li>当窗口大小为0之后，发送端在接收到ACK确认报文之后就不会发送数据了。但是会定期发送一个<em>窗口探测数据端</em>(防止缓冲区满了之后无法继续通信)，使接收端把窗口大小发送给发送端。</li></ol><p>​        在TCP首部的窗口大小字段，大小为16位，数据大小为65535，但由于TCP首部还有40字节的选项中包含了一个窗口扩大因子M，所以实际实际大小是窗口字段左移M位。</p><h1 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h1><p>​        拥塞控制是TCP通信的每一方需要执行的一系列行为。这些行为是由一些特定的算法规定，用于防止网络因为大规模的通信而瘫痪。其基本方法是可以认为网络即将进入拥塞状态或已经拥塞而出现的丢包情况出现时，减缓TCP传输数据。其难点在于怎样精准的判断何时需要减缓且如何减缓TCP传输、何时恢复原有的速度。</p><h2 id="TCP拥塞检测"><a href="#TCP拥塞检测" class="headerlink" title="TCP拥塞检测"></a>TCP拥塞检测</h2><p>​        典型的TCP拥塞检测通常看是否有丢包出现，丢包在TCP中被用作判断拥塞发生与否指标。当然也有其他的一些方法，如时延测量、显式拥塞通知等等。</p><h2 id="慢启动算法"><a href="#慢启动算法" class="headerlink" title="慢启动算法"></a>慢启动算法</h2><p>​        若网络上有很多的计算机，可能当前的网络状态就已经比较拥堵，在不清楚当前网络状态下，贸然发送大量的数据是很有可能引起雪上加霜的，造成网络更加堵塞，所以需要缓慢探测可用传输资源，防止短时间内大量数据注入导致拥塞甚至瘫痪。慢启动算法就是为了这一目的设计而出的。<strong>在数据传输之初或重传计时器检测到丢包后执行慢启动</strong>，直到有丢包时执行拥塞避免算法。</p><p>​    注：慢启动算法和拥塞避免算法在同一时刻只会运行其中一个，但两者可相互切换。</p><p>​        <code>cwnd</code>为拥塞窗口大小，在发送开始的时候定义拥塞窗口大小为1，每次收到一个ACK应答拥塞窗口加1。每次发送数据包的时候，将<em>拥塞窗口</em>和<em>接收端主机反馈的窗口大小</em>做比较，取较小的值作为实际发送的窗口。<code>cwnd</code>是随时间以指数增长的。</p><p>​        <code>&quot;慢启动&quot;</code>只是指初使时慢，但是增长速度非常快。为了不增长的那么快，因此不能使<code>拥塞窗口</code>单纯的加倍，此处引入一个叫做<code>慢启动的阈值</code>当拥塞窗口超过这个阈值的时候，不再按照指数方式增长， 而是按照<code>线性方式</code>增长。这个阈值是慢启动阶段至拥塞避免阶段的转折点。</p><ul><li>当<code>TCP</code>开始启动的时候，慢启动<code>阈值</code>等于窗口最大值</li><li>在每次<code>超时重发</code>的时候，慢启动<code>阈值</code>会变成原来的一半同时拥塞窗口置回<code>1</code></li></ul><h2 id="拥塞避免算法"><a href="#拥塞避免算法" class="headerlink" title="拥塞避免算法"></a>拥塞避免算法</h2><p>​        在慢启动阶段，cwnd会快速增长，帮助确定一个慢启动阈值。一旦到达这阈值，意味着可能有更多的资源可被传输。若全部占用这些资源，将会使共享路由器队列的其他链接出现严重的丢包和重传情况，从而导致整个网络的不稳定。<em>为了获取更多资源而不影响其他的连接传输，引入了拥塞避免算法</em>。一旦进入慢启动阈值，TCP就会进入拥塞避免阶段，cwnd每次增长值近似于成功传输的数据段大小。这种随时间接近线性增长。</p><h3 id="拥塞控制与流量控制"><a href="#拥塞控制与流量控制" class="headerlink" title="拥塞控制与流量控制"></a>拥塞控制与流量控制</h3><p>​        拥塞控制是防止过多的流量进入网络中，使网络中的路由器或链路不至于过载，是一个全局性的过程。流量是点对点的通信量的控制，是一个端到端的控制问题，主要权衡发送端发送数据的速度，以便接收端能够接收。</p><p>​    无论是在<code>慢启动阶段</code>还是在<code>拥塞避免阶段</code>，只要发送方判断网络出现<code>拥塞</code>（其根据就是没有收到确认，虽然没有收到<code>确认</code>可能是其他原因的分组丢失，但是因为无法判定，所以都当做<code>拥塞</code>来处理），这时就把<code>慢启动门限</code>设置为<code>出现拥塞</code>时的门限的一半。然后把<code>拥塞窗口</code>设置为1，执行<code>慢启动</code>算法。</p><pre><code>* 加法增大：执行`拥塞避免`算法后，拥塞窗口`线性缓慢`增大，防止网络过早出现拥塞* 乘法减小：无论是慢启动阶段还是拥塞避免，只要出现了网络拥塞（超时），那就把慢启动门限值`ssthresh`减半</code></pre><h2 id="延迟应答"><a href="#延迟应答" class="headerlink" title="延迟应答"></a>延迟应答</h2><p>​        如果接收数据的主机立刻返回ACK应答，这时候返回的窗口可能比较小。假设接收端缓冲区为1M 一次收到了500K的数据。如果立刻应答，返回的窗口就是500K。 但实际上可能处理端处理的速度很快，10ms之内就把500K数据从缓冲区消费掉了，在这种情况下，接收端处理还远没有达到自己的极限，即使窗口再放大一些也能处理过来。如果接收端稍微等一会再应答，比如等待200ms再应答，那么这个时候返回的窗口大小就是1M。</p><p>​        窗口越大，网络吞吐量就越大，传输效率就越高。我们的目标是在保证网络不拥塞的情况下尽量提高传输效率。</p><ul><li><p>数量限制: 每隔<code>N个包</code>就应答一次</p></li><li><p>时间限制: 超过大<code>延迟时间</code>就应答一次</p><p>  捎带应答：</p><p>  ​    在延迟应答的基础上，存在很多情况下，客户端服务器在应用层也是”一发一收” 的。 意味着客户端给服务器说了”How are you”， 服务器也会给客户端回一个”Fine, thank you”。那么这个时候ACK就可以搭顺风车，和服务器回应的 “Fine, thank you” 一起回给客户端。</p></li></ul><h2 id="面向字节流"><a href="#面向字节流" class="headerlink" title="面向字节流"></a>面向字节流</h2><p>​    当我们创建一个TCP的socket，同时在内核中创建一个发送缓冲区和一个接收缓冲区。</p><ul><li><p>调用write时，内核将数据会先写入发送缓冲区中，如果发送的字节数太长，会被拆分成多个TCP的数据包发出，如果发送的字节数太短，就会先在缓冲区里等待， 等到缓冲区长度达到设置长度，然后等到其他合适的时机发送出去。</p></li><li><p>调用read接收数据的时候， 数据也是从网卡驱动程序到达内核的接收缓冲区。然后应用程序可以调用read从接收缓冲区拿数据。TCP的一个连接，既有发送缓冲区, 也有接收缓冲区，那么对于这一个连接，既可以读数据，也可以写数据。所以是全双工的。</p></li></ul><p>​        由于缓冲区的存在，TCP程序的读和写不需要一一匹配。例如: 写100个字节数据时, 可以调用一次write写100个字节, 也可以调用100次write, 每次写一个字节; 读100个字节数据时, 也完全不需要考虑写的时候是怎么写的, 既可以一次read 100个字节, 也可以一次 read一个字节, 重复100次。</p><h2 id="粘包问题"><a href="#粘包问题" class="headerlink" title="粘包问题"></a>粘包问题</h2><p>​        粘包问题中的 “包”是指的应用层的数据包。在TCP的协议头中，没有如同UDP一样的 “报文长度”这样的字段，但是有一个序号这样的字段。站在传输层的角度， TCP是一个一个报文过来的，按照序号排好序放在缓冲区中，但是站在应用层的角度，它看到的只是一串连续的字节数据。应用程序看到了这么一连串的字节数据， 就不知道<strong>从哪个部分开始到哪个部分结束是一个完整的应用层数据包</strong>，这就是粘包问题。</p><p>​        如何解决：</p><ul><li>对于定长的包，保证每次都按固定大小读取即可。例如一个Request结构, 是固定大小的, 那么就从缓冲区从头开始按sizeof(Request)依次读取即可。</li><li>对于变长的包，可以在包头的位置，约定一个包总长度的字段，从而就知道了包的结束位置。</li><li>对于变长的包，还可以在包和包之间使用明确的分隔符(应用层协议是程序员自己来定义的, 只要保证分隔符不和正文冲突即可)。</li></ul><p>层的角度， TCP是一个一个报文过来的，按照序号排好序放在缓冲区中，但是站在应用层的角度，它看到的只是一串连续的字节数据。应用程序看到了这么一连串的字节数据， 就不知道<strong>从哪个部分开始到哪个部分结束是一个完整的应用层数据包</strong>，这就是粘包问题。</p><p>​        如何解决：</p><ul><li>对于定长的包，保证每次都按固定大小读取即可。例如一个Request结构, 是固定大小的, 那么就从缓冲区从头开始按sizeof(Request)依次读取即可。</li><li>对于变长的包，可以在包头的位置，约定一个包总长度的字段，从而就知道了包的结束位置。</li><li>对于变长的包，还可以在包和包之间使用明确的分隔符(应用层协议是程序员自己来定义的, 只要保证分隔符不和正文冲突即可)。</li></ul><p>对于UDP协议，如果还没有上层交付数据， UDP的报文长度仍然在。 同时UDP是一个一个把数据交付给应用层，这样就有存在明确的数据边界，站在应用层的角度， 使用UDP的时候要么收到完整的UDP报文要么不收，不会出现”半个”的情况。</p><h1 id="HTTP与HTTPS区别"><a href="#HTTP与HTTPS区别" class="headerlink" title="HTTP与HTTPS区别"></a>HTTP与HTTPS区别</h1><ol><li> https需要到ca申请证书，申请证书需要money；</li><li> http是超文本传输协议，信息是明文传输，https则是使用SSL/STL加密传输协议，安全性较高；</li><li> http使用80端口，https使用443端口；</li><li> http是无状态连接，https是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。</li></ol><h2 id="HTTPS工作原理"><a href="#HTTPS工作原理" class="headerlink" title="HTTPS工作原理"></a>HTTPS工作原理</h2><img src="/2021/08/03/tcp-ip%E5%85%AB%E8%82%A1%E6%96%87/https%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png" class="" title="image-20210603211824919"><ol><li> 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。</li><li> Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。</li><li> 客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。</li><li> 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。</li><li> Web服务器利用自己的私钥解密出会话密钥。</li><li> Web服务器利用会话密钥加密与客户端之间的通信。</li></ol><p>https缺点：</p><ul><li><p>  HTTPS协议握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电；</p></li><li><p>  HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；</p></li><li><p>  SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。</p></li><li><p>  SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。</p></li><li><p>  HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击(dos)、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。</p></li></ul><h1 id="session与cookie"><a href="#session与cookie" class="headerlink" title="session与cookie"></a>session与cookie</h1><p>cookie的内容主要包括：名字，值，过期时间，路径和域。路径与域一起构成cookie的作用范围。若不设置过期时间，则表示这个cookie的生命期为浏览器会话期间，关闭浏览器窗口，cookie就消失。这种生命期为浏览器会话期的cookie被称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。若设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存里的cookie，不同的浏览器有不同的处理方式</p><p>session机制。session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了一个session标识（称为session id），如果已包含则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（检索不到，会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发送给服务器。</p><p>区别：</p><ol><li> cookie数据放在客户的浏览器上，session数据放在服务器上；</li><li> cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，考虑到安全应当使用session；</li><li> session会在一定时间内保存在服务器上。当访问增多，会比较占用服务器的性能，考虑到服务器性能应当使用cookie；</li><li> 单个cookie保存的数据不能超过4k，很多浏览器都限制一个站点最多保存20个cookie；</li></ol><p><strong>建议：将登录等重要信息存放在session中，其他的一些信息若需要保留，就存放在cookie中</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;UDP&quot;&gt;&lt;a href=&quot;#UDP&quot; class=&quot;headerlink&quot; title=&quot;UDP&quot;&gt;&lt;/a&gt;UDP&lt;/h1&gt;&lt;p&gt;udp协议属于传输层协议。&lt;/p&gt;
&lt;h2 id=&quot;udp报文协议&quot;&gt;&lt;a href=&quot;#udp报文协议&quot; class=&quot;heade</summary>
      
    
    
    
    <category term="网络协议" scheme="http://example.com/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="面试" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
    <category term="HTTP" scheme="http://example.com/tags/HTTP/"/>
    
    <category term="TCP/IP" scheme="http://example.com/tags/TCP-IP/"/>
    
    <category term="UDP" scheme="http://example.com/tags/UDP/"/>
    
  </entry>
  
  <entry>
    <title>go_GC原理</title>
    <link href="http://example.com/2021/07/25/go-GC%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/07/25/go-GC%E5%8E%9F%E7%90%86/</id>
    <published>2021-07-25T14:23:06.000Z</published>
    <updated>2021-08-03T15:02:09.402Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Mark-amp-Sweep"><a href="#Mark-amp-Sweep" class="headerlink" title="Mark &amp; Sweep"></a>Mark &amp; Sweep</h1><h3 id="Carbage-Collection"><a href="#Carbage-Collection" class="headerlink" title="Carbage Collection"></a>Carbage Collection</h3><p>现代高级编程语言管理内存的方式分为两种：<em>自动</em>和<em>手动</em>，像 C、C++ 等编程语言使用手动管理内存的方式，工程师编写代码过程中需要<em>主动申请</em>或者<em>释放内存</em>；而 PHP、Java 和 Go 等语言使用自动的内存管理系统，有<em>内存分配器</em>和<em>垃圾收集器</em>来代为分配和回收内存，其中垃圾收集器就是我们常说的 GC。主流的垃圾回收算法：</p><ul><li>  <strong>引用计数</strong></li><li>  <strong>追踪式垃圾回收</strong></li></ul><p><strong>Go 现在用的三色标记法就属于追踪式垃圾回收算法的一种。</strong></p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/carbage-collection.png" class="" title="image-20210725130838565"><h3 id="Mark-amp-Sweep-1"><a href="#Mark-amp-Sweep-1" class="headerlink" title="Mark &amp; Sweep"></a>Mark &amp; Sweep</h3><p><em>STW</em></p><p><code>stop the world</code>, GC 的一些阶段需要停止所有的 <code>mutator </code>以确定当前的引用关系。这便是很多人对 GC 担心的来源，这也是 GC 算法优化的重点。</p><p><em>Root</em></p><p>根对象是 <code>mutator </code><strong>不需要通过其他对象就可以直接访问</strong>到的对象。比如<strong>全局对象</strong>，<strong>栈对象</strong>中的数据等。通过<code>Root </code>对象，可以<strong>追踪到其他存活的对象</strong>。</p><p><code>Mark Sweep</code> 两个阶段：**标记(Mark)**和 **清除(Sweep)**两个阶段，所以也叫 <code>Mark-Sweep</code> 垃圾回收算法。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/GC-root.png" class="" title="image-20210725131746009"><p>下面这个算法就是严格按照<em>追踪式算法</em>的思路来实现的：</p><ul><li>  <code>Stop the World</code></li><li>  <code>Mark</code>：通过 Root 和 Root 直接间接访问到的对象， 来寻找所有可达的对象，并进行标记。</li><li>  <code>Sweep</code>：对<em>堆对象迭代</em>，已标记的对象置位标记。所有<em>未标记的对象加入freelist</em>， 可用于再分配。</li><li>  <code>Start the Wrold</code></li></ul><p>这个算法最大的问题是 <strong>GC 执行期间需要把整个程序完全暂停</strong>，朴素的 Mark Sweep 是<code>整体 STW</code>，并且<em>分配速度慢</em>，<em>内存碎片率高</em>。</p><p><strong>标记过程</strong>需的要 <code>STW</code>，因为对象引用关系如果在标记阶段做了修改，会影响标记结果的正确性。</p><p>并发 GC 分为两层含义：</p><ul><li>  每个 <code>mark </code>或 <code>sweep ``本身是多个线程</code>(协程)执行的(<code>concurrent</code>)</li><li>  <code>mutator </code>和 <code>collector </code><em>同时运行</em>(<code>background</code>)</li></ul><p><em>concurrent 这一层是比较好实现的, GC 时整体进行STW，那么对象引用关系不会再改变，对 mark 或者sweep 任务进行分块，就能多个线程(协程) conncurrent 执行任务 mark 或 sweep</em>。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/mark-STW.png" class="" title="image-20210725141141348"><p>而对于 <code>backgroud </code>这一层, 也就是说 <code>mutator </code>和 <code>mark</code>，<code>sweep </code>同时运行，则相对复杂。</p><ul><li>  1.3以前的版本使用<strong>标记-清扫</strong>的方式，<em>整个过程都需要 STW</em>。</li><li>  1.3版本<strong>分离了标记和清扫</strong>的操作，<em>标记过程STW</em>，<em>清扫过程并发</em>执行。</li></ul><p><code>backgroup sweep</code> 是比较容易实现的，因为 mark 后，哪些对象是存活，哪些是要被 sweep 是已知的，sweep 的是不再引用的对象。sweep 结束前，这些对象不会再被分配到，所以 sweep 和 mutator 运行共存。无论全局还是栈不可能能访问的到这些对象，可以安全清理。</p><p>1.5版本在标记过程中使用<em>三色标记</em>法。标记和清扫都并发执行的，但<em>标记阶段的前后</em>需要 <code>STW</code> 一定时间来做 <em>GC 的准备工作</em>和<strong>栈的re-scan</strong>。</p><h1 id="Tri-color-Mark-amp-Sweep"><a href="#Tri-color-Mark-amp-Sweep" class="headerlink" title="Tri-color Mark &amp; Sweep"></a>Tri-color Mark &amp; Sweep</h1><h3 id="Tri-color-Mark-amp-Sweep-1"><a href="#Tri-color-Mark-amp-Sweep-1" class="headerlink" title="Tri-color Mark &amp; Sweep"></a>Tri-color Mark &amp; Sweep</h3><p>三色标记是对标记清除法的改进，标记清除法在整个执行时要求长时间 STW，Go 从1.5版本开始改为三色标记法，<strong>初始将所有内存标记为白色</strong>，然后将 <strong>roots 加入待扫描队列</strong>(<em>进入队列即被视为变成灰</em>色)，然后使用<em>并发 goroutine 扫描队列中的指针</em>，如果指针还引用了其他指针，那么<em>被引用的也进入队列</em>，<em>被扫描的对象视为黑色</em>。</p><ul><li>  <strong>白色</strong>对象：潜在的<code>垃圾</code>，其内存可能会被垃圾收集器回收。</li><li>  <strong>黑色</strong>对象：<code>活跃</code>的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象，<em>垃圾回收器不会扫描这些对象的子对象</em>。</li><li>  <strong>灰色</strong>对象 ：<code>活跃</code>的对象，因为存在指向白色对象的外部指针，<em>垃圾收集器会扫描这些对象的子对象</em>。</li></ul><h3 id="Tri-color-Marking"><a href="#Tri-color-Marking" class="headerlink" title="Tri-color Marking"></a>Tri-color Marking</h3><p>垃圾收集器从 <code>root </code><em>开始</em>然后跟随指针<em>递归整个内存空间</em>。分配于 <code>noscan </code>的 span 的对象, 不会进行扫描。然而，此过程不是由同一个 goroutine 完成的，每个指针都排队在工作池中。然后，先看到的被标记为工作协程的后台协程从该池中出队，扫描对象，然后将在其中找到的指针排入队列。</p><h3 id="Tri-color-Coloring"><a href="#Tri-color-Coloring" class="headerlink" title="Tri-color Coloring"></a>Tri-color Coloring</h3><p><strong>染色</strong>流程：</p><ul><li>  <em>一开始所有对象被认为是白色</em></li><li>  <em>根</em>节点(<code>stacks</code>，<code>heap</code>，<code>global variables</code>)<em>被染色为灰色</em></li></ul><p>一旦主流程走完，gc 会：</p><ul><li>  <em>选一个灰色对象，标记为黑色</em></li><li>  <em>遍历这个对象的所有指针，标记所有其引用的对象为灰色</em></li></ul><p>最终直到所有对象需要被染色。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/coloring-white.png" class="" title="image-20210725143944601"><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/coloring-grey.png" class="" title="image-20210725144023009"><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/coloring-black.png" class="" title="image-20210725144051380"><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/coloring-done.png" class="" title="image-20210725144137278"><p>标记结束后，<em>黑色对象是内存中正在使用的对象</em>，而<em>白色对象是要收集的对象</em>。由于s2的实例是在匿名函数中创建的，并且无法从堆栈访问，因此它保持为白色，可以清除。</p><p>颜色在内部实现原理：</p><p><em>每个 span 中有一个名为 <code>gcmarkBits </code>的位图属性，该属性跟踪扫描，并将相应的位设置为1</em>。</p><h1 id="Write-Barrier"><a href="#Write-Barrier" class="headerlink" title="Write Barrier"></a>Write Barrier</h1><h3 id="Wirte-Barrier"><a href="#Wirte-Barrier" class="headerlink" title="Wirte Barrier"></a>Wirte Barrier</h3><p>1.5版本在标记过程中使用三色标记法。<em>回收过程主要有四个阶段</em>，其中，<strong>标记</strong>和<strong>清扫</strong>都<em>并发执行</em>的，但标记阶段的前后需要 STW 一定时间来做<strong>GC 的准备工作</strong>和<strong>栈的 re-scan</strong>。</p><p>使用并发的垃圾回收，也就是多个 <code>Mutator </code>与 <code>Mark </code>并发执行，想要在并发或者增量的标记算法中保证正确性，我们需要达成以下<em>两种三色不变性</em>(<code>Tri-color invariant</code>)中的任意一种：</p><ul><li>  <strong>强三色</strong>不变性：<em>黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象</em>。</li><li>  <strong>弱三色</strong>不变性 ：<em>黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径</em>。</li></ul><p>也就是黑色到白色要么不可达，要么间接可达。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/change-pointer.png" class="" title="image-20210725145306181"><p>标记过程需要 STW，因为<em>对象引用关系如果在标记阶段做了修改，会影响标记结果的正确性</em>。<em>灰色对象 B 中包含指向白色对象 C 的指针 e，对象 C 尚未被扫描，此时，如有其他程序，将 e 指针从 B 对象中删除，并将指向对象 C 的新指针 f插入到黑色对象 A 中，由于对象 A 早已完成扫描，对象 C 就会一直保持白色状态直到被回收</em>。</p><p>可以看出，一个白色对象被黑色对象引用，是注定无法通过这个黑色对象来保证自身存活的，与此同时，如果所有能到达它的灰色对象与它之间的可达关系全部遭到破坏，那么这个白色对象必然会被视为垃圾清除掉。 故当上述两个条件同时满足时，就会出现对象丢失的问题。如果这个白色对象下游还引用了其他对象，并且这条路径是指向下游对象的唯一路径，那么他们也是必死无疑的。</p><p>为了防止这种现象的发生，最简单的方式就是 STW，直接禁止掉其他用户程序对对象引用关系的干扰，但是 STW 的过程有明显的资源浪费，对所有的用户程序都有很大影响，如何能在保证对象不丢失的情况下合理的尽可能的提高 GC 效率，减少 STW 时间呢？</p><h3 id="Dijkstra-写屏障"><a href="#Dijkstra-写屏障" class="headerlink" title="Dijkstra 写屏障"></a>Dijkstra 写屏障</h3><p><strong>插入屏障拦截</strong> <em>将白色指针插入黑色对象的操作，标记其对应对象为灰色状态</em>，这样就不存在黑色对象引用白色对象的情况了，满足强三色不变式，在插入指针 f 时将 C 对象标记为灰色。</p><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/write-barrier.png" class="" title="image-20210725145657296"><p>如果对栈上的写做拦截，那么流程代码会非常复杂，并且性能下降会非常大，得不偿失。根据局部性的原理来说，其实我们程序跑起来，大部分的其实都是操作在栈上，函数参数啊、函数调用导致的压栈出栈、局部变量啊，协程栈，这些如果也弄起写屏障，那么可想而知了，根本就不现实，复杂度和性能就是越不过去的坎。</p><p>1、内存屏障只是对应一段特殊的代码；2、内存屏障这段代码在编译期间生成；3、内存屏障本质上在运行期间拦截内存写操作，相当于一个 <code>hook </code>调用</p><p>Go 团队在实现上选择了<em>在标记阶段完成时暂停程序</em>、<em>将所有栈对象标记为灰色并重新扫描</em>，在活跃 <code>goroutine </code>非常多的程序中，重新扫描的过程需要占用 10 ~ 100ms 的时间。</p><p>所以 Go 选择<strong>仅对堆上的指针插入增加写屏障</strong>，这样就会出现在扫描结束后，<em>栈上仍存在引用白色对象的情况，这时的栈是灰色的，不满足三色不变式，所以需要对栈进行重新扫描使其变黑，完成剩余对象的标记，这个过程需要 STW</em>。</p><p><strong>初始化 GC <strong>任务，包括</strong>开启写屏障</strong>(write barrier)和<strong>开启辅助 GC</strong>(mutator assist)，<strong>统计 root 对象</strong>的任务数量等，<em>这个过程需要 STW</em>。</p><p><strong>扫描</strong>所有 root 对象，包括<em>全局指针</em>和 g<em>oroutine(G) 栈上的指针</em>(<strong>扫描对应 G 栈时需停止该 G</strong>)，将其加入标记队列(灰色队列)，并<em>循环处理灰色队列</em>的对象，<em>直到灰色队列为空</em>，该过程后台并行执行。</p><p>完成<strong>标记</strong>工作，<strong>重新扫描(re-scan)全局指针和栈</strong>。因为 <code>Mark </code>和 <code>mutator </code>是并行的，所以在 Mark 过程中可能会有新的对象分配和指针赋值，这个时候就需要通过写屏障(write barrier)记录下来，<em>re-scan 再检查一下，这个过程也是会 STW 的</em>。按照标记结果回收所有的白色对象，该过程后台并行执行。</p><p>对未清扫的span进行清扫, 只有<em>上一轮的GC的清扫工作完成才可以开始新一轮的GC</em>。</p><p>如果发现扫描后<em>回收的速度跟不上分配的速度它依然会把⽤户逻辑暂停</em>，⽤户逻辑暂停了以后也就意味着不会有新的对象出现，同时<em>会把⽤户线程抢过来加⼊到垃圾回收⾥⾯加快垃圾回收的速度</em>。这样⼀来原来的并发还是变成了STW，还是得把⽤户线程暂停掉，要不然扫描和回收没完没了了停不下来，因为新分配对象⽐回收快，所以这种东⻄叫做辅助回收.</p><h3 id="Yuasa-删屏障"><a href="#Yuasa-删屏障" class="headerlink" title="Yuasa 删屏障"></a>Yuasa 删屏障</h3><img src="/2021/07/25/go-GC%E5%8E%9F%E7%90%86/delete-barrier.png" class="" title="image-20210725150635934"><p><em>删除屏障</em>也是<strong>拦截写操作</strong>的，但是是通过<strong>保护灰色对象到白色对象的路径不会断</strong>来实现的。如上图例中，<strong>在删除指针 e 时将对象 C 标记为灰色</strong>，这样 C 下游的所有白色对象，即使会被黑色对象引用，最终也还是会被扫描标记的，满足了弱三色不变式。这种方式的回收<em>精度低</em>，<em>一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮 GC 中被清理掉</em>。</p><h3 id="混合屏障"><a href="#混合屏障" class="headerlink" title="混合屏障"></a>混合屏障</h3><p>插入屏障和删除屏障各有优缺点，Dijkstra 的<em>插入写屏障</em>在<strong>标记开始时无需 STW</strong>，可直接开始，并发进行，但<strong>结束时需要 STW 来重新扫描栈</strong>，标记栈上引用的白色对象的存活；Yuasa 的<em>删除写屏障</em>则需要在 <strong>GC 开始时 STW 扫描堆栈来记录初始快照</strong>，这个过程会保护开始时刻的所有存活对象，但<em>结束时无需 STW</em>。</p><p>Golang 中的<em>混合写屏障</em>满足的是<em>变形的弱三色不变式</em>，同样允许<strong>黑色对象引用白色对象，白色对象处于灰色保护状态，但是只由堆上的灰色对象保护</strong>。</p><p>由于结合了 Yuasa 的删除写屏障和 Dijkstra 的插入写屏障的优点，只<em>需要在开始时并发扫描各个goroutine 的栈，使其变黑并一直保持</em>，这个过程<em>不需要 STW</em>，而<em>标记结束后</em>，因为<em>栈在扫描后始终是黑色的，也无需再进行 re-scan 操作了</em>，减少了 STW 的时间。</p><p>为了移除栈的重扫描过程，除了<strong>引入混合写屏障</strong>之外，在垃圾收集的<em>标记</em>阶段，我们还需要<strong>将创建的所有堆上新对象都标记成黑色</strong>，防止新分配的栈内存和堆内存中的对象被错误地回收，因为<em>栈内存在标记阶段最终都会变为黑色</em>，所以不再需要重新扫描栈空间。</p><h3 id="Sweep"><a href="#Sweep" class="headerlink" title="Sweep"></a>Sweep</h3><p>Sweep 让 Go 知道哪些内存可以重新分配使用，然而，<em>Sweep 过程并不会处理释放的对象内存置为0</em>(zeroing the memory)。而是在分配重新使用的时候，重新 reset bit。</p><p>每个 span 内有一个 <code>bitmap allocBits</code>，他表示<em>上一次 GC 之后每一个 object 的分配情况</em>，<strong>1：表示已分配，0：表示未使用或释放</strong>。</p><p>内部还使用了 uint64 allocCache(deBruijn)，加速寻找 <code>freeobject</code>。</p><p>GC 将会启动去<em>释放不再被使用的内存</em>。在标记期间，GC 会用一个位图 <code>gcmarkBits </code>来跟踪在使用中的内存。</p><p><em>正在被使用的内存被标记为黑色，然而当前执行并不能够到达的那些内存会保持为白色</em>。</p><p>现在，我们可以使用 <code>gcmarkBits </code>精确查看可用于分配的内存。Go 使用 gcmarkBits 赋值了 allocBits，这个操作就是内存清理。</p><p>然而必须每个 <code>span </code>都来一次类似的处理，需要耗费大量时间。Go 的目标是在<strong>清理内存时不阻碍执行</strong>，并为此提供了两种策略。</p><p>Go 提供<strong>两种</strong>方式来清理内存：</p><ul><li>  在<strong>后台</strong>启动一个<strong>worker 等待清理内存</strong>，<em>一个一个 mspan 处理</em></li></ul><p>当开始运行程序时，Go 将设置一个后台运行的 Worker(唯一的任务就是去清理内存)，它将<em>进入睡眠状态并等待内存段扫描</em>。</p><ul><li>  当<strong>申请分配内存时候 lazy 触发</strong></li></ul><p>当应用程序 <code>goroutine </code>尝试在<strong>堆内存中分配新内存</strong>时，会触发该操作。清理导致的延迟和吞吐量降低被分散到每次内存分配时。</p><p>清理内存段的第二种方式是<strong>即时执行</strong>。但是，由于这些内存段已经被分发到每一个处理器 P 的本地缓存 mcache 中，因此很难追踪首先清理哪些内存。这就是为什么 <strong>Go 首先将所有内存段移动到 mcentral 的原因</strong>。然后，它将会让本地缓存 mcache 再次请求它们，去即时清理。</p><p><strong>即时扫描</strong>确保<em>所有内存段都会得到清理</em>（节省资源），同时<strong>不会阻塞程序</strong>执行。</p><p>由于后台只有一个 <code>worker </code>在清理内存块，清理过程可能会花费一些时间。但是，我们可能想知道如果另一个 GC 周期在一次清理过程中启动会发生什么。在这种情况下，这个运行 GC 的 Goroutine 就会在开始标记阶段前去协助完成剩余的清理工作。</p><h1 id="Stop-The-World"><a href="#Stop-The-World" class="headerlink" title="Stop The World"></a>Stop The World</h1><h3 id="STW"><a href="#STW" class="headerlink" title="STW"></a>STW</h3><p>在垃圾回收机制 (GC) 中，”Stop the World” (STW) 是一个重要阶段。顾名思义， 在 “Stop the World” 阶段， 当前运行的所有程序将被暂停， <strong>扫描内存的 root 节点</strong>和**添加写屏障 (write barrier) **。</p><p>这个阶段的第一步， 是<em>抢占所有正在运行的 goroutine</em>，被抢占之后， 这些 goroutine 会被<em>悬停在一个相对安全的状态</em>。</p><p>处理器 P (无论是正在运行代码的处理器还是已在 idle 列表中的处理器)， 都会被被标记成<strong>停止状态</strong> (stopped)， 不再运行任何代码。 调度器把每<em>个处理器的 M  从各自对应的处理器 P 分离出来</em>， 放到 <em>idle 列表</em>中去。</p><p>对于 <code>Goroutine </code>本身， 他们会被放到一个<em>全局队列中等待</em>。</p><h3 id="Pacing"><a href="#Pacing" class="headerlink" title="Pacing"></a>Pacing</h3><p><strong>运行时中有 GC Percentage 的配置选项，默认情况下为100。</strong></p><p>此值表示在下一次垃圾收集必须启动之前可以分配多少新内存的比率。将 GC 百分比设置为100意味着，*基于在垃圾收集完成后标记为活动的堆内存量，下次垃圾收集前，堆内存使用可以增加100%*。</p><p><strong>如果超过2分钟没有触发，会强制触发 GC。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Mark-amp-Sweep&quot;&gt;&lt;a href=&quot;#Mark-amp-Sweep&quot; class=&quot;headerlink&quot; title=&quot;Mark &amp;amp; Sweep&quot;&gt;&lt;/a&gt;Mark &amp;amp; Sweep&lt;/h1&gt;&lt;h3 id=&quot;Carbage-Colle</summary>
      
    
    
    
    <category term="Goroutine" scheme="http://example.com/categories/Goroutine/"/>
    
    
    <category term="Golang" scheme="http://example.com/tags/Golang/"/>
    
    <category term="GC" scheme="http://example.com/tags/GC/"/>
    
  </entry>
  
  <entry>
    <title>Goroutine原理</title>
    <link href="http://example.com/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/</id>
    <published>2021-07-25T14:19:29.000Z</published>
    <updated>2021-07-27T17:46:41.181Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Goroutine"><a href="#Goroutine" class="headerlink" title="Goroutine"></a>Goroutine</h1><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>“Goroutine 是一个与其他 goroutines 并行运行在同一地址空间的 Go 函数或方法。一个运行的程序由一个或更多个 goroutine 组成。它与线程、协程、进程等不同。它是一个 goroutine” —— Rob Pike</p><p><strong>Goroutines 在同一个用户地址空间里并行独立执行 functions，channels 则用于 goroutines 间的通信和同步访问控制。</strong></p><h3 id="goroutine-与thread有何区别"><a href="#goroutine-与thread有何区别" class="headerlink" title="goroutine 与thread有何区别"></a>goroutine 与thread有何区别</h3><ul><li><p><strong>内存占用</strong>，创建一个 goroutine 的栈内存消耗为 2 KB(Linux AMD64 Go v1.4后)，运行过程中，如果栈空间不够用，<strong>会自动进行扩缩容</strong>。<br>  <em>创建一个 thread 为了尽量避免极端情况下操作系统线程栈的溢出，默认会为其分配一个较大的栈内存( 1 - 8 MB 栈内存，线程标准 POSIX Thread)，而且还需要一个被称为 “guard page” 的区域用于和其他 thread 的栈空间进行隔离。而栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。</em></p></li><li><p><strong>创建/销毁</strong>，线程创建和销毀都会有巨大的消耗，是<strong>内核级的交互</strong>(trap)。<br>  <em>POSIX 线程(定义了创建和操纵线程的一套 API)通常是在已有的进程模型中增加的逻辑扩展，所以线程控制和进程控制很相似。而进入内核调度所消耗的性能代价比较高，开销较大。goroutine 是用户态线程，是由 go runtime 管理，创建和销毁的消耗非常小。</em></p></li><li><p><strong>调度切换</strong></p><pre><code>  抛开陷入内核，线程切换会消耗 1000-1500 纳秒(**上下文保存成本高，较多寄存器，公平性，复杂时间计算统计**)，一个纳秒平均可以执行 12-18 条指令。  所以由于线程切换，执行指令的条数会减少 12000-18000。goroutine 的切换约为 200 ns(用户态、3个寄存器，现在甚至达到了100~120ns)，相当于 2400-3600 条指令。因此，goroutines 切换**成本比 threads 要小得多**。</code></pre></li><li><p><strong>复杂性</strong></p><pre><code>  线程的**创建和退出**复杂，多个 thread 间**通讯**复杂(share memory)。  不能大量创建线程(参考早期的 httpd)，成本高，使用网络多路复用，存在大量`callback`(参考twemproxy、nginx 的代码)。对于应用服务线程门槛高，例如需要做第三方库隔离，需要考虑引入线程池等。</code></pre></li></ul><h3 id="M-N模型"><a href="#M-N模型" class="headerlink" title="M:N模型"></a>M:N模型</h3><p>Go 创建 M 个线程(CPU 执行调度的单元，内核的 task_struct)，之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行，即 M:N 模型。它们能够同时运行，与线程类似，但相比之下非常轻量。因此，<strong>程序运行时，Goroutines 的个数应该是远大于线程的个数的</strong>（phread 是内核线程？）。</p><p><strong>同一个时刻，一个线程只能跑一个 goroutine</strong>。<em>当 goroutine 发生阻塞 (chan 阻塞、mutex、syscall 等等) 时，Go 会把当前的 goroutine 调度走，让其他 goroutine 来继续执行，而不是让线程阻塞休眠，尽可能多的分发任务出去，让 CPU 忙</em>。</p><h1 id="GMP调度模型"><a href="#GMP调度模型" class="headerlink" title="GMP调度模型"></a>GMP调度模型</h1><h2 id="GMP概念"><a href="#GMP概念" class="headerlink" title="GMP概念"></a>GMP概念</h2><ul><li>  G </li></ul><p>goroutine 的缩写，每次 go func() 都代表一个 G，无限制。<br>使用 <code>struct runtime.g</code>，包含了当前 goroutine 的<strong>状态、堆栈、上下文</strong>。</p><ul><li>  M</li></ul><p>工作线程(<code>OS thread</code>)也被称为 Machine，使用 <code>struct runtime.m</code>，所有 M 是有<strong>线程栈</strong>的。<br>    如果不对该线程栈提供内存的话，系统会给该线程栈提供内存(不同操作系统提供的线程栈大小不同)。当指定了线程栈，则 <code>M.stack→G.stack</code>，M 的 PC 寄存器(下一个指令执行寄存器)指向 G 提供的函数，然后去执行。</p><ul><li>  P</li></ul><p><em>“Processor”是一个抽象的概念，并不是真正的物理 CPU。</em></p><p>Dmitry Vyukov 的方案是引入一个结构 P，它代表了 <em>M 所需的上下文环境</em>，也是处理<strong>用户级代码逻辑的处理器</strong>。它负责<strong>衔接 M 和 G 的调度上下文，将等待执行的 G 与 M 对接</strong>。当 P 有任务时需要<strong>创建</strong>或者<strong>唤醒</strong>一个 M 来执行它队列里的任务。所以 P/M 需要进行绑定，构成一个执行单元。P 决定了并行任务的数量，可通过 <code>runtime.GOMAXPROCS</code> 来设定。在 Go1.5 之后GOMAXPROCS 被默认设置可用的核数，而之前则默认为1。</p><p>Tips: <a href="https://github.com/uber-go/automaxprocs">https://github.com/uber-go/automaxprocs</a></p><p>Automatically set GOMAXPROCS to match Linux container CPU quota.</p><p><strong>mcache/stackalloc 从 M 移到了 P，而 G 队列也被分成两类，保留全局 G 队列，同时每个 P 中都会有一个本地的 G 队列。</strong></p><h3 id="GM调度器"><a href="#GM调度器" class="headerlink" title="GM调度器"></a>GM调度器</h3><p>Go 1.2前的调度器实现，限制了 Go 并发程序的伸缩性，尤其是对那些有高吞吐或并行计算需求的服务程序。</p><p>每个 goroutine 对应于 runtime 中的一个抽象结构：G，而 thread 作为“物理 CPU”的存在而被抽象为一个结构：M(machine)。当 goroutine 调用了一个阻塞的系统调用，运行这个 goroutine 的线程就会被阻塞，这时至少应该再创建/唤醒一个线程来运行别的没有阻塞的 goroutine。线程这里可以创建不止一个，可以按需不断地创建，而活跃的线程（处于非阻塞状态的线程）的最大个数存储在变量 GOMAXPROCS中。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/GM-Schedule.png" class="" title="image-20210718144120182"><h3 id="GM调度模型的问题"><a href="#GM调度模型的问题" class="headerlink" title="GM调度模型的问题"></a>GM调度模型的问题</h3><ul><li><p><strong>单一全局互斥锁</strong>(<code>Sched.Lock</code>)和<strong>集中状态存储</strong></p><pre><code>  导致所有 goroutine 相关操作，比如：创建、结束、重新调度等都要上锁。</code></pre></li><li><p><strong>Goroutine 传递</strong>问题</p><pre><code>   `M` 经常**在 M 之间**传递”可运行”的 goroutine，这导致**调度延迟增大**以及**额外的性能损耗**（*刚创建的 G 放到了全局队列，而不是本地 M 执行，不必要的开销和延迟*）。</code></pre></li><li><p><strong>Per-M 持有内存缓存</strong> (<code>M.mcache</code>)</p><pre><code>  每个 M 持有 `mcache `和 `stackalloc`，然而**只有在 M 运行 Go 代码时才需要使用内存**(每个 mcache 可以高达2mb)，**当 M 在处于 syscall 时并不需要这个内存**。运行 Go 代码和阻塞在 syscall 的 M 的比例高达`1:100`，造成了很大的浪费。同时**内存亲缘性也较差**，G 当前在 M 运行后对 M 的内存进行了预热，因为现在* G 调度到同一个 M 的概率不高，数据局部性不好*。</code></pre></li><li><p><strong>严重的线程阻塞/解锁</strong></p><pre><code>  在**系统调用**的情况下，工作线程**经常被阻塞和取消阻塞**，这增加了很多开销。比如 M 找不到G，此时 M 就会进入频繁阻塞/唤醒来进行检查的逻辑，以便及时发现新的 G 来执行。</code></pre><p>  <code>by Dmitry Vyukov “Scalable Go Scheduler Design Doc”</code></p></li></ul><h2 id="GMP调度器"><a href="#GMP调度器" class="headerlink" title="GMP调度器"></a>GMP调度器</h2><p>引入了<code> local queue</code>，因为 P 的存在，runtime 并不需要做一个集中式的 goroutine 调度，每一个 M 都会在 <code>P&#39;s local queue</code>、<code>global queue</code> 或者<code>其他 P 队列中找 G </code>执行，<em>减少全局锁对性能的影响</em>。</p><p>这也是 <code>GMP Work-stealing</code> 调度算法的核心。注意 P 的本地 G 队列还是可能面临一个并发访问的场景，为了避免加锁，这里 P 的本地队列是一个 <code>LockFree</code>的队列，窃取 G 时<strong>使用 CAS 原子操作</strong>来完成。关于LockFree 和 CAS 的知识参见 Lock-Free。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/GMP-schedule%E6%A8%A1%E5%9E%8B.png" class="" title="image-20210718145843014"><h1 id="Work-stealing调度算法"><a href="#Work-stealing调度算法" class="headerlink" title="Work-stealing调度算法"></a>Work-stealing调度算法</h1><h3 id="Work-stealing"><a href="#Work-stealing" class="headerlink" title="Work-stealing"></a>Work-stealing</h3><p><strong>当一个 P 执行完本地所有的 G 之后，并且全局队列为空的时候，会尝试挑选一个受害者 P，从它的 G 队列中窃取一半的 G。否则会从全局队列中获取(当前个数/GOMAXPROCS)个 G。</strong></p><p><strong>为了保证公平性，从随机位置上的 P 开始，而且遍历的顺序也随机化了(选择一个小于 GOMAXPROCS，且和它互为质数的步长)，保证遍历的顺序也随机化了。</strong></p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/work-stealing-p0.png" class="" title="image-20210718150126958"><p>光窃取失败时获取是不够的，可能会导致<strong>全局队列饥饿</strong>。P 的调度算法中还会<strong>每个 N (1/61 time)轮调度之后就去全局队列拿一个 G</strong>。</p><p>谁放入的全局队列呢？</p><p><em>新建 G 时 P 的本地 G 队列放不下已满并达到256个的时候会放半数 G 到全局队列去，阻塞的系统调用返回时找不到空闲 P 也会放到全局队列。</em></p><h3 id="Syscall"><a href="#Syscall" class="headerlink" title="Syscall"></a>Syscall</h3><p>调用 syscall 后<strong>M会解绑 P</strong>，然后**<code>M </code>和 <code>G</code> 进入<code>阻塞</code>*<em>，而 P 此时的状态就是 <code>syscall</code>，</em>表明这个 P 的 G 正在 syscall 中<em>，这时的 P 是</em>不能被调度给别的 M* 的。<em>如果在短时间内阻塞的 M 就唤醒了，那么 M 会优先来重新获取这个 P，能获取到就继续绑回去，这样有利于数据的局部性</em>。</p><p>系统监视器 (<code>system monitor</code>)，称为 <code>sysmon</code>，会<strong>定时扫描</strong>。在执行 syscall 时, 如果某个 P 的 G 执行超过一个<code> sysmon tick(10ms)</code>，就会把他设为 <code>idle</code>，<em>重新调度给需要的 M，强制解绑</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/syscall-handoffs-p-sysmon.png" class="" title="image-20210718152037397"><p>P1 和 M 脱离后目前在 idle list 中等待被绑定（处于 syscall 状态）。而 syscall 结束后 M 按照如下规则执行直到满足其中一个条件：</p><ol><li> 尝试<em>获取同一个 P</em>(P1)，恢复执行 G</li><li> 尝试<em>获取 idle list 中的其他空闲 P</em>，恢复执行 G</li><li> <em>找不到空闲 P，把 G 放回 global queue，M 放回到 idle list</em></li></ol><h3 id="Spining-thread"><a href="#Spining-thread" class="headerlink" title="Spining thread"></a>Spining thread</h3><p><em>线程自旋是相对于线程阻塞而言的</em>，表象就是循环执行一个指定逻辑(调度逻辑，目的是不停地寻找 G)。这样做的问题显而易见，如果 G 迟迟不来，<em>CPU 会白白浪费在这无意义的计算上</em>。但好处也很明显，<em>降低了 M 的上下文切换成本，提高了性能</em>。在两个地方引入自旋：</p><ul><li>  类型1：M 不带 P 的<strong>找 P</strong> 挂载（一有 P 释放就结合）</li><li>  类型2：M 带 P 的<strong>找 G</strong> 运行（一有 runable 的 G 就执行）</li></ul><p>为了避免过多浪费 CPU 资源，自旋的 M 数量最多只允许 <code>GOMAXPROCS (Busy P)</code>。同时当有类型1的自旋 M 存在时，类型2的自旋 M 就不阻塞，阻塞会释放 P，一释放 P 就马上被类型1的自旋 M 抢走了，没必要。</p><p>在<strong>新 G 被创建</strong>、<strong>M 进入系统调用</strong>、<strong>M 从空闲被激活</strong>这三种状态变化前，调度器会确保<strong>至少有一个自旋 M 存在</strong>（唤醒或者创建一个 M），<strong>除非没有空闲的 P</strong>。</p><ul><li><p>  <code>当新 G 创建，如果有可用 P，就意味着新 G 可以被立即执行，即便不在同一个 P 也无妨，所以我们保留一个自旋的 M（这时应该不存在类型1的自旋只有类型2的自旋）就可以保证新 G 很快被运行。</code></p></li><li><p>  <code>当 M 进入系统调用，意味着 M 不知道何时可以醒来，那么 M 对应的 P 中剩下的 G 就得有新的 M 来执行，所以我们保留一个自旋的 M 来执行剩下的 G（这时应该不存在类型2的自旋只有类型1的自旋）。</code></p></li><li><p>  <code>如果 M 从空闲变成活跃，意味着可能一个处于自旋状态的 M 进入工作状态了，这时要检查并确保还有一个自旋 M 存在，以防还有 G 或者还有 P 空着的。</code></p></li></ul><h3 id="GMP问题总结"><a href="#GMP问题总结" class="headerlink" title="GMP问题总结"></a>GMP问题总结</h3><ul><li><p><strong>单一全局互斥锁(Sched.Lock)和集中状态存储</strong></p><pre><code>  G 被分成全局队列和 P 的本地队列，*全局队列依旧是全局锁，但是使用场景明显很少，P 本地队列使用无锁队列，使用原子操作来面对可能的并发场景*。</code></pre></li><li><p><strong>Goroutine 传递问题</strong></p><pre><code>   *G 创建时就在 P 的本地队列*，可以避免在 G 之间传递（窃取除外），G 对 P 的数据局部性好; 当 G 开始执行了，系统调用返回后 M 会尝试获取可用 P，获取到了的话可以避免在 M 之间传递。**而且优先获取调用阻塞前的 P，所以 G 对 M 数据局部性好，G 对 P 的数据局部性也好。**</code></pre></li><li><p><strong>Per-M 持有内存缓存 (M.mcache)</strong></p><pre><code> *内存 mcache 只存在 P 结构中*，P 最多只有 GOMAXPROCS 个，远小于 M 的个数，所以内存没有过多的消耗。  </code></pre></li><li><p>严重的线程<strong>阻塞/解锁</strong></p><pre><code>  通过*引入自旋*，保证**任何时候都有处于等待状态的自旋 M**，避免**在等待可用的 P 和 G 时频繁的阻塞和唤醒**。</code></pre></li></ul><p><code>by Dmitry Vyukov “Scalable Go Scheduler Design Doc”</code></p><h3 id="sysmon"><a href="#sysmon" class="headerlink" title="sysmon"></a>sysmon</h3><p>sysmon 也叫<em>监控线程</em>，它<em>无需 P 也可以运行</em>，他是一个<em>死循环</em>，每<code>20us~10ms</code>循环一次，循环完一次就 <code>sleep </code>一会，为什么会是一个<strong>变动的周期</strong>呢，主要是<em>避免空转</em>，如果每次循环都没什么需要做的事，那么 sleep 的时间就会加大。</p><ul><li>  <strong>释放</strong>闲置超过5分钟的 <code>span </code><strong>物理内存</strong>；</li><li>  如果超过2分钟没有<strong>垃圾回收，强制执行</strong>；</li><li>  将长时间未处理的 <code>netpoll </code><em>添加到全局队列</em>；</li><li>  向长时间运行的 G 任务<strong>发出抢占调度</strong>；</li><li>  <strong>收回</strong>因 <code>syscall </code><strong>长时间阻塞的 P</strong>；</li></ul><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/preempt-by-sysmon.png" class="" title="image-20210718155407628"><p><em>当 P 在 M 上执行时间超过10ms</em>，<code>sysmon </code>调用 <code>preemptone </code>将 G 标记为 <code>stackPreempt </code>。因此需要在某个地方触发检测逻辑，Go 当前是在<strong>检查栈是否溢出的地方判定</strong>(<code>morestack</code>())，M 会保存当前 G 的上下文，重新进入调度逻辑。</p><p>死循环：issues/11462</p><p>信号抢占：go1.14基于信号的<em>抢占式调度</em>实现原理</p><p>异步抢占，注册 <code>sigurg </code>信号，通过 <code>sysmon </code>检测，对 M 对应的线程发送信号，触发注册的 handler，它往当前 G 的 PC 中插入一条指令(调用某个方法)，在处理完 handler，G 恢复后，自己把自己推到了 global queue 中。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/preempt-by-sysmon-sig.png" class="" title="image-20210718155635185"><h3 id="Network-poller"><a href="#Network-poller" class="headerlink" title="Network poller"></a>Network poller</h3><p>Go <strong>所有的 I/O 都是阻塞的</strong>。然后通过 <code>goroutine + channel</code> 来<em>处理并发</em>。因此所有的 IO 逻辑都是直来直去的，你不再需要回调，不再需要 future，要的仅仅是 step by step。这对于代码的可读性是很有帮助的。</p><p><em>G 发起网络 I/O 操作也不会导致 M 被阻塞(仅阻塞G)，从而不会导致大量 M 被创建出来</em>。<strong>将异步 I/O 转换为阻塞 I/O 的部分称为 netpoller</strong>。<em>打开或接受连接都被设置为非阻塞模式。如果你试图对其进行 I/O 操作，并且文件描述符数据还没有准备好，G 会进入 gopark 函数，将当前正在执行的 G 状态保存起来，然后切换到新的堆栈上执行新的 G。</em></p><p>那什么时候 G 被调度回来呢？</p><ul><li>  <code>sysmon</code></li><li>  <code>schedule()</code>：M 找 G 的调度函数</li><li>  <code>GC</code>：start the world</li></ul><p>调用 netpoll() 在某一次调度 G 的过程中，处于就绪状态的 fd 对应的 G 就会被调度回来。</p><p>G 的 gopark 状态：G 置为 waiting 状态，等待显示 goready 唤醒，在 poller 中用得较多，还有锁、chan 等。</p><h3 id="Schedule-Affinity"><a href="#Schedule-Affinity" class="headerlink" title="Schedule Affinity"></a>Schedule Affinity</h3><p>在 chan 来回通信的 goroutine 会导致频繁的 blocks，即频繁地在本地队列中重新排队。然而，由于本地队列是 FIFO 实现，如果另一个 goroutine 占用线程，unblock goroutine 不能保证尽快运行。同时 Go 亲缘性调度的一些限制：Work-stealing、系统调用。</p><p>goroutine #9 在 chan 被阻塞后恢复。但是，它必须等待#2、#5和#4之后才能运行。goroutine #5将阻塞其线程，从而延迟goroutine #9，并使其面临被另一个 P 窃取的风险。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/image-20210718160233704.png" class="" title="image-20210718160233704"><p>针对 communicate-and-wait 模式，进行了<strong>亲缘性调度</strong>的优化。Go 1.5 在 P 中引入了 <code>runnext </code>特殊的一个字段，可以<strong>高优先级执行 unblock G</strong>。</p><p><em>goroutine #9现在被标记为下一个可运行的</em>。<strong>这种新的优先级排序允许 goroutine 在再次被阻塞之前快速运行</strong>。这一变化对运行中的标准库产生了总体上的积极影响，提高了一些包的性能。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/affinity-schedule.png" class="" title="image-20210718160318778"><h1 id="Goroutine-Lifecycle"><a href="#Goroutine-Lifecycle" class="headerlink" title="Goroutine Lifecycle"></a>Goroutine Lifecycle</h1><h3 id="Go程序启动"><a href="#Go程序启动" class="headerlink" title="Go程序启动"></a>Go程序启动</h3><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/runtime-main.png" class="" title="image-20210718160426412"><p>整个程序始于一段汇编，而在随后的<code> runtime·rt0_go</code>（也是汇编程序）中，会执行很多初始化工作。</p><ul><li>  <strong>绑定 m0 和 g0</strong>，<code>m0</code>就是<strong>程序的主线程</strong>，程序启动必然会拥有一个主线程，这个就是 m0。<code>g0</code> <strong>负责调度</strong>，即 <code>shedule() 函数</code>。</li><li><strong>创建 P</strong>，<strong>绑定 m0 和 p0</strong>，首先会<code>创建 GOMAXPROCS 个 P</code> ，存储在 <code>sched </code>的 <code>空闲链表(pidle)</code>。<br>  新建任务 <em>g 到 p0 本地队列</em>，<em>m0 的 g0 会创建一个 指向 runtime.main() 的 g</em> ，并<em>放到 p0 的本地队列</em>。</li><li>  <strong>runtime.main()</strong>: 启动 <code>sysmon </code>线程；启动 <code>GC</code> <code>协程</code>；执行 <code>init</code>，即代码中的各种 init 函数；执行 <code>main.main</code>(用户程序main) 函数。</li></ul><h3 id="OS-thread-创建"><a href="#OS-thread-创建" class="headerlink" title="OS thread 创建"></a>OS thread 创建</h3><p>准备运行的<strong>新 goroutine 将唤醒 P</strong> 以更好地分发工作。这个 <strong>P 将创建一个与之关联的 M 绑定到一个 OS thread</strong>。</p><p>go func() 中 触发 <code>Wakeup </code>唤醒机制：</p><p>有空闲的 P 而没有在 <code>spinning </code>状态的 M 时候, 需要去<strong>唤醒</strong>一个*空闲(睡眠)的 M *或者<strong>新建</strong>一个。当线程首次创建时，会执行一个特殊的 G，即 <em>g0，它负责管理和调度 G</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/OS-thread.png" class="" title="image-20210718160954428"><h3 id="g0"><a href="#g0" class="headerlink" title="g0"></a>g0</h3><p> Go 基于<em>两种断点将 G 调度到线程</em>上： </p><ul><li>  当<strong>G 阻塞</strong>时：系统调用、互斥锁或 chan。阻塞的 G 进入睡眠模式/进入队列，并允许 Go 安排和运行等待其他的 G。</li><li>  在<strong>函数调用期间</strong>，如果 G 必须<strong>扩展其堆栈</strong>。这个断点允许 Go 调度另一个 G 并避免运行 G 占用 CPU。</li></ul><p>在这两种情况下，<strong>运行调度程序的 g0 将当前 G 替换为另一个 G</strong>，即 ready to run。然后，选择的 G 替换 g0 并在线程上运行。与常规 G 相反，<strong>g0 有一个固定和更大的栈</strong>。</p><ul><li>  Defer 函数的分配</li><li>  GC 收集，比如 STW、扫描 G 的堆栈和标记、清除操作</li><li>  栈扩容，当需要的时候，由 g0 进行扩栈操作</li></ul><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/G0-schedule.png" class="" title="image-20210718161445297"><h3 id="Schedule"><a href="#Schedule" class="headerlink" title="Schedule"></a>Schedule</h3><p>在 Go 中，G 的切换相当轻便，其中需要<strong>保存的状态</strong>仅仅涉及以下<em>两个</em>：</p><ul><li>  Goroutine 在<em>停止运行前执行的指令</em>，程序<em>当前要运行的指令</em>是<em>记录在程序计数器（PC）中</em>的， G 稍后将在同一指令处恢复运行；</li><li>  G 的<em>堆栈</em>，以便在再次运行时<em>还原局部变量</em>；</li></ul><p>在切换之前，堆栈将被保存，以便在 G 再次运行时进行恢复.</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/schedule-time.png" class="" title="image-20210718161747355"><p>从 g 到 g0 或从 g0 到 g 的切换是相当迅速的，它们<em>只包含少量固定的指令</em>。相反，对于调度阶段，<strong>调度程序需要检查许多资源以便确定下一个要运行的 G</strong>。</p><ul><li>  当前 g 阻塞在 chan 上并切换到 g0：1、PC 和堆栈指针一起保存在内部结构中；2、将 g0 设置为正在运行的 goroutine；3、g0 的堆栈替换当前堆栈；</li><li>  g0 寻找新的 Goroutine 来运行</li><li>  g0 使用所选的 Goroutine 进行切换： 1、PC 和堆栈指针是从其内部结构中获取的；2、程序跳转到对应的 PC 地址；</li></ul><h3 id="Goroutine-Recycle"><a href="#Goroutine-Recycle" class="headerlink" title="Goroutine Recycle"></a>Goroutine Recycle</h3><p>G 很容易创建，栈很小以及快速的上下文切换。基于这些原因，开发人员非常喜欢并使用它们。然而，一个产生许多 <code>shortlive</code> 的 G 的程序<em>将花费相当长的时间来创建和销毁它们</em>。</p><p>每个 P 维护一个 <code>freelist G</code>，保持这个列表是<em>本地的</em>，这样做的好处是不使用任何锁来 push/get 一个空闲的 G。<em>当 G 退出当前工作时，它将被 push 到这个空闲列表中</em>。</p><p>为了更好地分发空闲的 G ，<strong>调度器</strong>也有自己的列表。它实际上有两个列表：<strong>一个包含已分配栈的 G，另一个包含释放过堆栈的 G（无栈）</strong>。</p><p>锁保护 central list，因为任何 M 都可以访问它。当本地列表长度超过64时，调度程序持有的列表从 P 获取 G。然后一半的 G 将移动到中心列表。需求回收 G 是一种节省分配成本的好方法。但是，由于堆栈是动态增长的，现有的G 最终可能会有一个大栈。因此，<em>当堆栈增长（即超过2K）时，Go 不会保留这些栈</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/go-recycle.png" class="" title="image-20210718162414057">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Goroutine&quot;&gt;&lt;a href=&quot;#Goroutine&quot; class=&quot;headerlink&quot; title=&quot;Goroutine&quot;&gt;&lt;/a&gt;Goroutine&lt;/h1&gt;&lt;h3 id=&quot;定义&quot;&gt;&lt;a href=&quot;#定义&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="Goroutine" scheme="http://example.com/categories/Goroutine/"/>
    
    
    <category term="Golang" scheme="http://example.com/tags/Golang/"/>
    
    <category term="GMP" scheme="http://example.com/tags/GMP/"/>
    
    <category term="Algorithm" scheme="http://example.com/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>go内存分配原理</title>
    <link href="http://example.com/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/</id>
    <published>2021-07-25T14:06:18.000Z</published>
    <updated>2021-07-27T17:45:38.182Z</updated>
    
    <content type="html"><![CDATA[<h1 id="堆栈与逃逸分析"><a href="#堆栈与逃逸分析" class="headerlink" title="堆栈与逃逸分析"></a>堆栈与逃逸分析</h1><h3 id="堆栈定义"><a href="#堆栈定义" class="headerlink" title="堆栈定义"></a>堆栈定义</h3><p>Go 有两个地方可以分配内存：一个<strong>全局堆空间</strong>用来<em>动态分配</em>内存，另一个是每个 <code>goroutine </code>都有的<strong>自身栈空间</strong>。</p><h4 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h4><p> 栈区的内存一般由<strong>编译器自动进行分配和释放</strong>，其中存储着函数的<strong>入参</strong>以及<strong>局部</strong>变量，这些参数会随着函数的创建而创建，函数的返回而销毁。(通过 <code>CPU push &amp; release</code>)。<br>    <em>A function has direct access to the memory inside its frame, through the frame pointer, but access to memory outside its frame requires indirect access.</em></p><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>堆区的内存一般由<strong>编译器和工程师</strong>自己共同进行管理<strong>分配</strong>，交给 <code>Runtime GC</code> 来<strong>释放</strong>。堆上分配必须找到一块足够大的内存来存放新的变量数据。后续释放时，<em>垃圾回收器扫描堆空间寻找不再被使用的对象</em>。<br>    Anytime a value is shared outside the scope of a function’s stack frame, it will be placed (or allocated) on the heap.<br>栈分配廉价，堆分配昂贵。stack allocation is cheap and heap allocation is expensive.</p><h3 id="变量到底在堆还是栈上？"><a href="#变量到底在堆还是栈上？" class="headerlink" title="变量到底在堆还是栈上？"></a>变量到底在堆还是栈上？</h3><p>写过其他语言，比如 C 的同学都知道，有明确的栈和堆的相关概念。而 Go 声明语法并没有提到栈和堆，而是交给 Go 编译器决定在哪分配内存，保证程序的正确性，在 Go FAQ 里面提到这么一段解释：</p><p>从正确的角度来看，你不需要知道。Go 中的每个变量只要有引用就会一直存在。变量的存储位置(堆还是栈)和语言的语义无关。</p><p>存储位置对于写出高性能的程序确实有影响。如果可能，Go 编译器将为该函数的堆栈侦(stack frame)中的函数分配本地变量。但是如果编译器在函数返回后<strong>无法证明变量未被引用</strong>，则编译器必须在会被垃圾回收的堆上分配变量以避免悬空指针错误。此外，如果<em>局部变量非常大，将它存储在堆而不是栈上可能更有意义</em>。</p><p>在当前编译器中，<em>如果变量存在取址，则该变量是堆上分配的候选变量</em>。但是基础的<em>逃逸分析</em>可以将那些生存不超过函数返回值的变量识别出来，并且因此可以分配在栈上。</p><h3 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h3><p>“通过<strong>检查变量的作用域</strong>是否<strong>超出了它所在的栈</strong>来决定是否将它分配在堆上”的技术，其中“变量的作用域超出了它所在的栈”这种行为即被称为逃逸。逃逸分析在大多数语言里属于静态分析：在编译期由静态代码分析来决定一个值是否能被分配在栈帧上，还是需要“逃逸”到堆上。</p><ul><li><p>  <em>减少 GC 压力</em>，栈上的变量，随着函数退出后系统直接回收，不需要标记后再清除</p></li><li><p>  <em>减少内存碎片</em>的产生</p></li><li><p>  <em>减轻分配堆内存的开销</em>，提高程序的运行速度</p></li></ul><p>可以通过命令<code>go build -gcflags -m</code>发现变量是否逃逸到堆上。</p><h3 id="超过栈帧-stack-frame"><a href="#超过栈帧-stack-frame" class="headerlink" title="超过栈帧(stack frame)"></a>超过栈帧(stack frame)</h3><p>当一个函数被调用时，会在<strong>两个相关的帧边界</strong>间<strong>进行上下文切换</strong>。从调用函数切换到被调用函数，<em>如果函数调用时需要传递参数，那么这些参数值也要传递到被调用函数的帧边界中</em>。<em><strong>Go 语言中帧边界间的数据传递是按值传递的</strong></em>。任何在函数 <code>getRandom </code>中的变量在函数返回时，都将不能访问。<em>Go 查找所有变量超过当前函数栈侦的，把它们分配到堆上，避免 outlive 变量</em>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-stack.png" class="" title="image-20210722225325976"><p>上述情况中，num 变量不能指向之前的栈。</p><p>Go 查找所有变量超过当前函数栈侦的，把它们分配到堆上，避免 outlive 变量。</p><p>变量 tmp 在栈上分配，但是它包含了指向堆内存的地址，所以可以安全的从一个函数的栈侦复制到另外一个函数的栈帧。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/heap-alloc.png" class="" title="image-20210722225623130"><h3 id="逃逸案例"><a href="#逃逸案例" class="headerlink" title="逃逸案例"></a>逃逸案例</h3><p>还存在大量其他的 case 会出现逃逸，比较典型的就是 “<strong>多级间接赋值容易导致逃逸</strong>”，这里的多级间接指的是，<em>对某个引用类对象中的引用类成员进行赋值</em>（记住公式 <code>Data.Field = Value</code>，如果 Data, Field 都是引用类的数据类型，则会导致 Value 逃逸。这里的等号 = 不单单只赋值，也表示参数传递）。Go 语言中的引用类数据类型有 <code>func</code>, <code>interface</code>, <code>slice</code>, <code>map</code>, <code>chan</code>, <code>*Type</code> ：</p><ul><li>  一个值被分享到函数栈帧范围之外</li><li>  在 for 循环外申明，在 for 循环内分配，同理闭包</li><li>  发送指针或者带有指针的值到 channel 中</li><li>  在一个切片上存储指针或带指针的值</li><li>  slice 的背后数组被重新分配了</li><li>  在 interface 类型上调用方法</li></ul><p>….<strong>go build -gcflags ‘-m’</strong></p><h1 id="连续栈"><a href="#连续栈" class="headerlink" title="连续栈"></a>连续栈</h1><p>Go 应用程序运行时，<em>每个 goroutine 都维护着一个自己的栈区</em>，这个栈区只能自己使用不能被其他 goroutine 使用。<em>栈区的初始大小是2KB</em>(比 x86_64 架构下线程的默认栈2M 要小很多)，在 goroutine 运行的时候栈区会按<strong>照需要增长和收缩</strong>，占用的内存最大限制的默认值在64位系统上是<strong>1GB</strong>。</p><ul><li>  v1.0 ~ v1.1 — 最小栈内存空间为 4KB</li><li>  v1.2 — 将最小栈内存提升到了 8KB</li><li>  v1.3 — 使用连续栈替换之前版本的分段栈</li><li>  v1.4 — 将最小栈内存降低到了 2KB</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/segmented-stack.png" class="" title="image-20210722230300734"><h3 id="Hot-split问题"><a href="#Hot-split问题" class="headerlink" title="Hot split问题"></a>Hot split问题</h3><p>分段栈的实现方式存在 “<code>hot split</code>” 问题，如果栈快满了，那么下一次的函数调用会强制触发栈扩容。当函数返回时，新分配的 “stack chunk” 会被清理掉。如果这个函数调用产生的范围是在一个循环中，<em>会导致严重的性能问题，频繁的 alloc/free</em>。</p><p>Go 不得不在1.2版本把栈默认大小改为8KB，降低触发热分裂的问题，但是每个 goroutine 内存开销就比较大了。<em>直到实现了连续栈(contiguous stack)，栈大小才改为2KB</em>。 </p><h3 id="连续栈-Contigous-stacks"><a href="#连续栈-Contigous-stacks" class="headerlink" title="连续栈(Contigous stacks)"></a>连续栈(Contigous stacks)</h3><p>采用<strong>复制栈</strong>的实现方式，在热分裂场景中不会频发释放内存，即不像分配一个新的内存块并链接到老的栈内存块，而是<strong>会分配一个两倍大的内存块并把老的内存块内容复制到新的内存块里</strong>，当栈缩减回之前大小时，我们不需要做任何事情。</p><ul><li>  <code>runtime.newstack</code> <strong>分配</strong>更大的栈内存空间</li><li>  <code>runtime.copystack</code> 将旧栈中的内容<strong>复制</strong>到新栈中</li><li>  <strong>将指向旧栈对应变量的指针重新指向新栈</strong></li><li>  <code>runtime.stackfree</code> <strong>销毁</strong>并<strong>0</strong>旧栈的内存空间</li></ul><p>如果栈区的空间<strong>使用率不超过1/4</strong>，那么在<strong>垃圾回收</strong>的时候使用 <code>runtime.shrinkstack</code> 进行<strong>栈缩容</strong>，同样使用 <code>copystack</code>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/Contigous-stacks.png" class="" title="image-20210722230846677"><h3 id="栈扩容"><a href="#栈扩容" class="headerlink" title="栈扩容"></a>栈扩容</h3><p>Go <strong>运行时</strong>判断栈空间是否足够，所以在 <code>call function</code> 中会插入 <code>runtime.morestack</code>，但每个函数调用都判定的话，成本比较高。在编译期间通过计算 <code>sp、func stack framesize</code> 确定需要<strong>哪个函数调用中插入 runtime.morestack</strong>。</p><ul><li>  当函数是<strong>叶子节点</strong>，且<strong>栈帧小于等于 112</strong> ，不插入指令</li><li>  当<strong>叶子函数</strong>栈帧大小为 <code>120 -128</code> 或者 <strong>非叶子函数</strong>栈帧大小为 <code>0 -128</code>，<code>SP &lt; stackguard0</code></li><li>当函数栈帧大小为 <code>128 - 4096</code><pre><code>  `SP - framesize &lt; stackguard0 - StackSmall`</code></pre></li><li>大于 <code>StackBig</code><pre><code> ` SP-stackguard+StackGuard &lt;= framesize + (StackGuard-StackSmall)`</code></pre></li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/add-stacks.png" class="" title="image-20210722231223193"><h1 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h1><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><p><code>TCMalloc </code>是 <code>Thread Cache Malloc</code> 的简称，是Go 内存管理的起源，Go的内存管理是借鉴了TCMalloc：</p><ul><li><strong>内存碎片</strong><pre><code>  随着内存不断的申请和释放，内存上会存在大量的碎片，降低内存的使用率。为了解决内存碎片，可以**将2个连续的未使用的内存块合并，减少碎片**。</code></pre></li><li><strong>大锁</strong><pre><code>  同一进程下的所有线程共享相同的内存空间，它们申请内存时需要加锁，如果不加锁就存在同一块内存被2个线程同时访问的问题。</code></pre></li></ul><h3 id="内存布局"><a href="#内存布局" class="headerlink" title="内存布局"></a>内存布局</h3><p>需要先知道几个重要的概念：</p><ul><li>  <code>page</code>: 内存<strong>页</strong>，一块 <code>8K</code> 大小的内存空间。<strong>Go 与操作系统</strong>之间的内存<strong>申请和释放</strong>，都是以 <code>page </code>为单位的。</li><li>  <code>span</code>: 内存<strong>块</strong>，<em>一个</em>或<em>多个连续的 page 组成一个 span</em>。</li><li>  <code>sizeclass</code>: <em>空间规格</em>，每个 <code>span </code>都<em>带有</em>一个 <code>sizeclass</code>，标记着该 span 中的 page 应该如何使用。</li><li>  <code>object</code>: <em>对象</em>，用来存储一个变量数据内存空间，<em>一个 span 在初始化时，会被切割成一堆等大的 object</em>。假设 object 的大小是 16B，span 大小是 8K，那么就会把 span 中的 page 就会被初始化 8K / 16B = 512 个 object。</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/span-size-classes.png" class="" title="image-20210722233429021"><h3 id="小于32kb内存分配"><a href="#小于32kb内存分配" class="headerlink" title="小于32kb内存分配"></a>小于32kb内存分配</h3><p>当程序里发生了 32kb 以下的小块内存申请时，Go 会从一个叫做的 <code>mcache </code>的<strong>本地缓存</strong>给程序分配内存。这样的一个内存块里叫做 <code>mspan</code>，它是要给程序分配内存时的分配单元。</p><p>在 Go 的调度器模型里，每个线程  M 会绑定给一个处理器 P，在<strong>单一粒度的时间里只能最多处理运行一个 goroutine</strong>，<strong>每个 P</strong> 都会<strong>绑定一个</strong>上面说的本地缓存 <code>mcache</code>。当需要进行内存分配时，当前运行的 <code>goroutine </code>会从 <code>mcache </code>中查找可用的 <code>mspan</code>。从本地 <code>mcache </code>里<em>分配</em>内存时<strong>不需要加锁</strong>，这种分配策略效率更高。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/alloc-with-mcache.png" class="" title="image-20210722233807537"><p>申请内存时都分给他们一个 <code>mspan </code>这样的单元会不会产生浪费。其实 <code>mcache </code>持有的这一系列的<code>mspan </code>并不都是统一大小的，而是按照大小，从<code>8b 到 32kb </code>分了大概 <strong>67*2</strong> 类的 <code>mspan</code>。</p><p>每个内存页分为<strong>多级固定大小</strong>的“空闲列表”，这有助于减少碎片。类似的思路在<code> Linux Kernel</code>、<code>Memcache </code>都可以见到 <code>Slab-Allactor</code>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/alloc-with-mcache1.png" class="" title="image-20210722233953150"><p>如果分配内存时 <code>mcachce </code>里<strong>没有空闲的对口 sizeclass 的 mspan</strong> 了，Go 里还为每种类别的 <code>mspan </code>维护着一个 <code>mcentral</code>。</p><p><code>mcentral </code>的作用是<strong>为所有 mcache 提供切分好的 mspan 资源</strong>。每个 <code>central </code>会持有一种<em>特定大小</em>的<strong>全局 mspan 列表</strong>，包括<em>已分配</em>出去的和<em>未分配</em>出去的。 每个 <code>mcentral </code>对应一种 <code>mspan</code>，当<strong>工作线程</strong>的 <code>mcache </code>中没有合适(也就是特定大小的)的mspan 时就<strong>会从 mcentral 去获取</strong>。</p><p><code>mcentral </code>被<em>所有的工作线程</em><strong>共同享有</strong>，存在多个 <strong>goroutine 竞争</strong>的情况，因此从 mcentral 获取资源时<strong>需要加锁</strong>。mcentral 里维护着两个双向链表，<code>nonempty </code>表示链表里还有<em>空闲的 mspan 待分配</em>。<code>empty</code> 表示这条链表里的 <em>mspan 都被分配了</em><code>object </code>或缓存 <code>mcache </code>中。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/central-lists-mspan.png" class="" title="image-20210722234358905"><p>程序申请内存的时候，mcache 里已经没有合适的空闲 mspan了，那么工作线程就会像下图这样去 mcentral 里去申请。<code>mcache </code>从 <code>mcentral </code><em>获取</em>和<em>归还</em> <code>mspan </code>的流程：</p><ul><li>  <strong>获取</strong> <em>加锁</em>；从 <code>nonempty </code>链表<em>找到一个可用的mspan</em>；并将其<em>从 nonempty 链表删除</em>；将取出的 <em>mspan 加入到 empty</em> 链表；将 <em>mspan 返回给工作线程</em>；<em>解锁</em>。</li><li>  <strong>归还</strong> <em>加锁</em>；将 <code>mspan </code>从 <code>empty </code>链表<em>删除</em>；将<code>mspan </code><em>加入</em>到 <code>nonempty </code>链表；<em>解锁</em>。</li></ul><p><code>mcentral </code>是 sizeclass 相同的 span 会以链表的形式组织在一起, 就是指该 span 用来存储哪种大小的对象。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/span-replace-from-central.png" class="" title="image-20210722234818604"><p>当 <strong>mcentral 没有空闲的 mspan 时，会向 mheap 申请</strong>。而 <strong>mheap 没有资源时，会向操作系统申请新内存</strong>。mheap 主要用于<em>大对象</em>的内存分配，以及<em>管理未切割的 mspan</em>，用于给 mcentral 切割成小对象。<br>mheap 中含有<em>所有规格的 mcentral</em>，所以<em>当一个 mcache 从 mcentral 申请 mspan 时，只需要在独立的 mcentral 中使用锁，并不会影响申请其他规格的 mspan</em>。</p><p>所有 <code>mcentral </code>的<em>集合</em>则是<em>存放于</em> <code>mheap </code>中的。 <code>mheap </code>里的 <code>arena </code>区域是<strong>真正的堆区</strong>，运行时会将 <code>8KB</code> 看做<em>一页</em>，这些内存页中存储了所有在<strong>堆上初始化的对象</strong>。运行时使用二维的 <code>runtime.heapArena</code> 数组管理所有的内存，每个 <code>runtime.heapArena</code> 都会<strong>管理 64MB 的内存</strong>。<br>如果 arena 区域没有足够的空间，会调用 <code>runtime.mheap.sysAlloc</code> 从<em>操作系统中申请</em>更多的内存。（如下图：Go 1.11 前的内存布局）</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-strcuture.png" class="" title="image-20210722235715115"><p>图中的空间大小，是 Go 向操作系统申请的虚拟内存地址空间，操作系统会将该段地址空间预留出来不做它用；而不是真的创建出这么大的虚拟内存，在页表中创建出这么大的映射关系。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/scan.png" class="" title="image-20210722235921766"><h3 id="小于16byte内存分配"><a href="#小于16byte内存分配" class="headerlink" title="小于16byte内存分配"></a>小于16byte内存分配</h3><p>对于<strong>小于16字节</strong>的对象(且<strong>无指针</strong>)，Go 语言将其划分为了<code>tiny </code>对象。划分 <code>tiny </code>对象的主要目的是为了<strong>处理极小的字符串</strong>和<strong>独立的转义变量</strong>。对 json 的基准测试表明，使用 tiny 对象减少了12%的分配次数和20%的堆大小。tiny 对象会被放入<code>class </code>为<em>2</em>的 <code>span </code>中。</p><ul><li>  首先<em>查看</em>之前分配的元素中是否<em>有空余的空间</em></li><li>  如果当前要分配的<em>大小不够</em>，例如要分配16字节的大小，这时就需要<em>找到下一个</em>空闲的元素</li></ul><p><code>tiny </code>分配的第一步是<strong>尝试利用分配过的前一个元素的空间</strong>，达到<em>节约内存</em>的目的。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/tiny-memory.png" class="" title="image-20210723000345774"><h3 id="大于32kb内存分配"><a href="#大于32kb内存分配" class="headerlink" title="大于32kb内存分配"></a>大于32kb内存分配</h3><p>Go 没法使用工作线程的本地缓存 <code>mcache </code>和全局中心缓存 <code>mcentral </code>上管理<em>超过32KB的内存</em>分配，所以对于那些超过32KB的内存申请，会直接从堆上(<code>mheap</code>)上分配<em>对应的数量</em>的内存页(<em>每页大小是8KB</em>)给程序。</p><ul><li>  <code>freelist</code></li><li>  <code>treap</code></li><li>  <code>radix tree + pagecache</code></li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/large-memory-alloc.png" class="" title="image-20210723001300487"><h3 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h3><p>一般<em>小对象</em>通过 <code>mspan </code><em>分配内存</em>；<em>大对象</em>则直接由 <code>mheap </code><em>分配</em>内存。</p><ul><li>  Go 在程序<em>启动时</em>，会向<em>操作系统申请一大块内存</em>，由 <em>mheap 结构全局管理</em>(现在 Go 版本不需要连续地址了，所以不会申请一大堆地址，多个64M内存组成)</li><li>  Go 内存管理的<em>基本单元</em>是 <code>mspan</code>，<em>每种 mspan 可以分配特定大小的 object</em></li><li>  <code>mcache</code>, <code>mcentral</code>, <code>mheap </code>是 Go 内存管理的三大组件，<code>mcache </code>管理线程在<em>本地缓存</em>的 <code>mspan</code>；<code>mcentral </code>管理<em>全局的 mspan</em>供所有线程</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-alloc.png" class="" title="image-20210723001733960"><p>1、使用<strong>缓存提高效率</strong>。在存储的整个体系中到处可见缓存的思想，Go 利用缓存一是<strong>减少了系统调用</strong>的次数，二是<strong>降低了锁的粒度</strong>、<strong>减少加锁的次数</strong>。</p><p>2、以<strong>空间换时间</strong>，提高<strong>内存管理效率</strong>。空间换时间是一种常用的性能优化思想，这种思想其实非常普遍，比如<code>Hash</code>、<code>Map</code>、<code>二叉排序树</code>等数据结构的本质就是空间换时间。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;堆栈与逃逸分析&quot;&gt;&lt;a href=&quot;#堆栈与逃逸分析&quot; class=&quot;headerlink&quot; title=&quot;堆栈与逃逸分析&quot;&gt;&lt;/a&gt;堆栈与逃逸分析&lt;/h1&gt;&lt;h3 id=&quot;堆栈定义&quot;&gt;&lt;a href=&quot;#堆栈定义&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="Goroutine" scheme="http://example.com/categories/Goroutine/"/>
    
    
    <category term="Golang" scheme="http://example.com/tags/Golang/"/>
    
    <category term="Heap" scheme="http://example.com/tags/Heap/"/>
    
    <category term="Stack" scheme="http://example.com/tags/Stack/"/>
    
    <category term="Memory" scheme="http://example.com/tags/Memory/"/>
    
  </entry>
  
</feed>
