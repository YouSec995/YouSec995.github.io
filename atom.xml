<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YouSec</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-07-25T14:20:03.197Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>yousec</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Goroutine原理</title>
    <link href="http://example.com/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/</id>
    <published>2021-07-25T14:19:29.000Z</published>
    <updated>2021-07-25T14:20:03.197Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Goroutine"><a href="#Goroutine" class="headerlink" title="Goroutine"></a>Goroutine</h1><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>“Goroutine 是一个与其他 goroutines 并行运行在同一地址空间的 Go 函数或方法。一个运行的程序由一个或更多个 goroutine 组成。它与线程、协程、进程等不同。它是一个 goroutine” —— Rob Pike</p><p><strong>Goroutines 在同一个用户地址空间里并行独立执行 functions，channels 则用于 goroutines 间的通信和同步访问控制。</strong></p><h3 id="goroutine-与thread有何区别"><a href="#goroutine-与thread有何区别" class="headerlink" title="goroutine 与thread有何区别"></a>goroutine 与thread有何区别</h3><ul><li><p><strong>内存占用</strong>，创建一个 goroutine 的栈内存消耗为 2 KB(Linux AMD64 Go v1.4后)，运行过程中，如果栈空间不够用，<strong>会自动进行扩缩容</strong>。<br>  <em>创建一个 thread 为了尽量避免极端情况下操作系统线程栈的溢出，默认会为其分配一个较大的栈内存( 1 - 8 MB 栈内存，线程标准 POSIX Thread)，而且还需要一个被称为 “guard page” 的区域用于和其他 thread 的栈空间进行隔离。而栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。</em></p></li><li><p><strong>创建/销毁</strong>，线程创建和销毀都会有巨大的消耗，是<strong>内核级的交互</strong>(trap)。<br>  <em>POSIX 线程(定义了创建和操纵线程的一套 API)通常是在已有的进程模型中增加的逻辑扩展，所以线程控制和进程控制很相似。而进入内核调度所消耗的性能代价比较高，开销较大。goroutine 是用户态线程，是由 go runtime 管理，创建和销毁的消耗非常小。</em></p></li><li><p><strong>调度切换</strong></p><pre><code>  抛开陷入内核，线程切换会消耗 1000-1500 纳秒(**上下文保存成本高，较多寄存器，公平性，复杂时间计算统计**)，一个纳秒平均可以执行 12-18 条指令。  所以由于线程切换，执行指令的条数会减少 12000-18000。goroutine 的切换约为 200 ns(用户态、3个寄存器，现在甚至达到了100~120ns)，相当于 2400-3600 条指令。因此，goroutines 切换**成本比 threads 要小得多**。</code></pre></li><li><p><strong>复杂性</strong></p><pre><code>  线程的**创建和退出**复杂，多个 thread 间**通讯**复杂(share memory)。  不能大量创建线程(参考早期的 httpd)，成本高，使用网络多路复用，存在大量`callback`(参考twemproxy、nginx 的代码)。对于应用服务线程门槛高，例如需要做第三方库隔离，需要考虑引入线程池等。</code></pre></li></ul><h3 id="M-N模型"><a href="#M-N模型" class="headerlink" title="M:N模型"></a>M:N模型</h3><p>Go 创建 M 个线程(CPU 执行调度的单元，内核的 task_struct)，之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行，即 M:N 模型。它们能够同时运行，与线程类似，但相比之下非常轻量。因此，<strong>程序运行时，Goroutines 的个数应该是远大于线程的个数的</strong>（phread 是内核线程？）。</p><p><strong>同一个时刻，一个线程只能跑一个 goroutine</strong>。<em>当 goroutine 发生阻塞 (chan 阻塞、mutex、syscall 等等) 时，Go 会把当前的 goroutine 调度走，让其他 goroutine 来继续执行，而不是让线程阻塞休眠，尽可能多的分发任务出去，让 CPU 忙</em>。</p><h1 id="GMP调度模型"><a href="#GMP调度模型" class="headerlink" title="GMP调度模型"></a>GMP调度模型</h1><h2 id="GMP概念"><a href="#GMP概念" class="headerlink" title="GMP概念"></a>GMP概念</h2><ul><li>  G </li></ul><p>goroutine 的缩写，每次 go func() 都代表一个 G，无限制。<br>使用 <code>struct runtime.g</code>，包含了当前 goroutine 的<strong>状态、堆栈、上下文</strong>。</p><ul><li>  M</li></ul><p>工作线程(<code>OS thread</code>)也被称为 Machine，使用 <code>struct runtime.m</code>，所有 M 是有<strong>线程栈</strong>的。<br>    如果不对该线程栈提供内存的话，系统会给该线程栈提供内存(不同操作系统提供的线程栈大小不同)。当指定了线程栈，则 <code>M.stack→G.stack</code>，M 的 PC 寄存器(下一个指令执行寄存器)指向 G 提供的函数，然后去执行。</p><ul><li>  P</li></ul><p><em>“Processor”是一个抽象的概念，并不是真正的物理 CPU。</em></p><p>Dmitry Vyukov 的方案是引入一个结构 P，它代表了 <em>M 所需的上下文环境</em>，也是处理<strong>用户级代码逻辑的处理器</strong>。它负责<strong>衔接 M 和 G 的调度上下文，将等待执行的 G 与 M 对接</strong>。当 P 有任务时需要<strong>创建</strong>或者<strong>唤醒</strong>一个 M 来执行它队列里的任务。所以 P/M 需要进行绑定，构成一个执行单元。P 决定了并行任务的数量，可通过 <code>runtime.GOMAXPROCS</code> 来设定。在 Go1.5 之后GOMAXPROCS 被默认设置可用的核数，而之前则默认为1。</p><p>Tips: <a href="https://github.com/uber-go/automaxprocs">https://github.com/uber-go/automaxprocs</a></p><p>Automatically set GOMAXPROCS to match Linux container CPU quota.</p><p><strong>mcache/stackalloc 从 M 移到了 P，而 G 队列也被分成两类，保留全局 G 队列，同时每个 P 中都会有一个本地的 G 队列。</strong></p><h3 id="GM调度器"><a href="#GM调度器" class="headerlink" title="GM调度器"></a>GM调度器</h3><p>Go 1.2前的调度器实现，限制了 Go 并发程序的伸缩性，尤其是对那些有高吞吐或并行计算需求的服务程序。</p><p>每个 goroutine 对应于 runtime 中的一个抽象结构：G，而 thread 作为“物理 CPU”的存在而被抽象为一个结构：M(machine)。当 goroutine 调用了一个阻塞的系统调用，运行这个 goroutine 的线程就会被阻塞，这时至少应该再创建/唤醒一个线程来运行别的没有阻塞的 goroutine。线程这里可以创建不止一个，可以按需不断地创建，而活跃的线程（处于非阻塞状态的线程）的最大个数存储在变量 GOMAXPROCS中。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/GM-Schedule.png" class="" title="image-20210718144120182"><h3 id="GM调度模型的问题"><a href="#GM调度模型的问题" class="headerlink" title="GM调度模型的问题"></a>GM调度模型的问题</h3><ul><li><p><strong>单一全局互斥锁</strong>(<code>Sched.Lock</code>)和<strong>集中状态存储</strong></p><pre><code>  导致所有 goroutine 相关操作，比如：创建、结束、重新调度等都要上锁。</code></pre></li><li><p><strong>Goroutine 传递</strong>问题</p><pre><code>   `M` 经常**在 M 之间**传递”可运行”的 goroutine，这导致**调度延迟增大**以及**额外的性能损耗**（*刚创建的 G 放到了全局队列，而不是本地 M 执行，不必要的开销和延迟*）。</code></pre></li><li><p><strong>Per-M 持有内存缓存</strong> (<code>M.mcache</code>)</p><pre><code>  每个 M 持有 `mcache `和 `stackalloc`，然而**只有在 M 运行 Go 代码时才需要使用内存**(每个 mcache 可以高达2mb)，**当 M 在处于 syscall 时并不需要这个内存**。运行 Go 代码和阻塞在 syscall 的 M 的比例高达`1:100`，造成了很大的浪费。同时**内存亲缘性也较差**，G 当前在 M 运行后对 M 的内存进行了预热，因为现在* G 调度到同一个 M 的概率不高，数据局部性不好*。</code></pre></li><li><p><strong>严重的线程阻塞/解锁</strong></p><pre><code>  在**系统调用**的情况下，工作线程**经常被阻塞和取消阻塞**，这增加了很多开销。比如 M 找不到G，此时 M 就会进入频繁阻塞/唤醒来进行检查的逻辑，以便及时发现新的 G 来执行。</code></pre><p>  <code>by Dmitry Vyukov “Scalable Go Scheduler Design Doc”</code></p></li></ul><h2 id="GMP调度器"><a href="#GMP调度器" class="headerlink" title="GMP调度器"></a>GMP调度器</h2><p>引入了<code> local queue</code>，因为 P 的存在，runtime 并不需要做一个集中式的 goroutine 调度，每一个 M 都会在 <code>P&#39;s local queue</code>、<code>global queue</code> 或者<code>其他 P 队列中找 G </code>执行，<em>减少全局锁对性能的影响</em>。</p><p>这也是 <code>GMP Work-stealing</code> 调度算法的核心。注意 P 的本地 G 队列还是可能面临一个并发访问的场景，为了避免加锁，这里 P 的本地队列是一个 <code>LockFree</code>的队列，窃取 G 时<strong>使用 CAS 原子操作</strong>来完成。关于LockFree 和 CAS 的知识参见 Lock-Free。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/GMP-schedule%E6%A8%A1%E5%9E%8B.png" class="" title="image-20210718145843014"><h1 id="Work-stealing调度算法"><a href="#Work-stealing调度算法" class="headerlink" title="Work-stealing调度算法"></a>Work-stealing调度算法</h1><h3 id="Work-stealing"><a href="#Work-stealing" class="headerlink" title="Work-stealing"></a>Work-stealing</h3><p><strong>当一个 P 执行完本地所有的 G 之后，并且全局队列为空的时候，会尝试挑选一个受害者 P，从它的 G 队列中窃取一半的 G。否则会从全局队列中获取(当前个数/GOMAXPROCS)个 G。</strong></p><p><strong>为了保证公平性，从随机位置上的 P 开始，而且遍历的顺序也随机化了(选择一个小于 GOMAXPROCS，且和它互为质数的步长)，保证遍历的顺序也随机化了。</strong></p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/work-stealing-p0.png" class="" title="image-20210718150126958"><p>光窃取失败时获取是不够的，可能会导致<strong>全局队列饥饿</strong>。P 的调度算法中还会<strong>每个 N (1/61 time)轮调度之后就去全局队列拿一个 G</strong>。</p><p>谁放入的全局队列呢？</p><p><em>新建 G 时 P 的本地 G 队列放不下已满并达到256个的时候会放半数 G 到全局队列去，阻塞的系统调用返回时找不到空闲 P 也会放到全局队列。</em></p><h3 id="Syscall"><a href="#Syscall" class="headerlink" title="Syscall"></a>Syscall</h3><p>调用 syscall 后<strong>M会解绑 P</strong>，然后**<code>M </code>和 <code>G</code> 进入<code>阻塞</code>*<em>，而 P 此时的状态就是 <code>syscall</code>，</em>表明这个 P 的 G 正在 syscall 中<em>，这时的 P 是</em>不能被调度给别的 M* 的。<em>如果在短时间内阻塞的 M 就唤醒了，那么 M 会优先来重新获取这个 P，能获取到就继续绑回去，这样有利于数据的局部性</em>。</p><p>系统监视器 (<code>system monitor</code>)，称为 <code>sysmon</code>，会<strong>定时扫描</strong>。在执行 syscall 时, 如果某个 P 的 G 执行超过一个<code> sysmon tick(10ms)</code>，就会把他设为 <code>idle</code>，<em>重新调度给需要的 M，强制解绑</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/syscall-handoffs-p-sysmon.png" class="" title="image-20210718152037397"><p>P1 和 M 脱离后目前在 idle list 中等待被绑定（处于 syscall 状态）。而 syscall 结束后 M 按照如下规则执行直到满足其中一个条件：</p><ol><li> 尝试<em>获取同一个 P</em>(P1)，恢复执行 G</li><li> 尝试<em>获取 idle list 中的其他空闲 P</em>，恢复执行 G</li><li> <em>找不到空闲 P，把 G 放回 global queue，M 放回到 idle list</em></li></ol><h3 id="Spining-thread"><a href="#Spining-thread" class="headerlink" title="Spining thread"></a>Spining thread</h3><p><em>线程自旋是相对于线程阻塞而言的</em>，表象就是循环执行一个指定逻辑(调度逻辑，目的是不停地寻找 G)。这样做的问题显而易见，如果 G 迟迟不来，<em>CPU 会白白浪费在这无意义的计算上</em>。但好处也很明显，<em>降低了 M 的上下文切换成本，提高了性能</em>。在两个地方引入自旋：</p><ul><li>  类型1：M 不带 P 的<strong>找 P</strong> 挂载（一有 P 释放就结合）</li><li>  类型2：M 带 P 的<strong>找 G</strong> 运行（一有 runable 的 G 就执行）</li></ul><p>为了避免过多浪费 CPU 资源，自旋的 M 数量最多只允许 <code>GOMAXPROCS (Busy P)</code>。同时当有类型1的自旋 M 存在时，类型2的自旋 M 就不阻塞，阻塞会释放 P，一释放 P 就马上被类型1的自旋 M 抢走了，没必要。</p><p>在<strong>新 G 被创建</strong>、<strong>M 进入系统调用</strong>、<strong>M 从空闲被激活</strong>这三种状态变化前，调度器会确保<strong>至少有一个自旋 M 存在</strong>（唤醒或者创建一个 M），<strong>除非没有空闲的 P</strong>。</p><ul><li><p>  <code>当新 G 创建，如果有可用 P，就意味着新 G 可以被立即执行，即便不在同一个 P 也无妨，所以我们保留一个自旋的 M（这时应该不存在类型1的自旋只有类型2的自旋）就可以保证新 G 很快被运行。</code></p></li><li><p>  <code>当 M 进入系统调用，意味着 M 不知道何时可以醒来，那么 M 对应的 P 中剩下的 G 就得有新的 M 来执行，所以我们保留一个自旋的 M 来执行剩下的 G（这时应该不存在类型2的自旋只有类型1的自旋）。</code></p></li><li><p>  <code>如果 M 从空闲变成活跃，意味着可能一个处于自旋状态的 M 进入工作状态了，这时要检查并确保还有一个自旋 M 存在，以防还有 G 或者还有 P 空着的。</code></p></li></ul><h3 id="GMP问题总结"><a href="#GMP问题总结" class="headerlink" title="GMP问题总结"></a>GMP问题总结</h3><ul><li><p><strong>单一全局互斥锁(Sched.Lock)和集中状态存储</strong></p><pre><code>  G 被分成全局队列和 P 的本地队列，*全局队列依旧是全局锁，但是使用场景明显很少，P 本地队列使用无锁队列，使用原子操作来面对可能的并发场景*。</code></pre></li><li><p><strong>Goroutine 传递问题</strong></p><pre><code>   *G 创建时就在 P 的本地队列*，可以避免在 G 之间传递（窃取除外），G 对 P 的数据局部性好; 当 G 开始执行了，系统调用返回后 M 会尝试获取可用 P，获取到了的话可以避免在 M 之间传递。**而且优先获取调用阻塞前的 P，所以 G 对 M 数据局部性好，G 对 P 的数据局部性也好。**</code></pre></li><li><p><strong>Per-M 持有内存缓存 (M.mcache)</strong></p><pre><code> *内存 mcache 只存在 P 结构中*，P 最多只有 GOMAXPROCS 个，远小于 M 的个数，所以内存没有过多的消耗。  </code></pre></li><li><p>严重的线程<strong>阻塞/解锁</strong></p><pre><code>  通过*引入自旋*，保证**任何时候都有处于等待状态的自旋 M**，避免**在等待可用的 P 和 G 时频繁的阻塞和唤醒**。</code></pre></li></ul><p><code>by Dmitry Vyukov “Scalable Go Scheduler Design Doc”</code></p><h3 id="sysmon"><a href="#sysmon" class="headerlink" title="sysmon"></a>sysmon</h3><p>sysmon 也叫<em>监控线程</em>，它<em>无需 P 也可以运行</em>，他是一个<em>死循环</em>，每<code>20us~10ms</code>循环一次，循环完一次就 <code>sleep </code>一会，为什么会是一个<strong>变动的周期</strong>呢，主要是<em>避免空转</em>，如果每次循环都没什么需要做的事，那么 sleep 的时间就会加大。</p><ul><li>  <strong>释放</strong>闲置超过5分钟的 <code>span </code><strong>物理内存</strong>；</li><li>  如果超过2分钟没有<strong>垃圾回收，强制执行</strong>；</li><li>  将长时间未处理的 <code>netpoll </code><em>添加到全局队列</em>；</li><li>  向长时间运行的 G 任务<strong>发出抢占调度</strong>；</li><li>  <strong>收回</strong>因 <code>syscall </code><strong>长时间阻塞的 P</strong>；</li></ul><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/preempt-by-sysmon.png" class="" title="image-20210718155407628"><p><em>当 P 在 M 上执行时间超过10ms</em>，<code>sysmon </code>调用 <code>preemptone </code>将 G 标记为 <code>stackPreempt </code>。因此需要在某个地方触发检测逻辑，Go 当前是在<strong>检查栈是否溢出的地方判定</strong>(<code>morestack</code>())，M 会保存当前 G 的上下文，重新进入调度逻辑。</p><p>死循环：issues/11462</p><p>信号抢占：go1.14基于信号的<em>抢占式调度</em>实现原理</p><p>异步抢占，注册 <code>sigurg </code>信号，通过 <code>sysmon </code>检测，对 M 对应的线程发送信号，触发注册的 handler，它往当前 G 的 PC 中插入一条指令(调用某个方法)，在处理完 handler，G 恢复后，自己把自己推到了 global queue 中。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/preempt-by-sysmon-sig.png" class="" title="image-20210718155635185"><h3 id="Network-poller"><a href="#Network-poller" class="headerlink" title="Network poller"></a>Network poller</h3><p>Go <strong>所有的 I/O 都是阻塞的</strong>。然后通过 <code>goroutine + channel</code> 来<em>处理并发</em>。因此所有的 IO 逻辑都是直来直去的，你不再需要回调，不再需要 future，要的仅仅是 step by step。这对于代码的可读性是很有帮助的。</p><p><em>G 发起网络 I/O 操作也不会导致 M 被阻塞(仅阻塞G)，从而不会导致大量 M 被创建出来</em>。<strong>将异步 I/O 转换为阻塞 I/O 的部分称为 netpoller</strong>。<em>打开或接受连接都被设置为非阻塞模式。如果你试图对其进行 I/O 操作，并且文件描述符数据还没有准备好，G 会进入 gopark 函数，将当前正在执行的 G 状态保存起来，然后切换到新的堆栈上执行新的 G。</em></p><p>那什么时候 G 被调度回来呢？</p><ul><li>  <code>sysmon</code></li><li>  <code>schedule()</code>：M 找 G 的调度函数</li><li>  <code>GC</code>：start the world</li></ul><p>调用 netpoll() 在某一次调度 G 的过程中，处于就绪状态的 fd 对应的 G 就会被调度回来。</p><p>G 的 gopark 状态：G 置为 waiting 状态，等待显示 goready 唤醒，在 poller 中用得较多，还有锁、chan 等。</p><h3 id="Schedule-Affinity"><a href="#Schedule-Affinity" class="headerlink" title="Schedule Affinity"></a>Schedule Affinity</h3><p>在 chan 来回通信的 goroutine 会导致频繁的 blocks，即频繁地在本地队列中重新排队。然而，由于本地队列是 FIFO 实现，如果另一个 goroutine 占用线程，unblock goroutine 不能保证尽快运行。同时 Go 亲缘性调度的一些限制：Work-stealing、系统调用。</p><p>goroutine #9 在 chan 被阻塞后恢复。但是，它必须等待#2、#5和#4之后才能运行。goroutine #5将阻塞其线程，从而延迟goroutine #9，并使其面临被另一个 P 窃取的风险。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/image-20210718160233704.png" class="" title="image-20210718160233704"><p>针对 communicate-and-wait 模式，进行了<strong>亲缘性调度</strong>的优化。Go 1.5 在 P 中引入了 <code>runnext </code>特殊的一个字段，可以<strong>高优先级执行 unblock G</strong>。</p><p><em>goroutine #9现在被标记为下一个可运行的</em>。<strong>这种新的优先级排序允许 goroutine 在再次被阻塞之前快速运行</strong>。这一变化对运行中的标准库产生了总体上的积极影响，提高了一些包的性能。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/affinity-schedule.png" class="" title="image-20210718160318778"><h1 id="Goroutine-Lifecycle"><a href="#Goroutine-Lifecycle" class="headerlink" title="Goroutine Lifecycle"></a>Goroutine Lifecycle</h1><h3 id="Go程序启动"><a href="#Go程序启动" class="headerlink" title="Go程序启动"></a>Go程序启动</h3><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/runtime-main.png" class="" title="image-20210718160426412"><p>整个程序始于一段汇编，而在随后的<code> runtime·rt0_go</code>（也是汇编程序）中，会执行很多初始化工作。</p><ul><li>  <strong>绑定 m0 和 g0</strong>，<code>m0</code>就是<strong>程序的主线程</strong>，程序启动必然会拥有一个主线程，这个就是 m0。<code>g0</code> <strong>负责调度</strong>，即 <code>shedule() 函数</code>。</li><li><strong>创建 P</strong>，<strong>绑定 m0 和 p0</strong>，首先会<code>创建 GOMAXPROCS 个 P</code> ，存储在 <code>sched </code>的 <code>空闲链表(pidle)</code>。<br>  新建任务 <em>g 到 p0 本地队列</em>，<em>m0 的 g0 会创建一个 指向 runtime.main() 的 g</em> ，并<em>放到 p0 的本地队列</em>。</li><li>  <strong>runtime.main()</strong>: 启动 <code>sysmon </code>线程；启动 <code>GC</code> <code>协程</code>；执行 <code>init</code>，即代码中的各种 init 函数；执行 <code>main.main</code>(用户程序main) 函数。</li></ul><h3 id="OS-thread-创建"><a href="#OS-thread-创建" class="headerlink" title="OS thread 创建"></a>OS thread 创建</h3><p>准备运行的<strong>新 goroutine 将唤醒 P</strong> 以更好地分发工作。这个 <strong>P 将创建一个与之关联的 M 绑定到一个 OS thread</strong>。</p><p>go func() 中 触发 <code>Wakeup </code>唤醒机制：</p><p>有空闲的 P 而没有在 <code>spinning </code>状态的 M 时候, 需要去<strong>唤醒</strong>一个*空闲(睡眠)的 M *或者<strong>新建</strong>一个。当线程首次创建时，会执行一个特殊的 G，即 <em>g0，它负责管理和调度 G</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/OS-thread.png" class="" title="image-20210718160954428"><h3 id="g0"><a href="#g0" class="headerlink" title="g0"></a>g0</h3><p> Go 基于<em>两种断点将 G 调度到线程</em>上： </p><ul><li>  当<strong>G 阻塞</strong>时：系统调用、互斥锁或 chan。阻塞的 G 进入睡眠模式/进入队列，并允许 Go 安排和运行等待其他的 G。</li><li>  在<strong>函数调用期间</strong>，如果 G 必须<strong>扩展其堆栈</strong>。这个断点允许 Go 调度另一个 G 并避免运行 G 占用 CPU。</li></ul><p>在这两种情况下，<strong>运行调度程序的 g0 将当前 G 替换为另一个 G</strong>，即 ready to run。然后，选择的 G 替换 g0 并在线程上运行。与常规 G 相反，<strong>g0 有一个固定和更大的栈</strong>。</p><ul><li>  Defer 函数的分配</li><li>  GC 收集，比如 STW、扫描 G 的堆栈和标记、清除操作</li><li>  栈扩容，当需要的时候，由 g0 进行扩栈操作</li></ul><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/G0-schedule.png" class="" title="image-20210718161445297"><h3 id="Schedule"><a href="#Schedule" class="headerlink" title="Schedule"></a>Schedule</h3><p>在 Go 中，G 的切换相当轻便，其中需要<strong>保存的状态</strong>仅仅涉及以下<em>两个</em>：</p><ul><li>  Goroutine 在<em>停止运行前执行的指令</em>，程序<em>当前要运行的指令</em>是<em>记录在程序计数器（PC）中</em>的， G 稍后将在同一指令处恢复运行；</li><li>  G 的<em>堆栈</em>，以便在再次运行时<em>还原局部变量</em>；</li></ul><p>在切换之前，堆栈将被保存，以便在 G 再次运行时进行恢复.</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/schedule-time.png" class="" title="image-20210718161747355"><p>从 g 到 g0 或从 g0 到 g 的切换是相当迅速的，它们<em>只包含少量固定的指令</em>。相反，对于调度阶段，<strong>调度程序需要检查许多资源以便确定下一个要运行的 G</strong>。</p><ul><li>  当前 g 阻塞在 chan 上并切换到 g0：1、PC 和堆栈指针一起保存在内部结构中；2、将 g0 设置为正在运行的 goroutine；3、g0 的堆栈替换当前堆栈；</li><li>  g0 寻找新的 Goroutine 来运行</li><li>  g0 使用所选的 Goroutine 进行切换： 1、PC 和堆栈指针是从其内部结构中获取的；2、程序跳转到对应的 PC 地址；</li></ul><h3 id="Goroutine-Recycle"><a href="#Goroutine-Recycle" class="headerlink" title="Goroutine Recycle"></a>Goroutine Recycle</h3><p>G 很容易创建，栈很小以及快速的上下文切换。基于这些原因，开发人员非常喜欢并使用它们。然而，一个产生许多 <code>shortlive</code> 的 G 的程序<em>将花费相当长的时间来创建和销毁它们</em>。</p><p>每个 P 维护一个 <code>freelist G</code>，保持这个列表是<em>本地的</em>，这样做的好处是不使用任何锁来 push/get 一个空闲的 G。<em>当 G 退出当前工作时，它将被 push 到这个空闲列表中</em>。</p><p>为了更好地分发空闲的 G ，<strong>调度器</strong>也有自己的列表。它实际上有两个列表：<strong>一个包含已分配栈的 G，另一个包含释放过堆栈的 G（无栈）</strong>。</p><p>锁保护 central list，因为任何 M 都可以访问它。当本地列表长度超过64时，调度程序持有的列表从 P 获取 G。然后一半的 G 将移动到中心列表。需求回收 G 是一种节省分配成本的好方法。但是，由于堆栈是动态增长的，现有的G 最终可能会有一个大栈。因此，<em>当堆栈增长（即超过2K）时，Go 不会保留这些栈</em>。</p><img src="/2021/07/25/Goroutine%E5%8E%9F%E7%90%86/go-recycle.png" class="" title="image-20210718162414057">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Goroutine&quot;&gt;&lt;a href=&quot;#Goroutine&quot; class=&quot;headerlink&quot; title=&quot;Goroutine&quot;&gt;&lt;/a&gt;Goroutine&lt;/h1&gt;&lt;h3 id=&quot;定义&quot;&gt;&lt;a href=&quot;#定义&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="Goroutine" scheme="http://example.com/categories/Goroutine/"/>
    
    
  </entry>
  
  <entry>
    <title>go内存分配原理</title>
    <link href="http://example.com/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/</id>
    <published>2021-07-25T14:06:18.000Z</published>
    <updated>2021-07-25T14:08:40.247Z</updated>
    
    <content type="html"><![CDATA[<h1 id="堆栈与逃逸分析"><a href="#堆栈与逃逸分析" class="headerlink" title="堆栈与逃逸分析"></a>堆栈与逃逸分析</h1><h3 id="堆栈定义"><a href="#堆栈定义" class="headerlink" title="堆栈定义"></a>堆栈定义</h3><p>Go 有两个地方可以分配内存：一个<strong>全局堆空间</strong>用来<em>动态分配</em>内存，另一个是每个 <code>goroutine </code>都有的<strong>自身栈空间</strong>。</p><h4 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h4><p> 栈区的内存一般由<strong>编译器自动进行分配和释放</strong>，其中存储着函数的<strong>入参</strong>以及<strong>局部</strong>变量，这些参数会随着函数的创建而创建，函数的返回而销毁。(通过 <code>CPU push &amp; release</code>)。<br>    <em>A function has direct access to the memory inside its frame, through the frame pointer, but access to memory outside its frame requires indirect access.</em></p><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>堆区的内存一般由<strong>编译器和工程师</strong>自己共同进行管理<strong>分配</strong>，交给 <code>Runtime GC</code> 来<strong>释放</strong>。堆上分配必须找到一块足够大的内存来存放新的变量数据。后续释放时，<em>垃圾回收器扫描堆空间寻找不再被使用的对象</em>。<br>    Anytime a value is shared outside the scope of a function’s stack frame, it will be placed (or allocated) on the heap.<br>栈分配廉价，堆分配昂贵。stack allocation is cheap and heap allocation is expensive.</p><h3 id="变量到底在堆还是栈上？"><a href="#变量到底在堆还是栈上？" class="headerlink" title="变量到底在堆还是栈上？"></a>变量到底在堆还是栈上？</h3><p>写过其他语言，比如 C 的同学都知道，有明确的栈和堆的相关概念。而 Go 声明语法并没有提到栈和堆，而是交给 Go 编译器决定在哪分配内存，保证程序的正确性，在 Go FAQ 里面提到这么一段解释：</p><p>从正确的角度来看，你不需要知道。Go 中的每个变量只要有引用就会一直存在。变量的存储位置(堆还是栈)和语言的语义无关。</p><p>存储位置对于写出高性能的程序确实有影响。如果可能，Go 编译器将为该函数的堆栈侦(stack frame)中的函数分配本地变量。但是如果编译器在函数返回后<strong>无法证明变量未被引用</strong>，则编译器必须在会被垃圾回收的堆上分配变量以避免悬空指针错误。此外，如果<em>局部变量非常大，将它存储在堆而不是栈上可能更有意义</em>。</p><p>在当前编译器中，<em>如果变量存在取址，则该变量是堆上分配的候选变量</em>。但是基础的<em>逃逸分析</em>可以将那些生存不超过函数返回值的变量识别出来，并且因此可以分配在栈上。</p><h3 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h3><p>“通过<strong>检查变量的作用域</strong>是否<strong>超出了它所在的栈</strong>来决定是否将它分配在堆上”的技术，其中“变量的作用域超出了它所在的栈”这种行为即被称为逃逸。逃逸分析在大多数语言里属于静态分析：在编译期由静态代码分析来决定一个值是否能被分配在栈帧上，还是需要“逃逸”到堆上。</p><ul><li><p>  <em>减少 GC 压力</em>，栈上的变量，随着函数退出后系统直接回收，不需要标记后再清除</p></li><li><p>  <em>减少内存碎片</em>的产生</p></li><li><p>  <em>减轻分配堆内存的开销</em>，提高程序的运行速度</p></li></ul><p>可以通过命令<code>go build -gcflags -m</code>发现变量是否逃逸到堆上。</p><h3 id="超过栈帧-stack-frame"><a href="#超过栈帧-stack-frame" class="headerlink" title="超过栈帧(stack frame)"></a>超过栈帧(stack frame)</h3><p>当一个函数被调用时，会在<strong>两个相关的帧边界</strong>间<strong>进行上下文切换</strong>。从调用函数切换到被调用函数，<em>如果函数调用时需要传递参数，那么这些参数值也要传递到被调用函数的帧边界中</em>。<em><strong>Go 语言中帧边界间的数据传递是按值传递的</strong></em>。任何在函数 <code>getRandom </code>中的变量在函数返回时，都将不能访问。<em>Go 查找所有变量超过当前函数栈侦的，把它们分配到堆上，避免 outlive 变量</em>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-stack.png" class="" title="image-20210722225325976"><p>上述情况中，num 变量不能指向之前的栈。</p><p>Go 查找所有变量超过当前函数栈侦的，把它们分配到堆上，避免 outlive 变量。</p><p>变量 tmp 在栈上分配，但是它包含了指向堆内存的地址，所以可以安全的从一个函数的栈侦复制到另外一个函数的栈帧。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/heap-alloc.png" class="" title="image-20210722225623130"><h3 id="逃逸案例"><a href="#逃逸案例" class="headerlink" title="逃逸案例"></a>逃逸案例</h3><p>还存在大量其他的 case 会出现逃逸，比较典型的就是 “<strong>多级间接赋值容易导致逃逸</strong>”，这里的多级间接指的是，<em>对某个引用类对象中的引用类成员进行赋值</em>（记住公式 <code>Data.Field = Value</code>，如果 Data, Field 都是引用类的数据类型，则会导致 Value 逃逸。这里的等号 = 不单单只赋值，也表示参数传递）。Go 语言中的引用类数据类型有 <code>func</code>, <code>interface</code>, <code>slice</code>, <code>map</code>, <code>chan</code>, <code>*Type</code> ：</p><ul><li>  一个值被分享到函数栈帧范围之外</li><li>  在 for 循环外申明，在 for 循环内分配，同理闭包</li><li>  发送指针或者带有指针的值到 channel 中</li><li>  在一个切片上存储指针或带指针的值</li><li>  slice 的背后数组被重新分配了</li><li>  在 interface 类型上调用方法</li></ul><p>….<strong>go build -gcflags ‘-m’</strong></p><h1 id="连续栈"><a href="#连续栈" class="headerlink" title="连续栈"></a>连续栈</h1><p>Go 应用程序运行时，<em>每个 goroutine 都维护着一个自己的栈区</em>，这个栈区只能自己使用不能被其他 goroutine 使用。<em>栈区的初始大小是2KB</em>(比 x86_64 架构下线程的默认栈2M 要小很多)，在 goroutine 运行的时候栈区会按<strong>照需要增长和收缩</strong>，占用的内存最大限制的默认值在64位系统上是<strong>1GB</strong>。</p><ul><li>  v1.0 ~ v1.1 — 最小栈内存空间为 4KB</li><li>  v1.2 — 将最小栈内存提升到了 8KB</li><li>  v1.3 — 使用连续栈替换之前版本的分段栈</li><li>  v1.4 — 将最小栈内存降低到了 2KB</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/segmented-stack.png" class="" title="image-20210722230300734"><h3 id="Hot-split问题"><a href="#Hot-split问题" class="headerlink" title="Hot split问题"></a>Hot split问题</h3><p>分段栈的实现方式存在 “<code>hot split</code>” 问题，如果栈快满了，那么下一次的函数调用会强制触发栈扩容。当函数返回时，新分配的 “stack chunk” 会被清理掉。如果这个函数调用产生的范围是在一个循环中，<em>会导致严重的性能问题，频繁的 alloc/free</em>。</p><p>Go 不得不在1.2版本把栈默认大小改为8KB，降低触发热分裂的问题，但是每个 goroutine 内存开销就比较大了。<em>直到实现了连续栈(contiguous stack)，栈大小才改为2KB</em>。 </p><h3 id="连续栈-Contigous-stacks"><a href="#连续栈-Contigous-stacks" class="headerlink" title="连续栈(Contigous stacks)"></a>连续栈(Contigous stacks)</h3><p>采用<strong>复制栈</strong>的实现方式，在热分裂场景中不会频发释放内存，即不像分配一个新的内存块并链接到老的栈内存块，而是<strong>会分配一个两倍大的内存块并把老的内存块内容复制到新的内存块里</strong>，当栈缩减回之前大小时，我们不需要做任何事情。</p><ul><li>  <code>runtime.newstack</code> <strong>分配</strong>更大的栈内存空间</li><li>  <code>runtime.copystack</code> 将旧栈中的内容<strong>复制</strong>到新栈中</li><li>  <strong>将指向旧栈对应变量的指针重新指向新栈</strong></li><li>  <code>runtime.stackfree</code> <strong>销毁</strong>并<strong>0</strong>旧栈的内存空间</li></ul><p>如果栈区的空间<strong>使用率不超过1/4</strong>，那么在<strong>垃圾回收</strong>的时候使用 <code>runtime.shrinkstack</code> 进行<strong>栈缩容</strong>，同样使用 <code>copystack</code>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/Contigous-stacks.png" class="" title="image-20210722230846677"><h3 id="栈扩容"><a href="#栈扩容" class="headerlink" title="栈扩容"></a>栈扩容</h3><p>Go <strong>运行时</strong>判断栈空间是否足够，所以在 <code>call function</code> 中会插入 <code>runtime.morestack</code>，但每个函数调用都判定的话，成本比较高。在编译期间通过计算 <code>sp、func stack framesize</code> 确定需要<strong>哪个函数调用中插入 runtime.morestack</strong>。</p><ul><li>  当函数是<strong>叶子节点</strong>，且<strong>栈帧小于等于 112</strong> ，不插入指令</li><li>  当<strong>叶子函数</strong>栈帧大小为 <code>120 -128</code> 或者 <strong>非叶子函数</strong>栈帧大小为 <code>0 -128</code>，<code>SP &lt; stackguard0</code></li><li>当函数栈帧大小为 <code>128 - 4096</code><pre><code>  `SP - framesize &lt; stackguard0 - StackSmall`</code></pre></li><li>大于 <code>StackBig</code><pre><code> ` SP-stackguard+StackGuard &lt;= framesize + (StackGuard-StackSmall)`</code></pre></li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/add-stacks.png" class="" title="image-20210722231223193"><h1 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h1><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><p><code>TCMalloc </code>是 <code>Thread Cache Malloc</code> 的简称，是Go 内存管理的起源，Go的内存管理是借鉴了TCMalloc：</p><ul><li><strong>内存碎片</strong><pre><code>  随着内存不断的申请和释放，内存上会存在大量的碎片，降低内存的使用率。为了解决内存碎片，可以**将2个连续的未使用的内存块合并，减少碎片**。</code></pre></li><li><strong>大锁</strong><pre><code>  同一进程下的所有线程共享相同的内存空间，它们申请内存时需要加锁，如果不加锁就存在同一块内存被2个线程同时访问的问题。</code></pre></li></ul><h3 id="内存布局"><a href="#内存布局" class="headerlink" title="内存布局"></a>内存布局</h3><p>需要先知道几个重要的概念：</p><ul><li>  <code>page</code>: 内存<strong>页</strong>，一块 <code>8K</code> 大小的内存空间。<strong>Go 与操作系统</strong>之间的内存<strong>申请和释放</strong>，都是以 <code>page </code>为单位的。</li><li>  <code>span</code>: 内存<strong>块</strong>，<em>一个</em>或<em>多个连续的 page 组成一个 span</em>。</li><li>  <code>sizeclass</code>: <em>空间规格</em>，每个 <code>span </code>都<em>带有</em>一个 <code>sizeclass</code>，标记着该 span 中的 page 应该如何使用。</li><li>  <code>object</code>: <em>对象</em>，用来存储一个变量数据内存空间，<em>一个 span 在初始化时，会被切割成一堆等大的 object</em>。假设 object 的大小是 16B，span 大小是 8K，那么就会把 span 中的 page 就会被初始化 8K / 16B = 512 个 object。</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/span-size-classes.png" class="" title="image-20210722233429021"><h3 id="小于32kb内存分配"><a href="#小于32kb内存分配" class="headerlink" title="小于32kb内存分配"></a>小于32kb内存分配</h3><p>当程序里发生了 32kb 以下的小块内存申请时，Go 会从一个叫做的 <code>mcache </code>的<strong>本地缓存</strong>给程序分配内存。这样的一个内存块里叫做 <code>mspan</code>，它是要给程序分配内存时的分配单元。</p><p>在 Go 的调度器模型里，每个线程  M 会绑定给一个处理器 P，在<strong>单一粒度的时间里只能最多处理运行一个 goroutine</strong>，<strong>每个 P</strong> 都会<strong>绑定一个</strong>上面说的本地缓存 <code>mcache</code>。当需要进行内存分配时，当前运行的 <code>goroutine </code>会从 <code>mcache </code>中查找可用的 <code>mspan</code>。从本地 <code>mcache </code>里<em>分配</em>内存时<strong>不需要加锁</strong>，这种分配策略效率更高。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/alloc-with-mcache.png" class="" title="image-20210722233807537"><p>申请内存时都分给他们一个 <code>mspan </code>这样的单元会不会产生浪费。其实 <code>mcache </code>持有的这一系列的<code>mspan </code>并不都是统一大小的，而是按照大小，从<code>8b 到 32kb </code>分了大概 <strong>67*2</strong> 类的 <code>mspan</code>。</p><p>每个内存页分为<strong>多级固定大小</strong>的“空闲列表”，这有助于减少碎片。类似的思路在<code> Linux Kernel</code>、<code>Memcache </code>都可以见到 <code>Slab-Allactor</code>。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/alloc-with-mcache1.png" class="" title="image-20210722233953150"><p>如果分配内存时 <code>mcachce </code>里<strong>没有空闲的对口 sizeclass 的 mspan</strong> 了，Go 里还为每种类别的 <code>mspan </code>维护着一个 <code>mcentral</code>。</p><p><code>mcentral </code>的作用是<strong>为所有 mcache 提供切分好的 mspan 资源</strong>。每个 <code>central </code>会持有一种<em>特定大小</em>的<strong>全局 mspan 列表</strong>，包括<em>已分配</em>出去的和<em>未分配</em>出去的。 每个 <code>mcentral </code>对应一种 <code>mspan</code>，当<strong>工作线程</strong>的 <code>mcache </code>中没有合适(也就是特定大小的)的mspan 时就<strong>会从 mcentral 去获取</strong>。</p><p><code>mcentral </code>被<em>所有的工作线程</em><strong>共同享有</strong>，存在多个 <strong>goroutine 竞争</strong>的情况，因此从 mcentral 获取资源时<strong>需要加锁</strong>。mcentral 里维护着两个双向链表，<code>nonempty </code>表示链表里还有<em>空闲的 mspan 待分配</em>。<code>empty</code> 表示这条链表里的 <em>mspan 都被分配了</em><code>object </code>或缓存 <code>mcache </code>中。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/central-lists-mspan.png" class="" title="image-20210722234358905"><p>程序申请内存的时候，mcache 里已经没有合适的空闲 mspan了，那么工作线程就会像下图这样去 mcentral 里去申请。<code>mcache </code>从 <code>mcentral </code><em>获取</em>和<em>归还</em> <code>mspan </code>的流程：</p><ul><li>  <strong>获取</strong> <em>加锁</em>；从 <code>nonempty </code>链表<em>找到一个可用的mspan</em>；并将其<em>从 nonempty 链表删除</em>；将取出的 <em>mspan 加入到 empty</em> 链表；将 <em>mspan 返回给工作线程</em>；<em>解锁</em>。</li><li>  <strong>归还</strong> <em>加锁</em>；将 <code>mspan </code>从 <code>empty </code>链表<em>删除</em>；将<code>mspan </code><em>加入</em>到 <code>nonempty </code>链表；<em>解锁</em>。</li></ul><p><code>mcentral </code>是 sizeclass 相同的 span 会以链表的形式组织在一起, 就是指该 span 用来存储哪种大小的对象。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/span-replace-from-central.png" class="" title="image-20210722234818604"><p>当 <strong>mcentral 没有空闲的 mspan 时，会向 mheap 申请</strong>。而 <strong>mheap 没有资源时，会向操作系统申请新内存</strong>。mheap 主要用于<em>大对象</em>的内存分配，以及<em>管理未切割的 mspan</em>，用于给 mcentral 切割成小对象。<br>mheap 中含有<em>所有规格的 mcentral</em>，所以<em>当一个 mcache 从 mcentral 申请 mspan 时，只需要在独立的 mcentral 中使用锁，并不会影响申请其他规格的 mspan</em>。</p><p>所有 <code>mcentral </code>的<em>集合</em>则是<em>存放于</em> <code>mheap </code>中的。 <code>mheap </code>里的 <code>arena </code>区域是<strong>真正的堆区</strong>，运行时会将 <code>8KB</code> 看做<em>一页</em>，这些内存页中存储了所有在<strong>堆上初始化的对象</strong>。运行时使用二维的 <code>runtime.heapArena</code> 数组管理所有的内存，每个 <code>runtime.heapArena</code> 都会<strong>管理 64MB 的内存</strong>。<br>如果 arena 区域没有足够的空间，会调用 <code>runtime.mheap.sysAlloc</code> 从<em>操作系统中申请</em>更多的内存。（如下图：Go 1.11 前的内存布局）</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-strcuture.png" class="" title="image-20210722235715115"><p>图中的空间大小，是 Go 向操作系统申请的虚拟内存地址空间，操作系统会将该段地址空间预留出来不做它用；而不是真的创建出这么大的虚拟内存，在页表中创建出这么大的映射关系。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/scan.png" class="" title="image-20210722235921766"><h3 id="小于16byte内存分配"><a href="#小于16byte内存分配" class="headerlink" title="小于16byte内存分配"></a>小于16byte内存分配</h3><p>对于<strong>小于16字节</strong>的对象(且<strong>无指针</strong>)，Go 语言将其划分为了<code>tiny </code>对象。划分 <code>tiny </code>对象的主要目的是为了<strong>处理极小的字符串</strong>和<strong>独立的转义变量</strong>。对 json 的基准测试表明，使用 tiny 对象减少了12%的分配次数和20%的堆大小。tiny 对象会被放入<code>class </code>为<em>2</em>的 <code>span </code>中。</p><ul><li>  首先<em>查看</em>之前分配的元素中是否<em>有空余的空间</em></li><li>  如果当前要分配的<em>大小不够</em>，例如要分配16字节的大小，这时就需要<em>找到下一个</em>空闲的元素</li></ul><p><code>tiny </code>分配的第一步是<strong>尝试利用分配过的前一个元素的空间</strong>，达到<em>节约内存</em>的目的。</p><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/tiny-memory.png" class="" title="image-20210723000345774"><h3 id="大于32kb内存分配"><a href="#大于32kb内存分配" class="headerlink" title="大于32kb内存分配"></a>大于32kb内存分配</h3><p>Go 没法使用工作线程的本地缓存 <code>mcache </code>和全局中心缓存 <code>mcentral </code>上管理<em>超过32KB的内存</em>分配，所以对于那些超过32KB的内存申请，会直接从堆上(<code>mheap</code>)上分配<em>对应的数量</em>的内存页(<em>每页大小是8KB</em>)给程序。</p><ul><li>  <code>freelist</code></li><li>  <code>treap</code></li><li>  <code>radix tree + pagecache</code></li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/large-memory-alloc.png" class="" title="image-20210723001300487"><h3 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h3><p>一般<em>小对象</em>通过 <code>mspan </code><em>分配内存</em>；<em>大对象</em>则直接由 <code>mheap </code><em>分配</em>内存。</p><ul><li>  Go 在程序<em>启动时</em>，会向<em>操作系统申请一大块内存</em>，由 <em>mheap 结构全局管理</em>(现在 Go 版本不需要连续地址了，所以不会申请一大堆地址，多个64M内存组成)</li><li>  Go 内存管理的<em>基本单元</em>是 <code>mspan</code>，<em>每种 mspan 可以分配特定大小的 object</em></li><li>  <code>mcache</code>, <code>mcentral</code>, <code>mheap </code>是 Go 内存管理的三大组件，<code>mcache </code>管理线程在<em>本地缓存</em>的 <code>mspan</code>；<code>mcentral </code>管理<em>全局的 mspan</em>供所有线程</li></ul><img src="/2021/07/25/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/memory-alloc.png" class="" title="image-20210723001733960"><p>1、使用<strong>缓存提高效率</strong>。在存储的整个体系中到处可见缓存的思想，Go 利用缓存一是<strong>减少了系统调用</strong>的次数，二是<strong>降低了锁的粒度</strong>、<strong>减少加锁的次数</strong>。</p><p>2、以<strong>空间换时间</strong>，提高<strong>内存管理效率</strong>。空间换时间是一种常用的性能优化思想，这种思想其实非常普遍，比如<code>Hash</code>、<code>Map</code>、<code>二叉排序树</code>等数据结构的本质就是空间换时间。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;堆栈与逃逸分析&quot;&gt;&lt;a href=&quot;#堆栈与逃逸分析&quot; class=&quot;headerlink&quot; title=&quot;堆栈与逃逸分析&quot;&gt;&lt;/a&gt;堆栈与逃逸分析&lt;/h1&gt;&lt;h3 id=&quot;堆栈定义&quot;&gt;&lt;a href=&quot;#堆栈定义&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="Goroutine" scheme="http://example.com/categories/Goroutine/"/>
    
    
  </entry>
  
</feed>
